{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ribonanza - Attempt 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A second approach to the [Stanford Ribonanza problem](https://www.kaggle.com/competitions/stanford-ribonanza-rna-folding/) that builds off the first and second approaches.\n",
    "\n",
    "Major differences:\n",
    "- use of pytorch instead of tensorflow\n",
    "- use of attention model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, the attention architecture scores 0.2049"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- improve model\n",
    "- experiment with other types of attention\n",
    "- use full transformer model (with decoder) (not just encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filesystem Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your project directory should look like this:\n",
    "\n",
    "- `(project directory)`\n",
    "    - `ribonanza2.ipynb`\n",
    "    - `train_data.csv`\n",
    "    - `test_data.csv` (optional)\n",
    "\n",
    "`train_data.csv` is the only file necessary for training, and it can be downloaded from the kaggle competition linked in the description.\n",
    "\n",
    "`test_data.csv` is only necessary if you intend to make and submit predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import pandas\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import seaborn\n",
    "import os\n",
    "\n",
    "# used for better attention mechanisms\n",
    "import xformers.components.positional_embedding as embeddings\n",
    "import xformers.ops as xops\n",
    "import xformers.components.attention as attentions\n",
    "import xformers.components.attention.utils as att_utils\n",
    "import xformers.components as components\n",
    "\n",
    "# used for learning rate examining\n",
    "import fastai.learner as learner\n",
    "import fastai.callback.schedule  # used for lr_find\n",
    "import fastai.data.core as fdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "# according to kaggle, this is the maximum # of reactivites to be used\n",
    "NUM_REACTIVITIES = 457\n",
    "\n",
    "# there are 4 different bases (AUCG)\n",
    "NUM_BASES = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(out: str, key: str, value: str, file_name: str, force: bool):\n",
    "    \"\"\"\n",
    "    Filters a file to only take datapoints\n",
    "    whose values of `key` are `value`.\n",
    "\n",
    "    Parameters:\n",
    "        - out: str - the name of the file that will store the filtered datapoints\n",
    "        - key: str - the name of the key to look at\n",
    "        - value: str - the value that the key should have\n",
    "        - file_name: str - the name of the file that contains all the datapoints.\n",
    "        - force: bool - whether or not to force re-processing of the data (if False and `out` already exists, no work will be done)\n",
    "    \"\"\"\n",
    "    if os.path.exists(out) and not force:\n",
    "        print(\"File already exists, not doing any work\")\n",
    "        return\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    # count how many lines we have in total\n",
    "    with open(file_name) as file:\n",
    "        line = file.readline()  # ignore the header\n",
    "        line = (\n",
    "            file.readline()\n",
    "        )  # take the first line since we increment count in the loop\n",
    "        while line != \"\":\n",
    "            count += 1\n",
    "            line = file.readline()\n",
    "\n",
    "    # use that knowledge for a progress bar\n",
    "    with open(file_name, \"r\") as file, open(out, \"w\") as outfile:\n",
    "        # write the header\n",
    "        header = file.readline()\n",
    "        outfile.write(header)\n",
    "\n",
    "        # get what index the SN_filter is\n",
    "        SN_idx = header.split(\",\").index(key)\n",
    "\n",
    "        # only take the approved filtered lines\n",
    "        for _ in tqdm(range(count)):\n",
    "            line = file.readline()\n",
    "            temp = line.split(\",\")\n",
    "            if temp[SN_idx] == value:\n",
    "                outfile.write(line)\n",
    "\n",
    "\n",
    "def filter_train_data(force: bool = False):\n",
    "    \"\"\"\n",
    "    Filters the immense train_data.csv to only take datapoints\n",
    "    whose SN_filter (Signal to Noise filter) is 1. In other words,\n",
    "    we only take good reads. These filtered datapoints are then\n",
    "    written to the file provided\n",
    "\n",
    "    Parameters:\n",
    "        - force: bool - whether or not to force re-processing of the data (if False and `out` already exists, no work will be done)\n",
    "    \"\"\"\n",
    "    filter_data(\"train_data_filtered.csv\", \"SN_filter\", \"1\", \"train_data.csv\", force)\n",
    "\n",
    "\n",
    "def filter_2A3(force: bool = False):\n",
    "    \"\"\"\n",
    "    Only take the 2A3 points\n",
    "\n",
    "    Parameters:\n",
    "        - force: bool - whether or not to force re-processing of the data (if False and `out` already exists, no work will be done)\n",
    "    \"\"\"\n",
    "    filter_data(\n",
    "        \"train_data_2a3.csv\",\n",
    "        \"experiment_type\",\n",
    "        \"2A3_MaP\",\n",
    "        \"train_data_filtered.csv\",\n",
    "        force,\n",
    "    )\n",
    "\n",
    "\n",
    "def filter_DMS(force: bool = False):\n",
    "    \"\"\"\n",
    "    Only take the DMS points\n",
    "\n",
    "    Parameters:\n",
    "        - force: bool - whether or not to force re-processing of the data (if False and `out` already exists, no work will be done)\n",
    "    \"\"\"\n",
    "    filter_data(\n",
    "        \"train_data_dms.csv\",\n",
    "        \"experiment_type\",\n",
    "        \"DMS_MaP\",\n",
    "        \"train_data_filtered.csv\",\n",
    "        force,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists, not doing any work\n"
     ]
    }
   ],
   "source": [
    "# filter our data\n",
    "filter_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists, not doing any work\n"
     ]
    }
   ],
   "source": [
    "# take the 2a3 points\n",
    "filter_2A3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists, not doing any work\n"
     ]
    }
   ],
   "source": [
    "# take the dms points\n",
    "filter_DMS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Data to Inputs and Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode inputs as\n",
    "# A : 1\n",
    "# U : 2\n",
    "# C : 3\n",
    "# G : 4\n",
    "base_map = {\n",
    "    \"A\": 1,\n",
    "    \"U\": 2,\n",
    "    \"C\": 3,\n",
    "    \"G\": 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_csv(out: str, file_name: str, force: bool = False):\n",
    "    \"\"\"\n",
    "    Preprocess the csv and save the preprocessed data as a .npz file\n",
    "\n",
    "    Parameters:\n",
    "        - out: str - the name of the file to save the arrays to\n",
    "        - file_name: str - the name of the input csv file\n",
    "        - force: bool - whether or not to force re-processing of the data (if False and `out` already exists, no work will be done).\n",
    "                Defaults to `False`\n",
    "    \"\"\"\n",
    "    if os.path.exists(out) and not force:\n",
    "        print(\"File already exists, not doing any work\")\n",
    "        return\n",
    "\n",
    "    df = pandas.read_csv(file_name)\n",
    "\n",
    "    inputs = np.zeros((len(df), NUM_REACTIVITIES))\n",
    "    outputs = np.zeros((len(df), NUM_REACTIVITIES))\n",
    "    output_masks = np.ones((len(df), NUM_REACTIVITIES), dtype=np.bool_)\n",
    "    errors = np.zeros((len(df), NUM_REACTIVITIES))\n",
    "\n",
    "    for index in tqdm(range(len(df))):\n",
    "        row = df.iloc[index]\n",
    "\n",
    "        # get the sequence\n",
    "        seq_len = len(row[\"sequence\"])\n",
    "\n",
    "        # map the base to its one-hot encoding\n",
    "        inputs[index, :seq_len] = np.array(\n",
    "            list(map(lambda letter: base_map[letter], row[\"sequence\"]))\n",
    "        )\n",
    "\n",
    "        # get all the reactivities and reactivity errors\n",
    "        reactivities = np.array(\n",
    "            list(\n",
    "                map(\n",
    "                    lambda seq_idx: row[\"reactivity_\" + str(seq_idx + 1).rjust(4, \"0\")],\n",
    "                    range(seq_len),\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        reactivity_errors = np.array(\n",
    "            list(\n",
    "                map(\n",
    "                    lambda seq_idx: row[\n",
    "                        \"reactivity_error_\" + str(seq_idx + 1).rjust(4, \"0\")\n",
    "                    ],\n",
    "                    range(seq_len),\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # replace reactivity error nans with 0s (assume no error)\n",
    "        reactivity_errors = np.where(\n",
    "            np.isnan(reactivity_errors), 0.0, reactivity_errors\n",
    "        )\n",
    "\n",
    "        # get where all the reactivities are nan\n",
    "        nan_locats = np.isnan(reactivities)\n",
    "\n",
    "        # where it is nan, store True, else false\n",
    "        output_masks[index, :seq_len] = nan_locats\n",
    "\n",
    "        # where it is not nan, store the reactivity and error, else 0\n",
    "        outputs[index, :seq_len] = np.where(nan_locats == False, reactivities, 0.0)\n",
    "        errors[index, :seq_len] = np.where(nan_locats == False, reactivity_errors, 0.0)\n",
    "\n",
    "    # save the outputs\n",
    "    np.savez_compressed(\n",
    "        out, inputs=inputs, outputs=outputs, output_masks=output_masks, errors=errors\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists, not doing any work\n"
     ]
    }
   ],
   "source": [
    "preprocess_csv(\"train_data_2a3_preprocessed.npz\", \"train_data_2a3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists, not doing any work\n"
     ]
    }
   ],
   "source": [
    "preprocess_csv(\"train_data_dms_preprocessed.npz\", \"train_data_dms.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the desired dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:09:33.551791Z",
     "start_time": "2023-10-05T17:09:33.535197Z"
    }
   },
   "outputs": [],
   "source": [
    "desired_dataset = \"dms\"  # either \"2a3\" or \"dms\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:09:42.265620Z",
     "start_time": "2023-10-05T17:09:33.728394Z"
    }
   },
   "outputs": [],
   "source": [
    "# load the npz file\n",
    "npz_file = np.load(f\"train_data_{desired_dataset}_preprocessed.npz\")\n",
    "\n",
    "# stored inputs, outputs, and output_masks\n",
    "full_dataset = data.TensorDataset(\n",
    "    torch.tensor(npz_file[\"inputs\"], dtype=torch.float32),\n",
    "    torch.tensor(np.clip(npz_file[\"outputs\"], 0, 1), dtype=torch.float32),\n",
    "    torch.tensor(\n",
    "        np.clip(\n",
    "            np.where(npz_file[\"output_masks\"], 0.0, 1.0) - np.abs(npz_file[\"errors\"]),\n",
    "            0,\n",
    "            1,\n",
    "        ),\n",
    "        dtype=torch.float32,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# split into train, val\n",
    "train_dataset, val_dataset = data.random_split(full_dataset, lengths=[0.9, 0.1])\n",
    "\n",
    "# close the npz file\n",
    "npz_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set is len 204233 and val dataset is len 22692\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"train set is len\", len(train_dataset), \"and val dataset is len\", len(val_dataset)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section of the notebook allows for visualizing the reactivities of the\n",
    "current dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:09:42.844615Z",
     "start_time": "2023-10-05T17:09:42.843236Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:09:42.851158Z",
     "start_time": "2023-10-05T17:09:42.846563Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not visualizing. Set `visualize` to `True` to visualize data\n"
     ]
    }
   ],
   "source": [
    "if visualize:\n",
    "    npz_file = np.load(f\"train_data_{desired_dataset}_preprocessed.npz\")\n",
    "    outputs, bool_output_masks = npz_file[\"outputs\"], npz_file[\"output_masks\"]\n",
    "    npz_file.close()\n",
    "    visualized_items = []\n",
    "    for i in tqdm(range(len(outputs))):\n",
    "        for x in range(NUM_REACTIVITIES):\n",
    "            if not bool_output_masks[i, x]:\n",
    "                visualized_items.append(outputs[i, x])\n",
    "    visualized_items = np.array(visualized_items)\n",
    "    print(f\"took {len(visualized_items)}/{len(outputs)*NUM_REACTIVITIES} reactivities\")\n",
    "else:\n",
    "    print(\"Not visualizing. Set `visualize` to `True` to visualize data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:09:42.851272Z",
     "start_time": "2023-10-05T17:09:42.849526Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not visualizing. Set `visualize` to `True` to visualize data\n"
     ]
    }
   ],
   "source": [
    "if visualize:\n",
    "    seaborn.histplot(visualized_items, binwidth=0.1)\n",
    "else:\n",
    "    print(\"Not visualizing. Set `visualize` to `True` to visualize data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryEfficientSelfAttention(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, latent_dim: int, n_heads: int, dropout: float, *args, **kwargs\n",
    "    ) -> None:\n",
    "        super(MemoryEfficientSelfAttention, self).__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.latent_dim = latent_dim\n",
    "        self.dropout = dropout\n",
    "\n",
    "        assert latent_dim % n_heads == 0\n",
    "\n",
    "    def forward(self, x: torch.Tensor, **kwargs):\n",
    "        # B, Seq Len, embedding -> B, Seq Len, Heads, Embedding per head\n",
    "        x = x.reshape(x.shape[0], x.shape[1], self.n_heads, x.shape[2] // self.n_heads)\n",
    "        x = xops.memory_efficient_attention(x, x, x, p=self.dropout)\n",
    "        x = x.reshape(x.shape[0], x.shape[1], -1)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class SDPAttention(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        latent_dim: int,\n",
    "        n_heads: int,\n",
    "        dropout: float,\n",
    "        device: str,\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        super(SDPAttention, self).__init__()\n",
    "        self.mha = components.MultiHeadDispatch(\n",
    "            latent_dim,\n",
    "            num_heads=n_heads,\n",
    "            attention=attentions.ScaledDotProduct(dropout=dropout),\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, attention_mask: torch.Tensor):\n",
    "        return self.mha(x, att_mask=attention_mask)\n",
    "\n",
    "\n",
    "class SlidingWindowAttention(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        latent_dim: int,\n",
    "        n_heads: int,\n",
    "        dropout: float,\n",
    "        device: str,\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        super(SlidingWindowAttention, self).__init__()\n",
    "        self.mha = components.MultiHeadDispatch(\n",
    "            latent_dim,\n",
    "            n_heads,\n",
    "            attentions.LocalAttention(\n",
    "                dropout=dropout, window_size=kwargs[\"context_window\"]\n",
    "            ),\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, **kwargs):\n",
    "        return self.mha(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTransformerEncoderLayer(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        attention_type: torch.nn.Module,\n",
    "        latent_dim: int,\n",
    "        ff_dim: int,\n",
    "        n_heads: int,\n",
    "        dropout: float = 0.1,\n",
    "        device: str = \"cuda\",\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        super(CustomTransformerEncoderLayer, self).__init__()\n",
    "        self.attention = attention_type(\n",
    "            latent_dim=latent_dim,\n",
    "            n_heads=n_heads,\n",
    "            dropout=dropout,\n",
    "            device=device,\n",
    "            **kwargs\n",
    "        )\n",
    "        self.layer_norm = torch.nn.LayerNorm(latent_dim).to(device)\n",
    "\n",
    "        self.ff1 = torch.nn.Linear(latent_dim, ff_dim).to(device)\n",
    "        self.ff2 = torch.nn.Linear(ff_dim, latent_dim).to(device)\n",
    "        self.gelu = torch.nn.GELU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor, attention_mask: torch.Tensor):\n",
    "        # MHA, add, norm\n",
    "        x = self.layer_norm(self.attention(x, attention_mask=attention_mask) + x)\n",
    "\n",
    "        # ff, add, norm\n",
    "        x = self.layer_norm(self.gelu(self.ff2(self.gelu(self.ff1(x)))) + x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class CustomTransformerEncoder(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        attention_type: torch.nn.Module,\n",
    "        n_layers: int,\n",
    "        latent_dim: int,\n",
    "        ff_dim: int,\n",
    "        n_heads: int,\n",
    "        dropout: float = 0.1,\n",
    "        device: str = \"cuda\",\n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        super(CustomTransformerEncoder, self).__init__()\n",
    "        for i in range(n_layers):\n",
    "            self.add_module(\n",
    "                str(i),\n",
    "                CustomTransformerEncoderLayer(\n",
    "                    attention_type=attention_type,\n",
    "                    latent_dim=latent_dim,\n",
    "                    ff_dim=ff_dim,\n",
    "                    n_heads=n_heads,\n",
    "                    dropout=dropout,\n",
    "                    device=device,\n",
    "                    **kwargs\n",
    "                ),\n",
    "            )\n",
    "\n",
    "    def forward(self, x: torch.Tensor, attention_mask: torch.Tensor):\n",
    "        for module in self._modules.values():\n",
    "            x = module(x, attention_mask=attention_mask)\n",
    "        return x\n",
    "\n",
    "\n",
    "class AttentionModel(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        attention_type: torch.nn.Module,\n",
    "        context_window: int = 31,\n",
    "        latent_dim: int = 128,\n",
    "        ff_dim: int = 1024,\n",
    "        n_heads: int = 2,\n",
    "        enc_layers: int = 1,\n",
    "        device: str = \"cuda\",\n",
    "    ) -> None:\n",
    "        super(AttentionModel, self).__init__()\n",
    "\n",
    "        # data\n",
    "        self.n_heads = n_heads\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        # prepatory conv layers\n",
    "        self.conv_layer = torch.nn.Conv1d(\n",
    "            1, out_channels=latent_dim, kernel_size=context_window, padding=\"same\"\n",
    "        ).to(device)\n",
    "        self.conv_layer_b = torch.nn.Conv1d(\n",
    "            1, out_channels=latent_dim, kernel_size=context_window, padding=\"same\"\n",
    "        ).to(device)\n",
    "\n",
    "        # positional embedding and encoder layers\n",
    "        self.pos_embedding = embeddings.SinePositionalEmbedding(latent_dim).to(device)\n",
    "        self.encoder_layers = CustomTransformerEncoder(\n",
    "            latent_dim=latent_dim,\n",
    "            ff_dim=ff_dim,\n",
    "            n_heads=n_heads,\n",
    "            device=device,\n",
    "            attention_type=attention_type,\n",
    "            n_layers=enc_layers,\n",
    "            context_window=context_window,\n",
    "        )\n",
    "\n",
    "        # output head\n",
    "        self.head = torch.nn.Linear(latent_dim, 1).to(device)\n",
    "        self.final_result = torch.nn.Linear(NUM_REACTIVITIES, NUM_REACTIVITIES).to(\n",
    "            device\n",
    "        )\n",
    "\n",
    "        # activations\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.gelu = torch.nn.GELU()\n",
    "\n",
    "    def _forward(self, x: torch.Tensor):\n",
    "        mask = att_utils.maybe_merge_masks(\n",
    "            att_mask=None,\n",
    "            key_padding_mask=x != 0,\n",
    "            batch_size=x.shape[0],\n",
    "            num_heads=self.n_heads,\n",
    "            src_len=x.shape[1],\n",
    "        )\n",
    "        x = x.reshape(x.shape[0], 1, x.shape[1])\n",
    "        # print(x.shape)\n",
    "\n",
    "        x = self.gelu(\n",
    "            self.conv_layer(x)\n",
    "            + torch.flip(self.conv_layer_b(torch.flip(x, dims=[2])), dims=[2])\n",
    "        )\n",
    "        # print(x.shape)\n",
    "\n",
    "        x = x.permute((0, 2, 1)).contiguous()\n",
    "\n",
    "        x = self.pos_embedding(x)\n",
    "        x = self.encoder_layers(x, attention_mask=mask)\n",
    "\n",
    "        x = self.relu(self.final_result(self.gelu(self.head(x).flatten(start_dim=1))))\n",
    "        # print(x.shape)\n",
    "        return x\n",
    "\n",
    "    # used for calculating lr to use\n",
    "    def weightedForward(self, x: torch.Tensor, weights: torch.Tensor):\n",
    "        self.weights = weights\n",
    "        return self._forward(x)\n",
    "\n",
    "    def weightedLoss(self, y_pred: torch.Tensor, y_true: torch.Tensor):\n",
    "        return (\n",
    "            (torch.nn.L1Loss()(y_pred.cuda(), y_true.cuda()) * self.weights.cuda())\n",
    "            .sum(dim=-1)\n",
    "            .mean()\n",
    "        )\n",
    "\n",
    "    def configure_for_lr_testing(self):\n",
    "        self.forward = self.weightedForward\n",
    "\n",
    "    def configure_for_training(self):\n",
    "        self.forward = self._forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineModel(torch.nn.Module):\n",
    "    def __init__(self, context_window: int = 31, device: str = \"cuda\"):\n",
    "        super(BaselineModel, self).__init__()\n",
    "        self.conv_layer = torch.nn.Conv1d(1, 1, context_window, padding=\"same\").to(\n",
    "            device\n",
    "        )\n",
    "        self.conv_layer_b = torch.nn.Conv1d(1, 1, context_window, padding=\"same\").to(\n",
    "            device\n",
    "        )\n",
    "        self.ff = torch.nn.Linear(NUM_REACTIVITIES, NUM_REACTIVITIES).to(device)\n",
    "        self.gelu = torch.nn.GELU()\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def _forward(self, x: torch.Tensor):\n",
    "        x = x.reshape(x.shape[0], 1, x.shape[1])\n",
    "\n",
    "        x = self.gelu(\n",
    "            self.conv_layer(x)\n",
    "            + torch.flip(self.conv_layer_b(torch.flip(x, dims=[2])), dims=[2])\n",
    "        )\n",
    "\n",
    "        return self.relu(self.ff(x.flatten(start_dim=1)))\n",
    "\n",
    "    def weightedForward(self, x: torch.Tensor, weights: torch.Tensor):\n",
    "        self.weights = weights\n",
    "        return self._forward(x)\n",
    "\n",
    "    def weightedLoss(self, y_pred: torch.Tensor, y_true: torch.Tensor):\n",
    "        return (\n",
    "            (torch.nn.L1Loss()(y_pred.cuda(), y_true.cuda()) * self.weights.cuda())\n",
    "            .sum(dim=-1)\n",
    "            .mean()\n",
    "        )\n",
    "\n",
    "    def configure_for_lr_testing(self):\n",
    "        self.forward = self.weightedForward\n",
    "\n",
    "    def configure_for_training(self):\n",
    "        self.forward = self._forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dms_kwargs = dict(\n",
    "    latent_dim=32, n_heads=4, enc_layers=2, ff_dim=1024, attention_type=SDPAttention\n",
    ")\n",
    "model_2a3_kwargs = dict(\n",
    "    latent_dim=32, n_heads=4, enc_layers=2, ff_dim=1024, attention_type=SDPAttention\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if desired_dataset == \"dms\":\n",
    "    model = AttentionModel(**model_dms_kwargs)\n",
    "elif desired_dataset == \"2a3\":\n",
    "    model = AttentionModel(**model_2a3_kwargs)\n",
    "# model= BaselineModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.zeros((2, NUM_REACTIVITIES))\n",
    "inp[:, 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.6019e-01, 3.2697e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 4.3156e-02, 1.8531e-01, 6.4674e-01, 4.5424e-01, 5.3366e-01,\n",
       "         0.0000e+00, 0.0000e+00, 1.8670e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         3.0115e-01, 0.0000e+00, 4.4301e-01, 1.0523e-01, 0.0000e+00, 8.9247e-01,\n",
       "         2.1195e-01, 0.0000e+00, 8.4839e-01, 0.0000e+00, 4.3378e-01, 0.0000e+00,\n",
       "         4.4093e-01, 7.3127e-01, 0.0000e+00, 0.0000e+00, 7.0907e-01, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 4.0982e-01, 4.6729e-01, 0.0000e+00, 6.5064e-03,\n",
       "         4.0520e-01, 0.0000e+00, 4.6152e-01, 0.0000e+00, 0.0000e+00, 1.6781e-01,\n",
       "         0.0000e+00, 7.8822e-01, 2.9824e-01, 0.0000e+00, 0.0000e+00, 1.3537e-01,\n",
       "         0.0000e+00, 1.7659e-01, 6.8097e-01, 1.4389e-01, 0.0000e+00, 6.7114e-01,\n",
       "         0.0000e+00, 0.0000e+00, 3.2506e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9437e-01, 0.0000e+00,\n",
       "         8.9026e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.5264e-01, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 3.0489e-01, 2.5627e-01, 0.0000e+00, 4.0543e-01,\n",
       "         4.6490e-01, 4.0863e-01, 1.3285e+00, 0.0000e+00, 9.9064e-01, 0.0000e+00,\n",
       "         1.0920e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.9937e-02, 1.1128e-01,\n",
       "         4.4648e-01, 5.6556e-01, 1.0688e-01, 0.0000e+00, 2.1049e-01, 5.3008e-01,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.5270e-01,\n",
       "         0.0000e+00, 3.1148e-01, 2.7259e-01, 0.0000e+00, 4.6417e-01, 7.0000e-01,\n",
       "         5.8173e-01, 8.5561e-02, 3.9847e-03, 2.6978e-01, 0.0000e+00, 2.2604e-01,\n",
       "         0.0000e+00, 0.0000e+00, 2.9850e-01, 0.0000e+00, 9.3642e-02, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 8.6510e-02, 0.0000e+00, 1.6931e-01, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 6.0154e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 1.0169e-01, 0.0000e+00, 1.2018e-01, 0.0000e+00, 0.0000e+00,\n",
       "         6.0986e-01, 0.0000e+00, 5.3045e-01, 1.3044e-01, 6.6675e-02, 0.0000e+00,\n",
       "         4.6107e-01, 0.0000e+00, 0.0000e+00, 7.5902e-01, 5.7062e-01, 3.2281e-01,\n",
       "         0.0000e+00, 6.6332e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4330e-01,\n",
       "         3.5201e-01, 2.4194e-01, 2.6039e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 6.7017e-02, 0.0000e+00, 3.5137e-01, 0.0000e+00, 1.1910e-01,\n",
       "         1.4686e-01, 0.0000e+00, 3.7106e-01, 0.0000e+00, 3.7608e-01, 4.0930e-01,\n",
       "         5.3322e-01, 0.0000e+00, 0.0000e+00, 3.7451e-01, 1.2257e+00, 1.4013e-01,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7501e-01, 5.2251e-01, 0.0000e+00,\n",
       "         4.0755e-02, 5.6983e-02, 8.4705e-01, 5.5593e-01, 6.3815e-01, 4.0354e-01,\n",
       "         1.2268e-01, 4.1439e-01, 0.0000e+00, 2.9572e-01, 2.8911e-01, 7.3550e-02,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6620e-01, 1.0197e-01, 0.0000e+00,\n",
       "         0.0000e+00, 4.4228e-01, 0.0000e+00, 0.0000e+00, 4.0056e-01, 4.0158e-01,\n",
       "         3.3827e-01, 9.1217e-02, 0.0000e+00, 0.0000e+00, 4.7083e-02, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 2.2973e-01, 0.0000e+00, 5.2026e-01, 1.1654e-01,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4843e-02, 5.2990e-01, 1.4522e-01,\n",
       "         2.0502e-01, 9.2933e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5027e-01,\n",
       "         0.0000e+00, 3.6212e-01, 0.0000e+00, 5.6036e-02, 0.0000e+00, 0.0000e+00,\n",
       "         8.4113e-01, 0.0000e+00, 0.0000e+00, 1.0065e-01, 0.0000e+00, 3.6943e-01,\n",
       "         2.8846e-02, 3.6929e-01, 0.0000e+00, 6.4447e-01, 5.6601e-01, 0.0000e+00,\n",
       "         0.0000e+00, 7.7553e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         6.0413e-01, 1.4174e-01, 1.5897e-01, 0.0000e+00, 2.7769e-01, 0.0000e+00,\n",
       "         1.4667e-01, 0.0000e+00, 1.6588e-01, 1.2817e+00, 3.3430e-02, 1.5081e-01,\n",
       "         1.3168e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6156e-01, 4.3917e-01,\n",
       "         0.0000e+00, 0.0000e+00, 2.8991e-01, 0.0000e+00, 0.0000e+00, 1.4040e-01,\n",
       "         0.0000e+00, 3.1774e-02, 0.0000e+00, 0.0000e+00, 6.8802e-01, 0.0000e+00,\n",
       "         0.0000e+00, 4.5328e-01, 1.1378e-01, 1.5488e-01, 0.0000e+00, 0.0000e+00,\n",
       "         6.7587e-02, 0.0000e+00, 5.1818e-01, 1.1562e-01, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 1.9543e-01, 1.0371e+00, 7.3315e-01, 0.0000e+00, 7.1164e-01,\n",
       "         8.9529e-03, 0.0000e+00, 0.0000e+00, 2.9594e-02, 2.2084e-01, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 5.9833e-01, 5.9640e-01, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 7.4578e-01, 0.0000e+00, 8.6283e-02, 3.4125e-01, 1.8124e-01,\n",
       "         7.9963e-01, 3.3012e-01, 1.1887e+00, 2.9181e-01, 0.0000e+00, 0.0000e+00,\n",
       "         2.1103e-01, 0.0000e+00, 1.9374e-01, 0.0000e+00, 2.8930e-01, 2.5803e-01,\n",
       "         3.8120e-01, 0.0000e+00, 3.0180e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         4.3924e-01, 0.0000e+00, 3.4063e-02, 2.8644e-01, 0.0000e+00, 0.0000e+00,\n",
       "         3.0949e-01, 1.0581e-01, 4.3463e-01, 4.1140e-01, 0.0000e+00, 0.0000e+00,\n",
       "         1.6027e-01, 6.2240e-02, 0.0000e+00, 1.1371e+00, 4.5349e-02, 3.5083e-01,\n",
       "         4.0828e-01, 0.0000e+00, 5.1305e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         1.3620e-01, 1.2215e-02, 4.4332e-02, 0.0000e+00, 6.5695e-01, 3.6705e-02,\n",
       "         8.0497e-02, 1.7787e-01, 2.5316e-01, 0.0000e+00, 0.0000e+00, 4.2729e-01,\n",
       "         0.0000e+00, 0.0000e+00, 3.6828e-01, 0.0000e+00, 1.3803e-01, 1.4229e-01,\n",
       "         4.2937e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         3.9317e-01, 5.8603e-02, 0.0000e+00, 0.0000e+00, 5.7447e-03, 3.1725e-01,\n",
       "         3.6518e-01, 2.7342e-01, 0.0000e+00, 0.0000e+00, 6.7794e-01, 0.0000e+00,\n",
       "         2.2714e-01, 1.0357e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0531e-01,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0090e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.7515e-01, 0.0000e+00, 8.1148e-01, 0.0000e+00,\n",
       "         1.2581e-01, 0.0000e+00, 1.8386e-01, 3.8508e-01, 0.0000e+00, 2.4880e-01,\n",
       "         0.0000e+00, 0.0000e+00, 2.9519e-01, 5.6069e-03, 8.9626e-01, 3.7883e-01,\n",
       "         9.7949e-02, 0.0000e+00, 0.0000e+00, 1.2661e-01, 0.0000e+00, 0.0000e+00,\n",
       "         7.1680e-01, 0.0000e+00, 1.9898e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 8.0650e-01, 3.5753e-01, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [4.0127e-01, 3.4548e-01, 0.0000e+00, 0.0000e+00, 1.7570e-02, 0.0000e+00,\n",
       "         0.0000e+00, 1.9346e-02, 2.1602e-01, 7.2869e-01, 3.9621e-01, 4.2705e-01,\n",
       "         0.0000e+00, 0.0000e+00, 2.2741e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         4.2172e-01, 0.0000e+00, 4.5105e-01, 1.9715e-01, 0.0000e+00, 9.7570e-01,\n",
       "         1.5849e-01, 0.0000e+00, 9.4259e-01, 1.4623e-02, 4.1290e-01, 0.0000e+00,\n",
       "         3.0264e-01, 6.8939e-01, 0.0000e+00, 0.0000e+00, 7.1594e-01, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 3.9842e-01, 4.3803e-01, 0.0000e+00, 8.9231e-04,\n",
       "         4.6501e-01, 0.0000e+00, 4.4751e-01, 0.0000e+00, 0.0000e+00, 1.5255e-01,\n",
       "         0.0000e+00, 7.7134e-01, 2.9914e-01, 0.0000e+00, 0.0000e+00, 1.5458e-01,\n",
       "         0.0000e+00, 8.6861e-02, 6.6485e-01, 1.8596e-03, 0.0000e+00, 8.2664e-01,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1575e-01, 0.0000e+00,\n",
       "         9.2355e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4364e-01, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 2.2206e-01, 2.2319e-01, 0.0000e+00, 3.8841e-01,\n",
       "         5.3625e-01, 3.5000e-01, 1.3073e+00, 0.0000e+00, 9.6742e-01, 0.0000e+00,\n",
       "         1.1945e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7516e-01, 9.5183e-02,\n",
       "         3.0493e-01, 5.9377e-01, 7.7151e-02, 0.0000e+00, 1.5360e-01, 4.1487e-01,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.1656e-01,\n",
       "         1.0922e-01, 3.4507e-01, 3.8545e-01, 0.0000e+00, 4.6636e-01, 6.2320e-01,\n",
       "         4.2910e-01, 0.0000e+00, 2.2176e-02, 2.2422e-01, 0.0000e+00, 1.6716e-01,\n",
       "         0.0000e+00, 0.0000e+00, 3.0034e-01, 0.0000e+00, 3.0174e-02, 2.0246e-02,\n",
       "         0.0000e+00, 0.0000e+00, 7.1321e-02, 0.0000e+00, 1.4125e-01, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 6.7449e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 5.3707e-02, 5.7780e-02, 0.0000e+00, 0.0000e+00,\n",
       "         7.1033e-01, 0.0000e+00, 5.0083e-01, 8.0971e-02, 1.1737e-01, 0.0000e+00,\n",
       "         4.0884e-01, 0.0000e+00, 0.0000e+00, 6.5645e-01, 5.5742e-01, 3.6757e-01,\n",
       "         0.0000e+00, 7.4230e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5499e-01,\n",
       "         3.3662e-01, 1.9396e-01, 1.8463e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 1.2384e-01, 0.0000e+00, 1.9559e-01, 0.0000e+00, 9.5268e-02,\n",
       "         6.1100e-02, 0.0000e+00, 3.0939e-01, 0.0000e+00, 4.8661e-01, 4.1344e-01,\n",
       "         5.0023e-01, 1.5929e-02, 0.0000e+00, 3.8651e-01, 1.3111e+00, 1.3895e-02,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 7.6762e-02, 4.6966e-01, 0.0000e+00,\n",
       "         4.4433e-02, 1.5162e-01, 9.1955e-01, 6.0486e-01, 6.5004e-01, 3.4078e-01,\n",
       "         8.8185e-02, 5.8432e-01, 0.0000e+00, 3.9732e-01, 2.7450e-01, 5.2500e-02,\n",
       "         0.0000e+00, 3.0428e-02, 0.0000e+00, 4.5267e-01, 4.9907e-02, 0.0000e+00,\n",
       "         0.0000e+00, 4.5724e-01, 0.0000e+00, 0.0000e+00, 3.4046e-01, 4.4420e-01,\n",
       "         3.5508e-01, 1.0876e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 3.1324e-01, 0.0000e+00, 6.1106e-01, 3.3013e-02,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 8.9191e-02, 5.4140e-01, 1.9377e-01,\n",
       "         1.7218e-01, 2.0655e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 3.3097e-01, 0.0000e+00, 8.0004e-02, 0.0000e+00, 0.0000e+00,\n",
       "         8.5149e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1479e-01,\n",
       "         6.6210e-02, 3.6693e-01, 0.0000e+00, 6.3409e-01, 6.4481e-01, 0.0000e+00,\n",
       "         0.0000e+00, 8.0965e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         5.7593e-01, 1.8519e-01, 8.8791e-02, 0.0000e+00, 3.1131e-01, 0.0000e+00,\n",
       "         2.1537e-01, 0.0000e+00, 1.9302e-01, 1.3685e+00, 6.4045e-02, 1.8351e-01,\n",
       "         1.6086e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3824e-01, 5.2279e-01,\n",
       "         0.0000e+00, 0.0000e+00, 1.9981e-01, 0.0000e+00, 0.0000e+00, 1.6744e-01,\n",
       "         0.0000e+00, 3.0685e-02, 0.0000e+00, 0.0000e+00, 8.2132e-01, 0.0000e+00,\n",
       "         0.0000e+00, 4.6342e-01, 6.2452e-02, 1.9174e-01, 0.0000e+00, 0.0000e+00,\n",
       "         1.0290e-01, 0.0000e+00, 5.8280e-01, 7.8963e-02, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 1.9401e-01, 9.9754e-01, 7.7184e-01, 0.0000e+00, 7.7668e-01,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7586e-02, 2.3807e-01, 6.8414e-02,\n",
       "         0.0000e+00, 0.0000e+00, 6.2921e-01, 5.0535e-01, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 7.3766e-01, 0.0000e+00, 3.7772e-02, 2.8409e-01, 2.2523e-01,\n",
       "         7.8569e-01, 3.6954e-01, 1.1422e+00, 1.9661e-01, 0.0000e+00, 0.0000e+00,\n",
       "         2.5577e-01, 0.0000e+00, 2.8720e-01, 0.0000e+00, 2.8480e-01, 3.1850e-01,\n",
       "         3.7708e-01, 0.0000e+00, 3.4809e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         4.9663e-01, 2.3177e-02, 7.7662e-02, 1.9866e-01, 0.0000e+00, 0.0000e+00,\n",
       "         1.8892e-01, 7.5408e-02, 4.3440e-01, 3.6527e-01, 0.0000e+00, 0.0000e+00,\n",
       "         1.8865e-01, 0.0000e+00, 0.0000e+00, 1.1111e+00, 1.7600e-02, 3.2417e-01,\n",
       "         4.2709e-01, 0.0000e+00, 4.3587e-01, 1.2193e-01, 0.0000e+00, 0.0000e+00,\n",
       "         1.8445e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.3396e-01, 0.0000e+00,\n",
       "         1.1149e-01, 2.3403e-01, 3.1011e-01, 0.0000e+00, 0.0000e+00, 5.2257e-01,\n",
       "         0.0000e+00, 0.0000e+00, 2.9650e-01, 0.0000e+00, 1.2196e-01, 1.2191e-01,\n",
       "         3.7850e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         4.2043e-01, 2.0309e-01, 0.0000e+00, 0.0000e+00, 4.7227e-02, 2.5720e-01,\n",
       "         2.6582e-01, 3.0258e-01, 0.0000e+00, 0.0000e+00, 6.3541e-01, 0.0000e+00,\n",
       "         2.0344e-01, 1.3688e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.6507e-03,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.8371e-01,\n",
       "         0.0000e+00, 0.0000e+00, 2.5240e-01, 1.0112e-01, 8.9840e-01, 0.0000e+00,\n",
       "         2.0825e-01, 0.0000e+00, 8.9416e-02, 3.1632e-01, 0.0000e+00, 1.9428e-01,\n",
       "         0.0000e+00, 0.0000e+00, 3.0010e-01, 2.7285e-02, 9.3217e-01, 4.3913e-01,\n",
       "         1.4193e-01, 0.0000e+00, 0.0000e+00, 1.8986e-01, 0.0000e+00, 0.0000e+00,\n",
       "         6.2776e-01, 0.0000e+00, 1.5587e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 8.1783e-01, 3.6036e-01, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.configure_for_training()\n",
    "model(inp.cuda()).cpu().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttentionModel(\n",
      "  (conv_layer): Conv1d(1, 32, kernel_size=(31,), stride=(1,), padding=same)\n",
      "  (conv_layer_b): Conv1d(1, 32, kernel_size=(31,), stride=(1,), padding=same)\n",
      "  (pos_embedding): SinePositionalEmbedding()\n",
      "  (encoder_layers): CustomTransformerEncoder(\n",
      "    (0): CustomTransformerEncoderLayer(\n",
      "      (attention): SDPAttention(\n",
      "        (mha): MultiHeadDispatch(\n",
      "          (attention): ScaledDotProduct(\n",
      "            (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (in_proj_container): InputProjection(\n",
      "            (q_proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (k_proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (v_proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "          )\n",
      "          (resid_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "      (ff1): Linear(in_features=32, out_features=1024, bias=True)\n",
      "      (ff2): Linear(in_features=1024, out_features=32, bias=True)\n",
      "      (gelu): GELU(approximate='none')\n",
      "    )\n",
      "    (1): CustomTransformerEncoderLayer(\n",
      "      (attention): SDPAttention(\n",
      "        (mha): MultiHeadDispatch(\n",
      "          (attention): ScaledDotProduct(\n",
      "            (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (in_proj_container): InputProjection(\n",
      "            (q_proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (k_proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (v_proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "          )\n",
      "          (resid_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "      (ff1): Linear(in_features=32, out_features=1024, bias=True)\n",
      "      (ff2): Linear(in_features=1024, out_features=32, bias=True)\n",
      "      (gelu): GELU(approximate='none')\n",
      "    )\n",
      "  )\n",
      "  (head): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (final_result): Linear(in_features=457, out_features=457, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (gelu): GELU(approximate='none')\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 353147\n"
     ]
    }
   ],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(\"Total params:\", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(valley=0.02754228748381138)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.configure_for_lr_testing()\n",
    "learner.Learner(\n",
    "    fdata.DataLoaders(\n",
    "        data.DataLoader(train_dataset, batch_size=32, shuffle=True),\n",
    "        data.DataLoader(val_dataset, batch_size=32, shuffle=True),\n",
    "    ),\n",
    "    model,\n",
    "    loss_func=model.weightedLoss,\n",
    ").lr_find(stop_div=False, num_it=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.configure_for_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), 2e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "SHUFFLE = True\n",
    "\n",
    "train_dataloader = data.DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=SHUFFLE\n",
    ")\n",
    "val_dataloader = data.DataLoader(\n",
    "    val_dataset, batch_size=BATCH_SIZE, shuffle=False\n",
    ")  # no point in shuffling val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weightedL1(\n",
    "    y_pred: torch.Tensor,\n",
    "    y_true: torch.Tensor,\n",
    "    weights: torch.Tensor,\n",
    "    l1=torch.nn.L1Loss(),\n",
    "):\n",
    "    return (l1(y_pred, y_true) * weights).sum(dim=-1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:09:43.992618Z",
     "start_time": "2023-10-05T17:09:43.053099Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_batch(\n",
    "    m: torch.nn.Module, inps: torch.Tensor, outs: torch.Tensor, masks: torch.Tensor\n",
    "):\n",
    "    \"\"\"\n",
    "    Get the loss on a batch and perform the corresponding weight updates.\n",
    "    Used for training purposes\n",
    "    \"\"\"\n",
    "    optimizer.zero_grad()\n",
    "    loss = weightedL1(m(inps), outs, masks)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    # calculate gradients\n",
    "    optimizer.step()\n",
    "\n",
    "    # return mae loss\n",
    "    return loss\n",
    "\n",
    "\n",
    "def noupdate_batch(\n",
    "    m: torch.nn.Module, inps: torch.Tensor, outs: torch.Tensor, masks: torch.Tensor\n",
    "):\n",
    "    \"\"\"\n",
    "    Get the loss on a batch without performing any updates.\n",
    "    Used for validation purposes\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        loss = weightedL1(m(inps), outs, masks)\n",
    "\n",
    "    # return mae loss\n",
    "    return loss\n",
    "\n",
    "\n",
    "def masked_train(\n",
    "    m: torch.nn.Module,\n",
    "    train_dataloader: data.DataLoader,\n",
    "    val_dataloader: data.DataLoader,\n",
    "    epochs: int = 1,\n",
    "    device: str = \"cuda\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Train the given model.\n",
    "\n",
    "    Arguments:\n",
    "        - m: keras.Model - the model to train.\n",
    "        - x: np.ndarray - the numpy array of inputs.\n",
    "        - y: np.ndarray - the numpy array of outputs.\n",
    "        - masks: np.ndarray - the sample weights (1s and 0s).\n",
    "        - batch_size: int - how large the batches should be. Defaults to `32`.\n",
    "        - epochs: int - how many epochs to train for. Defaults to `1`.\n",
    "        - validation_split: float - how large the validation subset should be, in the range (0, 1]. Defaults to `0.1`.\n",
    "\n",
    "    Note - The choice of np.ndarray is purely arbitrary, and this function can be modified to use tf.Tensors\n",
    "\n",
    "    Note - shuffle code is provided in numpy, but commented out because of memory limitations that less powerful computers\n",
    "    may encounter.\n",
    "    \"\"\"\n",
    "    # shuffle\n",
    "    # shuffled_idxs = np.arange(x.shape[0])\n",
    "    # np.random.shuffle(shuffled_idxs)\n",
    "    # x = x[shuffled_idxs]\n",
    "    # y = y[shuffled_idxs]\n",
    "    # masks = masks[shuffled_idxs]\n",
    "    m = m.to(device)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"Epoch {epoch}\")\n",
    "        epoch_mae = 0.0\n",
    "\n",
    "        m = m.train()\n",
    "        for batch, tdata in enumerate(train_dataloader):\n",
    "            inps, outs, masks = tdata\n",
    "\n",
    "            inps = inps.to(device)\n",
    "            outs = outs.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            mae_loss = train_batch(m, inps, outs, masks).detach().cpu()\n",
    "\n",
    "            epoch_mae += mae_loss\n",
    "\n",
    "            # log\n",
    "            print(\n",
    "                f\"Batch {batch+1}/{len(train_dataloader)}\\t- mae loss: {mae_loss:.5f}\",\n",
    "                end=\"\\r\",\n",
    "            )\n",
    "\n",
    "            # break  # used for sanity check\n",
    "        epoch_mae /= len(train_dataloader)\n",
    "\n",
    "        # do validation\n",
    "        val_mae = 0.0\n",
    "        m = m.eval()\n",
    "        for batch, vdata in enumerate(val_dataloader):\n",
    "            inps, outs, masks = vdata\n",
    "            inps = inps.to(device)\n",
    "            outs = outs.to(device)\n",
    "            masks = masks.to(device)\n",
    "            mae_loss = noupdate_batch(m, inps, outs, masks)\n",
    "\n",
    "            val_mae += mae_loss\n",
    "        val_mae /= len(val_dataloader)\n",
    "\n",
    "        # shuffle\n",
    "        # shuffled_idxs = np.arange(x.shape[0])\n",
    "        # np.random.shuffle(shuffled_idxs)\n",
    "        # x = x[shuffled_idxs]\n",
    "        # y = y[shuffled_idxs]\n",
    "        # masks = masks[shuffled_idxs]\n",
    "\n",
    "        print()\n",
    "        print(f\"Epoch MAE: {epoch_mae:.5f}\\tVal MAE: {val_mae:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:14:00.128074Z",
     "start_time": "2023-10-05T17:09:43.998369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Batch 1596/1596\t- mae loss: 3.28079\n",
      "Epoch MAE: 2.99263\tVal MAE: 2.99168\n"
     ]
    }
   ],
   "source": [
    "# baseline gets ~ 3.64968 on dms w/ 10 epochs, ~ 4.64478 on 2a3 w/ 10 epochs\n",
    "masked_train(\n",
    "    model, train_dataloader=train_dataloader, val_dataloader=val_dataloader, epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section saves the current model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:14:00.616528Z",
     "start_time": "2023-10-05T17:14:00.119617Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"{desired_dataset}_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section of the noteboook creates a zipped csv submission file that can\n",
    "be submitted on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:14:00.624146Z",
     "start_time": "2023-10-05T17:14:00.601389Z"
    }
   },
   "outputs": [],
   "source": [
    "make_submissions = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:14:01.233216Z",
     "start_time": "2023-10-05T17:14:00.608006Z"
    }
   },
   "outputs": [],
   "source": [
    "valid = False\n",
    "\n",
    "if (\n",
    "    os.path.exists(\"2a3_model\")\n",
    "    and os.path.exists(\"dms_model\")\n",
    "    and os.path.exists(\"test_sequences.csv\")\n",
    "    and make_submissions\n",
    "):\n",
    "    model_2a3 = AttentionModel(**model_2a3_kwargs)\n",
    "    model_2a3.load_state_dict(torch.load(\"2a3_model\"))\n",
    "    model_dms = AttentionModel(**model_dms_kwargs)\n",
    "    model_dms.load_state_dict(torch.load(\"dms_model\"))\n",
    "\n",
    "    model_2a3.eval().cuda().configure_for_training()\n",
    "    model_dms.eval().cuda().configure_for_training()\n",
    "\n",
    "    valid = True\n",
    "else:\n",
    "    print(\"Not going to create submissions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:14:01.247263Z",
     "start_time": "2023-10-05T17:14:01.233464Z"
    }
   },
   "outputs": [],
   "source": [
    "def pipeline(\n",
    "    model_2a3: torch.nn.Module,\n",
    "    model_dms: torch.nn.Module,\n",
    "    input_csv: str,\n",
    "    out: str,\n",
    "    batch_size: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    Process test data and write submissions to a csv file\n",
    "\n",
    "    Arguments:\n",
    "        - model_2a3: keras.Model - the model trained on the 2a3 distribution\n",
    "        - model_dms: keras.Model - the model trained on the dms distribution\n",
    "        - input_csv: str - the name of the file that contains the test data\n",
    "        - out: str - the name of the file to write predictions to\n",
    "        - batch_size: int - how many predictions to make at a time\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "\n",
    "    # count how many lines we have in total\n",
    "    with open(input_csv) as file:\n",
    "        line = file.readline()  # ignore the header\n",
    "        # take the first line since we increment count in the loop\n",
    "        line = file.readline()\n",
    "        while line != \"\":\n",
    "            count += 1\n",
    "            line = file.readline()\n",
    "\n",
    "    # use that knowledge for a progress bar\n",
    "    with open(input_csv, \"r\") as file, open(out, \"w\") as outfile:\n",
    "        # write the header\n",
    "        outfile.write(\"id,reactivity_DMS_MaP,reactivity_2A3_MaP\\n\")\n",
    "\n",
    "        # get what index the things we need are\n",
    "        header = file.readline()\n",
    "        split_header = header.split(\",\")\n",
    "        min_idx = split_header.index(\"id_min\")\n",
    "        max_idx = split_header.index(\"id_max\")\n",
    "        sequence_idx = split_header.index(\"sequence\")\n",
    "\n",
    "        # only take the approved filtered lines\n",
    "        num_batches = count // batch_size\n",
    "        if count % batch_size != 0:\n",
    "            num_batches += 1\n",
    "        for batch in tqdm(range(num_batches)):\n",
    "            num_items = min(batch_size, count - batch * batch_size)\n",
    "\n",
    "            # initialize variables\n",
    "            inputs = np.zeros((num_items, NUM_REACTIVITIES))\n",
    "            min_seq_idxs = []\n",
    "            sequence_lengths = []\n",
    "\n",
    "            # collect the inputs\n",
    "            for i in range(num_items):\n",
    "                line = file.readline()\n",
    "                temp = line.split(\",\")\n",
    "                sequence = temp[sequence_idx]\n",
    "                max_seq_idx = int(temp[max_idx])\n",
    "                min_seq_idx = int(temp[min_idx])\n",
    "\n",
    "                # verify that everything is correct\n",
    "                assert len(sequence) + min_seq_idx - 1 == max_seq_idx\n",
    "\n",
    "                # store the data\n",
    "                inputs[i, : len(sequence)] = np.array(\n",
    "                    list(map(lambda letter: base_map[letter], sequence))\n",
    "                )\n",
    "                min_seq_idxs.append(min_seq_idx)\n",
    "                sequence_lengths.append(len(sequence))\n",
    "\n",
    "            # run inputs through the associated model\n",
    "            inputs = torch.tensor(inputs, dtype=torch.float32).cuda()\n",
    "            with torch.no_grad():\n",
    "                probs_2a3, probs_dms = model_2a3(inputs), model_dms(inputs)\n",
    "            probs_dms = probs_dms.cpu()\n",
    "            probs_2a3 = probs_2a3.cpu()\n",
    "\n",
    "            # write predictions\n",
    "            for i in range(num_items):\n",
    "                for seq_idx in range(\n",
    "                    min_seq_idxs[i], min_seq_idxs[i] + sequence_lengths[i]\n",
    "                ):\n",
    "                    outfile.write(\n",
    "                        f\"{seq_idx},{probs_dms[i, seq_idx - min_seq_idxs[i]]:.3f},{probs_2a3[i, seq_idx - min_seq_idxs[i]]:.3f}\\n\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-05T17:14:01.248308Z"
    },
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5250/5250 [1:06:52<00:00,  1.31it/s]\n"
     ]
    }
   ],
   "source": [
    "if valid:\n",
    "    pipeline(\n",
    "        model_2a3, model_dms, \"test_sequences.csv\", \"submission.csv\", batch_size=256\n",
    "    )\n",
    "else:\n",
    "    print(\"Not going to create submissions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zipping submissions. This may take a while...\n",
      "updating: submission.csv (deflated 80%)\n",
      "Done zipping submissions!\n"
     ]
    }
   ],
   "source": [
    "if valid:\n",
    "    # zip our submission into an easily-uploadable zip file\n",
    "    print(\"zipping submissions. This may take a while...\")\n",
    "    os.system(\"zip submission.csv.zip submission.csv\")\n",
    "    print(\"Done zipping submissions!\")\n",
    "else:\n",
    "    print(\"Not going to zip submissions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
