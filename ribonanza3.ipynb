{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ribonanza - Attempt 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A second approach to the [Stanford Ribonanza problem](https://www.kaggle.com/competitions/stanford-ribonanza-rna-folding/) that builds off the first and second approaches.\n",
    "\n",
    "Major differences:\n",
    "- use of pytorch instead of tensorflow\n",
    "- use of attention model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, the attention architecture scores 0.2049"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- improve model\n",
    "- experiment with other types of attention\n",
    "- use full transformer model (with decoder) (not just encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filesystem Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your project directory should look like this:\n",
    "\n",
    "- `(project directory)`\n",
    "    - `ribonanza2.ipynb`\n",
    "    - `train_data.csv`\n",
    "    - `test_data.csv` (optional)\n",
    "\n",
    "`train_data.csv` is the only file necessary for training, and it can be downloaded from the kaggle competition linked in the description.\n",
    "\n",
    "`test_data.csv` is only necessary if you intend to make and submit predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependency Seetup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to install pip packages:\n",
    "```sh\n",
    "pip install torch numpy seaborn xformers arnie datasets\n",
    "```\n",
    "Need to install conda packages for eternafold:\n",
    "```sh\n",
    "conda install -c conda-forge \"libgcc-ng>=12\" \"libstdcxx-ng>=12\"\n",
    "conda install -c bioconda eternafold\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset\n",
    "import os\n",
    "\n",
    "# for visualization\n",
    "import seaborn\n",
    "\n",
    "# typing hints\n",
    "from typing import List\n",
    "from collections.abc import Callable\n",
    "\n",
    "# used for better attention mechanisms\n",
    "import xformers.components.positional_embedding as embeddings\n",
    "import xformers.ops as xops\n",
    "import xformers.components.attention as attentions\n",
    "import xformers.components.attention.utils as att_utils\n",
    "import xformers.components as components\n",
    "\n",
    "# used for bpps\n",
    "from arnie.bpps import bpps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "# according to kaggle, this is the maximum # of reactivites to be used\n",
    "NUM_REACTIVITIES = 457\n",
    "\n",
    "# there are 4 different bases (AUCG)\n",
    "NUM_BASES = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\"  # if no gpu available, use cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(out: str, key: str, value: str, file_name: str, force: bool):\n",
    "    \"\"\"\n",
    "    Filters a file to only take datapoints\n",
    "    whose values of `key` are `value`.\n",
    "\n",
    "    Parameters:\n",
    "        - out: str - the name of the file that will store the filtered datapoints\n",
    "        - key: str - the name of the key to look at\n",
    "        - value: str - the value that the key should have\n",
    "        - file_name: str - the name of the file that contains all the datapoints.\n",
    "        - force: bool - whether or not to force re-processing of the data (if False and `out` already exists, no work will be done)\n",
    "    \"\"\"\n",
    "    if os.path.exists(out) and not force:\n",
    "        print(\"File already exists, not doing any work\")\n",
    "        return\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    # count how many lines we have in total\n",
    "    with open(file_name) as file:\n",
    "        line = file.readline()  # ignore the header\n",
    "        line = (\n",
    "            file.readline()\n",
    "        )  # take the first line since we increment count in the loop\n",
    "        while line != \"\":\n",
    "            count += 1\n",
    "            line = file.readline()\n",
    "\n",
    "    # use that knowledge for a progress bar\n",
    "    with open(file_name, \"r\") as file, open(out, \"w\") as outfile:\n",
    "        # write the header\n",
    "        header = file.readline()\n",
    "        outfile.write(header)\n",
    "\n",
    "        # get what index the SN_filter is\n",
    "        SN_idx = header.split(\",\").index(key)\n",
    "\n",
    "        # only take the approved filtered lines\n",
    "        for _ in tqdm(range(count)):\n",
    "            line = file.readline()\n",
    "            temp = line.split(\",\")\n",
    "            if temp[SN_idx] == value:\n",
    "                outfile.write(line)\n",
    "\n",
    "\n",
    "def filter_train_data(force: bool = False):\n",
    "    \"\"\"\n",
    "    Filters the immense train_data.csv to only take datapoints\n",
    "    whose SN_filter (Signal to Noise filter) is 1. In other words,\n",
    "    we only take good reads. These filtered datapoints are then\n",
    "    written to the file provided\n",
    "\n",
    "    Parameters:\n",
    "        - force: bool - whether or not to force re-processing of the data (if False and `out` already exists, no work will be done)\n",
    "    \"\"\"\n",
    "    filter_data(\"train_data_filtered.csv\", \"SN_filter\", \"1\", \"train_data.csv\", force)\n",
    "\n",
    "\n",
    "def filter_2A3(force: bool = False):\n",
    "    \"\"\"\n",
    "    Only take the 2A3 points\n",
    "\n",
    "    Parameters:\n",
    "        - force: bool - whether or not to force re-processing of the data (if False and `out` already exists, no work will be done)\n",
    "    \"\"\"\n",
    "    filter_data(\n",
    "        \"train_data_2a3.csv\",\n",
    "        \"experiment_type\",\n",
    "        \"2A3_MaP\",\n",
    "        \"train_data_filtered.csv\",\n",
    "        force,\n",
    "    )\n",
    "\n",
    "\n",
    "def filter_DMS(force: bool = False):\n",
    "    \"\"\"\n",
    "    Only take the DMS points\n",
    "\n",
    "    Parameters:\n",
    "        - force: bool - whether or not to force re-processing of the data (if False and `out` already exists, no work will be done)\n",
    "    \"\"\"\n",
    "    filter_data(\n",
    "        \"train_data_dms.csv\",\n",
    "        \"experiment_type\",\n",
    "        \"DMS_MaP\",\n",
    "        \"train_data_filtered.csv\",\n",
    "        force,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists, not doing any work\n"
     ]
    }
   ],
   "source": [
    "# filter our data\n",
    "filter_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists, not doing any work\n"
     ]
    }
   ],
   "source": [
    "# take the 2a3 points\n",
    "filter_2A3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists, not doing any work\n"
     ]
    }
   ],
   "source": [
    "# take the dms points\n",
    "filter_DMS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Data to Inputs and Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode inputs as\n",
    "# A : 1\n",
    "# U : 2\n",
    "# C : 3\n",
    "# G : 4\n",
    "base_map = {\n",
    "    \"A\": 1,\n",
    "    \"U\": 2,\n",
    "    \"C\": 3,\n",
    "    \"G\": 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(row):\n",
    "    \"\"\"\n",
    "    Convert a row containing all csv columns in the original dataset\n",
    "    to a row containing only the columns:\n",
    "    - inputs\n",
    "    - outputs\n",
    "    - bpp\n",
    "    - output_masks\n",
    "    - reactivity_error\n",
    "    - bool_output_masks\n",
    "    \"\"\"\n",
    "    # initialize arrays\n",
    "    # note that we assume everything is masked until told otherwise\n",
    "    inputs = np.zeros((NUM_REACTIVITIES,), dtype=np.float32)\n",
    "    bpp = np.zeros((NUM_REACTIVITIES,), dtype=np.float32)\n",
    "    output_masks = np.ones((NUM_REACTIVITIES,), dtype=np.bool_)\n",
    "    reactivity_errors = np.zeros((NUM_REACTIVITIES,), dtype=np.float32)\n",
    "    reactivities = np.zeros((NUM_REACTIVITIES,), dtype=np.float32)\n",
    "\n",
    "    seq_len = len(row[\"sequence\"])\n",
    "\n",
    "    # encode the bases\n",
    "    inputs[:seq_len] = np.array(\n",
    "        list(map(lambda letter: base_map[letter], row[\"sequence\"]))\n",
    "    )\n",
    "\n",
    "    # get the probability that any of those bases are paired\n",
    "    bpp[:seq_len] = np.max(bpps(row[\"sequence\"], package=\"eternafold\"), axis=-1)\n",
    "\n",
    "    # get the reactivities and their errors\n",
    "    reactivities[:seq_len] = np.array(\n",
    "        list(\n",
    "            map(\n",
    "                lambda seq_idx: np.float32(\n",
    "                    row[\"reactivity_\" + str(seq_idx + 1).rjust(4, \"0\")]\n",
    "                ),\n",
    "                range(seq_len),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    reactivity_errors[:seq_len] = np.array(\n",
    "        list(\n",
    "            map(\n",
    "                lambda seq_idx: np.float32(\n",
    "                    row[\"reactivity_error_\" + str(seq_idx + 1).rjust(4, \"0\")]\n",
    "                ),\n",
    "                range(seq_len),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # replace reactivity error nans with 0s (assume no error)\n",
    "    reactivity_errors = np.where(np.isnan(reactivity_errors), 0.0, reactivity_errors)\n",
    "\n",
    "    # get where all the reactivities are nan\n",
    "    nan_locats = np.isnan(reactivities)\n",
    "\n",
    "    # where it is nan, store True, else False\n",
    "    output_masks[:seq_len] = nan_locats[:seq_len]\n",
    "\n",
    "    # where it is not nan, store the reactivity and error, else 0\n",
    "    reactivities[:seq_len] = np.where(\n",
    "        nan_locats[:seq_len] == False, reactivities[:seq_len], 0.0\n",
    "    )\n",
    "    reactivity_errors[:seq_len] = np.where(\n",
    "        nan_locats[:seq_len] == False, reactivity_errors[:seq_len], 0.0\n",
    "    )\n",
    "\n",
    "    # store the values\n",
    "    row = {}\n",
    "    row[\"inputs\"] = inputs\n",
    "    row[\"bpp\"] = bpp\n",
    "    row[\"outputs\"] = np.clip(reactivities, 0, 1)\n",
    "    row[\"output_masks\"] = np.clip(\n",
    "        np.where(output_masks, 0.0, 1.0) - np.abs(reactivity_errors), 0, 1\n",
    "    )\n",
    "    row[\"bool_output_masks\"] = output_masks\n",
    "    row[\"reactivity_errors\"] = np.abs(reactivity_errors)\n",
    "\n",
    "    return row\n",
    "\n",
    "\n",
    "def process_data_test(row):\n",
    "    \"\"\"\n",
    "    Almost the same as process_data, except it only takes inputs and bpp\n",
    "    \"\"\"\n",
    "    # initialize arrays\n",
    "    # note that we assume everything is masked until told otherwise\n",
    "    inputs = np.zeros((NUM_REACTIVITIES,), dtype=np.float32)\n",
    "    bpp = np.zeros((NUM_REACTIVITIES,), dtype=np.float32)\n",
    "\n",
    "    seq_len = len(row[\"sequence\"])\n",
    "\n",
    "    # encode the bases\n",
    "    inputs[:seq_len] = np.array(\n",
    "        list(map(lambda letter: base_map[letter], row[\"sequence\"]))\n",
    "    )\n",
    "\n",
    "    # get the probability that any of those bases are paired\n",
    "    bpp[:seq_len] = np.max(bpps(row[\"sequence\"], package=\"eternafold\"), axis=-1)\n",
    "\n",
    "    row[\"inputs\"] = inputs\n",
    "    row[\"bpp\"] = bpp\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_csv(\n",
    "    out: str,\n",
    "    file_name: str,\n",
    "    n_proc: int = 12,\n",
    "    map_fn: Callable = process_data,\n",
    "    extra_cols_to_keep: List[str] = [],\n",
    "):\n",
    "    \"\"\"\n",
    "    Preprocess the csv and save the preprocessed data as a dataset\n",
    "    that can be loaded via datasets.Dataset.load_from_file\n",
    "\n",
    "    The dataset contains the following items:\n",
    "        - bool_output_masks: Tensor(dtype=torch.bool) - the output masks.\n",
    "            If True, then that item should NOT be used to calculate loss.\n",
    "            If False, then that item should be used to calculate loss\n",
    "        - reactivity_errors: Tensor(dtype=torch.float32) - the reactivity errors\n",
    "        - output_masks: Tensor(dtype=torch.float32) - the elementwise weights to multiply the loss by to properly\n",
    "            account for masked items and reactivity errors\n",
    "        - inputs: tensor(dtype=torch.float32) - the input sequence, specifically of shape (None, NUM_REACTIVITIES)\n",
    "        - bpp: tensor(dtype=torch.float32)\n",
    "        - outputs: tensor(dtype=torch.float32) - the expected reactivities. Note that a simple MAE or MSE loss will not\n",
    "            suffice for training models on this dataset. Please use the output_masks tensor as well.\n",
    "\n",
    "    Parameters:\n",
    "        - out: str - the name of the file to save the arrays to\n",
    "        - file_name: str - the name of the input csv file\n",
    "        - n_proc: int - the number of processes to use while processing data\n",
    "        - map_fn: Callable - the function to apply to all dataset rows\n",
    "        - extra_cols_to_keep: List[str] - the names of any extra columns to keep in the dataset\n",
    "    \"\"\"\n",
    "    if os.path.exists(out):\n",
    "        print(\n",
    "            \"File already exists, not doing any work.\\n\"\n",
    "            + \"To force re-preprocessing, delete the dataset directory and restart the kernel.\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    names_to_keep = [\n",
    "        \"reactivity_errors\",\n",
    "        \"bool_output_masks\",\n",
    "        \"output_masks\",\n",
    "        \"inputs\",\n",
    "        \"outputs\",\n",
    "        \"bpp\",\n",
    "    ] + extra_cols_to_keep\n",
    "\n",
    "    # load dataset and map it to our preprocess function\n",
    "    ds = Dataset.from_csv(file_name).map(map_fn, num_proc=n_proc)\n",
    "\n",
    "    # drop excess columns and save to disk\n",
    "    ds.remove_columns(\n",
    "        list(filter(lambda c: c not in names_to_keep, ds.column_names))\n",
    "    ).save_to_disk(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists, not doing any work.\n",
      "To force re-preprocessing, delete the dataset directory and restart the kernel.\n"
     ]
    }
   ],
   "source": [
    "preprocess_csv(\"train_data_2a3_preprocessed\", \"train_data_2a3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists, not doing any work.\n",
      "To force re-preprocessing, delete the dataset directory and restart the kernel.\n"
     ]
    }
   ],
   "source": [
    "preprocess_csv(\"train_data_dms_preprocessed\", \"train_data_dms.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists, not doing any work.\n",
      "To force re-preprocessing, delete the dataset directory and restart the kernel.\n"
     ]
    }
   ],
   "source": [
    "preprocess_csv(\n",
    "    \"test_data_preprocessed\",\n",
    "    \"test_sequences.csv\",\n",
    "    map_fn=process_data_test,\n",
    "    extra_cols_to_keep=[\"id_min\", \"id_max\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the desired dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:09:33.551791Z",
     "start_time": "2023-10-05T17:09:33.535197Z"
    }
   },
   "outputs": [],
   "source": [
    "desired_dataset = \"2a3\"  # either \"2a3\" or \"dms\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['inputs', 'bpp', 'outputs', 'output_masks', 'bool_output_masks', 'reactivity_errors'],\n",
       "    num_rows: 210992\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.load_from_disk(\n",
    "    f\"train_data_{desired_dataset}_preprocessed\"\n",
    ").with_format(\"torch\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set is len 189892 and val dataset is len 21100\n"
     ]
    }
   ],
   "source": [
    "columns = [\"inputs\", \"outputs\", \"output_masks\", \"bpp\"]\n",
    "split = (\n",
    "    dataset.train_test_split(test_size=0.1).with_format(\"torch\").select_columns(columns)\n",
    ")\n",
    "train_dataset = split[\"train\"]\n",
    "val_dataset = split[\"test\"]\n",
    "\n",
    "print(\n",
    "    \"train set is len\", len(train_dataset), \"and val dataset is len\", len(val_dataset)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the dataset preprocessed, we can visualize what the distribution looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:09:42.844615Z",
     "start_time": "2023-10-05T17:09:42.843236Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(*args):\n",
    "    \"\"\"\n",
    "    Gets the product of all arguments passed to it\n",
    "    \"\"\"\n",
    "    prod = 1\n",
    "    for item in args:\n",
    "        prod *= item\n",
    "    return prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 0.21671% of the data\n"
     ]
    }
   ],
   "source": [
    "if visualize:\n",
    "    # select all the reactivities that are valid (that shouldn't be masked)\n",
    "    visualized_items = torch.masked_select(\n",
    "        dataset[\"outputs\"], dataset[\"bool_output_masks\"] == False\n",
    "    ).numpy()\n",
    "\n",
    "    # sanity check that we didn't take all the items\n",
    "    print(\n",
    "        f\"took {visualized_items.shape[0] / multiply(*dataset['outputs'].shape):.5f}% of the data\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:09:42.851272Z",
     "start_time": "2023-10-05T17:09:42.849526Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if visualize:\n",
    "    seaborn.histplot(visualized_items, binwidth=0.1)\n",
    "else:\n",
    "    print(\"Not visualizing. Set `visualize` to `True` to visualize data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To model our distribution, we have two models:\n",
    "- an AttentionModel that uses attention layers\n",
    "- a BaselineModel that we compare against that uses only a couple convolution layers and a Linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryEfficientSelfAttention(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, latent_dim: int, n_heads: int, dropout: float, *args, **kwargs\n",
    "    ) -> None:\n",
    "        super(MemoryEfficientSelfAttention, self).__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.latent_dim = latent_dim\n",
    "        self.dropout = dropout\n",
    "\n",
    "        assert latent_dim % n_heads == 0\n",
    "\n",
    "    def forward(self, x: torch.Tensor, **kwargs):\n",
    "        # B, Seq Len, embedding -> B, Seq Len, Heads, Embedding per head\n",
    "        x = x.reshape(x.shape[0], x.shape[1], self.n_heads, x.shape[2] // self.n_heads)\n",
    "        x = xops.memory_efficient_attention(x, x, x, p=self.dropout)\n",
    "        x = x.reshape(x.shape[0], x.shape[1], -1)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class SDPAttention(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        latent_dim: int,\n",
    "        n_heads: int,\n",
    "        dropout: float,\n",
    "        device: str,\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        super(SDPAttention, self).__init__()\n",
    "        self.mha = components.MultiHeadDispatch(\n",
    "            latent_dim,\n",
    "            num_heads=n_heads,\n",
    "            attention=attentions.ScaledDotProduct(dropout=dropout),\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, attention_mask: torch.Tensor):\n",
    "        return self.mha(x, att_mask=attention_mask)\n",
    "\n",
    "\n",
    "class SlidingWindowAttention(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        latent_dim: int,\n",
    "        n_heads: int,\n",
    "        dropout: float,\n",
    "        device: str,\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        super(SlidingWindowAttention, self).__init__()\n",
    "        self.mha = components.MultiHeadDispatch(\n",
    "            latent_dim,\n",
    "            n_heads,\n",
    "            attentions.LocalAttention(\n",
    "                dropout=dropout, window_size=kwargs[\"context_window\"]\n",
    "            ),\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, **kwargs):\n",
    "        return self.mha(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTransformerEncoderLayer(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        attention_type: torch.nn.Module,\n",
    "        latent_dim: int,\n",
    "        ff_dim: int,\n",
    "        n_heads: int,\n",
    "        dropout: float = 0.1,\n",
    "        device: str = \"cuda\",\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        super(CustomTransformerEncoderLayer, self).__init__()\n",
    "        self.attention = attention_type(\n",
    "            latent_dim=latent_dim,\n",
    "            n_heads=n_heads,\n",
    "            dropout=dropout,\n",
    "            device=device,\n",
    "            **kwargs\n",
    "        )\n",
    "        self.layer_norm = torch.nn.LayerNorm(latent_dim).to(device)\n",
    "\n",
    "        self.ff1 = torch.nn.Linear(latent_dim, ff_dim).to(device)\n",
    "        self.ff2 = torch.nn.Linear(ff_dim, latent_dim).to(device)\n",
    "        self.gelu = torch.nn.GELU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor, attention_mask: torch.Tensor):\n",
    "        # MHA, add, norm\n",
    "        x = self.layer_norm(self.attention(x, attention_mask=attention_mask) + x)\n",
    "\n",
    "        # ff, add, norm\n",
    "        x = self.layer_norm(self.gelu(self.ff2(self.gelu(self.ff1(x)))) + x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class CustomTransformerEncoder(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        attention_type: torch.nn.Module,\n",
    "        n_layers: int,\n",
    "        latent_dim: int,\n",
    "        ff_dim: int,\n",
    "        n_heads: int,\n",
    "        dropout: float = 0.1,\n",
    "        device: str = \"cuda\",\n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        super(CustomTransformerEncoder, self).__init__()\n",
    "        for i in range(n_layers):\n",
    "            self.add_module(\n",
    "                str(i),\n",
    "                CustomTransformerEncoderLayer(\n",
    "                    attention_type=attention_type,\n",
    "                    latent_dim=latent_dim,\n",
    "                    ff_dim=ff_dim,\n",
    "                    n_heads=n_heads,\n",
    "                    dropout=dropout,\n",
    "                    device=device,\n",
    "                    **kwargs\n",
    "                ),\n",
    "            )\n",
    "\n",
    "    def forward(self, x: torch.Tensor, attention_mask: torch.Tensor):\n",
    "        for module in self._modules.values():\n",
    "            x = module(x, attention_mask=attention_mask)\n",
    "        return x\n",
    "\n",
    "\n",
    "class AttentionModel(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        attention_type: torch.nn.Module,\n",
    "        context_window: int = 31,\n",
    "        latent_dim: int = 128,\n",
    "        ff_dim: int = 1024,\n",
    "        n_heads: int = 2,\n",
    "        enc_layers: int = 1,\n",
    "        device: str = \"cuda\",\n",
    "    ) -> None:\n",
    "        super(AttentionModel, self).__init__()\n",
    "\n",
    "        # data\n",
    "        self.n_heads = n_heads\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        # prepatory conv layers\n",
    "        self.conv_layer = torch.nn.Conv1d(\n",
    "            2, out_channels=latent_dim, kernel_size=context_window, padding=\"same\"\n",
    "        ).to(device)\n",
    "        self.conv_layer_b = torch.nn.Conv1d(\n",
    "            2, out_channels=latent_dim, kernel_size=context_window, padding=\"same\"\n",
    "        ).to(device)\n",
    "\n",
    "        # positional embedding and encoder layers\n",
    "        self.pos_embedding = embeddings.SinePositionalEmbedding(latent_dim).to(device)\n",
    "        self.encoder_layers = CustomTransformerEncoder(\n",
    "            latent_dim=latent_dim,\n",
    "            ff_dim=ff_dim,\n",
    "            n_heads=n_heads,\n",
    "            device=device,\n",
    "            attention_type=attention_type,\n",
    "            n_layers=enc_layers,\n",
    "            context_window=context_window,\n",
    "        )\n",
    "\n",
    "        # output head\n",
    "        self.head = torch.nn.Linear(latent_dim, 1).to(device)\n",
    "        self.final_result = torch.nn.Linear(NUM_REACTIVITIES, NUM_REACTIVITIES).to(\n",
    "            device\n",
    "        )\n",
    "\n",
    "        # activations\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.gelu = torch.nn.GELU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        mask = att_utils.maybe_merge_masks(\n",
    "            att_mask=None,\n",
    "            key_padding_mask=(x != 0).any(dim=-1),\n",
    "            batch_size=x.shape[0],\n",
    "            num_heads=self.n_heads,\n",
    "            src_len=x.shape[1],\n",
    "        )\n",
    "        x = x.reshape(x.shape[0], -1, x.shape[1])\n",
    "        # print(x.shape)\n",
    "\n",
    "        x = self.gelu(\n",
    "            self.conv_layer(x)\n",
    "            + torch.flip(self.conv_layer_b(torch.flip(x, dims=[2])), dims=[2])\n",
    "        )\n",
    "        # print(x.shape)\n",
    "\n",
    "        x = x.permute((0, 2, 1)).contiguous()\n",
    "\n",
    "        x = self.pos_embedding(x)\n",
    "        x = self.encoder_layers(x, attention_mask=mask)\n",
    "\n",
    "        x = self.relu(self.final_result(self.gelu(self.head(x).flatten(start_dim=1))))\n",
    "        # print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineModel(torch.nn.Module):\n",
    "    def __init__(self, context_window: int = 31, device: str = \"cuda\"):\n",
    "        super(BaselineModel, self).__init__()\n",
    "        self.preLayer = torch.nn.Linear(2, 2).to(device)\n",
    "        self.conv_layer = torch.nn.Conv1d(2, 2, context_window, padding=\"same\").to(\n",
    "            device\n",
    "        )\n",
    "        self.conv_layer_b = torch.nn.Conv1d(2, 2, context_window, padding=\"same\").to(\n",
    "            device\n",
    "        )\n",
    "        self.ff = torch.nn.Linear(NUM_REACTIVITIES * 2, NUM_REACTIVITIES).to(device)\n",
    "        self.gelu = torch.nn.GELU()\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.gelu(self.preLayer(x))\n",
    "        x = x.reshape(x.shape[0], -1, x.shape[1])\n",
    "\n",
    "        x = self.gelu(\n",
    "            self.conv_layer(x)\n",
    "            + torch.flip(self.conv_layer_b(torch.flip(x, dims=[2])), dims=[2])\n",
    "        )\n",
    "\n",
    "        return self.relu(self.ff(x.flatten(start_dim=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dms_kwargs = dict(\n",
    "    latent_dim=16, n_heads=2, enc_layers=1, ff_dim=512, attention_type=SDPAttention\n",
    ")\n",
    "model_2a3_kwargs = dict(\n",
    "    latent_dim=16, n_heads=2, enc_layers=1, ff_dim=512, attention_type=SDPAttention\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_baseline = True\n",
    "\n",
    "# select the model\n",
    "if use_baseline:\n",
    "    model = BaselineModel()\n",
    "elif desired_dataset == \"dms\":\n",
    "    model = AttentionModel(**model_dms_kwargs)\n",
    "elif desired_dataset == \"2a3\":\n",
    "    model = AttentionModel(**model_2a3_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load old weights if possible\n",
    "if os.path.exists(f\"{desired_dataset}_model\"):\n",
    "    try:\n",
    "        model.load_state_dict( torch.load(f\"{desired_dataset}_model\"))\n",
    "        print(\"loaded previous weights\")\n",
    "    except Exception as e:\n",
    "        print(\"not loading previous weights because\", e)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0623, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0352, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0762,\n",
       "         0.0000, 0.2149, 0.1514, 0.1430, 0.2965, 0.3544, 0.1241, 0.1007, 0.1970,\n",
       "         0.1964, 0.3502, 0.3582, 0.1733, 0.0899, 0.2445, 0.1897, 0.1143, 0.0987,\n",
       "         0.0872, 0.0965, 0.0000, 0.0000, 0.0000, 0.0030, 0.0000, 0.1981, 0.0881,\n",
       "         0.1302, 0.0469, 0.1013, 0.2789, 0.1499, 0.1239, 0.0213, 0.1044, 0.0307,\n",
       "         0.1926, 0.1326, 0.0308, 0.2311, 0.0000, 0.0000, 0.0227, 0.0000, 0.0856,\n",
       "         0.0000, 0.0320, 0.0659, 0.1245, 0.2019, 0.2541, 0.1233, 0.2132, 0.2556,\n",
       "         0.1207, 0.2677, 0.2141, 0.2567, 0.4317, 0.2617, 0.1836, 0.1618, 0.1791,\n",
       "         0.2635, 0.2979, 0.3243, 0.2830, 0.2639, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0900, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0195, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0163, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0111, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0623, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0352, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0762,\n",
       "         0.0000, 0.2149, 0.1514, 0.1430, 0.2965, 0.3544, 0.1241, 0.1007, 0.1970,\n",
       "         0.1964, 0.3502, 0.3582, 0.1733, 0.0899, 0.2445, 0.1897, 0.1143, 0.0987,\n",
       "         0.0872, 0.0965, 0.0000, 0.0000, 0.0000, 0.0030, 0.0000, 0.1981, 0.0881,\n",
       "         0.1302, 0.0469, 0.1013, 0.2789, 0.1499, 0.1239, 0.0213, 0.1044, 0.0307,\n",
       "         0.1926, 0.1326, 0.0308, 0.2311, 0.0000, 0.0000, 0.0227, 0.0000, 0.0856,\n",
       "         0.0000, 0.0320, 0.0659, 0.1245, 0.2019, 0.2541, 0.1233, 0.2132, 0.2556,\n",
       "         0.1207, 0.2677, 0.2141, 0.2567, 0.4317, 0.2617, 0.1836, 0.1618, 0.1791,\n",
       "         0.2635, 0.2979, 0.3243, 0.2830, 0.2639, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0900, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0195, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0163, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0111, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure that calling the model works as expected\n",
    "inp = torch.zeros((2, NUM_REACTIVITIES, 2))\n",
    "inp[:, 0, :] = 1\n",
    "\n",
    "model(inp.cuda()).cpu().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaselineModel(\n",
      "  (preLayer): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (conv_layer): Conv1d(2, 2, kernel_size=(31,), stride=(1,), padding=same)\n",
      "  (conv_layer_b): Conv1d(2, 2, kernel_size=(31,), stride=(1,), padding=same)\n",
      "  (ff): Linear(in_features=914, out_features=457, bias=True)\n",
      "  (gelu): GELU(approximate='none')\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 418413\n"
     ]
    }
   ],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(\"Total params:\", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024\n",
    "SHUFFLE = True\n",
    "\n",
    "# create dataloaders\n",
    "train_dataloader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=SHUFFLE)\n",
    "# no point in shuffling validation set\n",
    "val_dataloader = data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weightedL1(\n",
    "    y_pred: torch.Tensor,\n",
    "    y_true: torch.Tensor,\n",
    "    weights: torch.Tensor,\n",
    "    l1=torch.nn.L1Loss(),\n",
    "):\n",
    "    \"\"\"\n",
    "    This is our custom loss function that takes into account sample weights\n",
    "    \"\"\"\n",
    "    return (l1(y_pred, y_true) * weights).sum(dim=-1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:09:43.992618Z",
     "start_time": "2023-10-05T17:09:43.053099Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_batch(\n",
    "    m: torch.nn.Module, inps: torch.Tensor, outs: torch.Tensor, masks: torch.Tensor\n",
    "):\n",
    "    \"\"\"\n",
    "    Get the loss on a batch and perform the corresponding weight updates.\n",
    "    Used for training purposes\n",
    "    \"\"\"\n",
    "    optimizer.zero_grad()\n",
    "    loss = weightedL1(m(inps), outs, masks)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    # calculate gradients\n",
    "    optimizer.step()\n",
    "\n",
    "    # return mae loss\n",
    "    return loss\n",
    "\n",
    "\n",
    "def noupdate_batch(\n",
    "    m: torch.nn.Module, inps: torch.Tensor, outs: torch.Tensor, masks: torch.Tensor\n",
    "):\n",
    "    \"\"\"\n",
    "    Get the loss on a batch without performing any updates.\n",
    "    Used for validation purposes\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        loss = weightedL1(m(inps), outs, masks)\n",
    "\n",
    "    # return mae loss\n",
    "    return loss\n",
    "\n",
    "\n",
    "def masked_train(\n",
    "    m: torch.nn.Module,\n",
    "    train_dataloader: data.DataLoader,\n",
    "    val_dataloader: data.DataLoader,\n",
    "    epochs: int = 1,\n",
    "    device: str = DEVICE,\n",
    "):\n",
    "    \"\"\"\n",
    "    Train the given model.\n",
    "\n",
    "    Arguments:\n",
    "        - m: torch.nn.Module - the model to train.\n",
    "        - train_dataloader: data.Dataloader - the dataloader that provides the batched training data\n",
    "        - val_dataloader: data.Dataloader - the dataloader that provides the batched validation data\n",
    "        - epochs: int - how many epochs to train for. Defaults to `1`.\n",
    "        - device: str - the device to train on, defaults to `DEVICE`\n",
    "    \"\"\"\n",
    "    m = m.to(device)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"Epoch {epoch}\")\n",
    "        epoch_mae = 0.0\n",
    "\n",
    "        m = m.train()\n",
    "        for batch, tdata in enumerate(train_dataloader):\n",
    "            inps = torch.stack([tdata[\"inputs\"], tdata[\"bpp\"]], dim=-1)\n",
    "            outs = tdata[\"outputs\"]\n",
    "            masks = tdata[\"output_masks\"]\n",
    "\n",
    "            inps = inps.to(device)\n",
    "            outs = outs.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            mae_loss = train_batch(m, inps, outs, masks).detach().cpu()\n",
    "\n",
    "            epoch_mae += mae_loss\n",
    "\n",
    "            # log\n",
    "            print(\n",
    "                f\"Batch {batch+1}/{len(train_dataloader)}\\t- mae loss: {mae_loss:.5f}\",\n",
    "                end=\"\\r\",\n",
    "            )\n",
    "\n",
    "            # break  # used for sanity check\n",
    "        epoch_mae /= batch + 1\n",
    "\n",
    "        # do validation\n",
    "        val_mae = 0.0\n",
    "        m = m.eval()\n",
    "        for batch, vdata in enumerate(val_dataloader):\n",
    "            inps = torch.stack([vdata[\"inputs\"], vdata[\"bpp\"]], dim=-1)\n",
    "            outs = vdata[\"outputs\"]\n",
    "            masks = vdata[\"output_masks\"]\n",
    "\n",
    "            inps = inps.to(device)\n",
    "            outs = outs.to(device)\n",
    "            masks = masks.to(device)\n",
    "            mae_loss = noupdate_batch(m, inps, outs, masks)\n",
    "\n",
    "            val_mae += mae_loss\n",
    "        val_mae /= len(val_dataloader)\n",
    "\n",
    "        print()\n",
    "        print(f\"Epoch MAE: {epoch_mae:.5f}\\tVal MAE: {val_mae:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:14:00.128074Z",
     "start_time": "2023-10-05T17:09:43.998369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 186/186\t- mae loss: 3.88938\n",
      "Epoch MAE: 3.89894\tVal MAE: 3.90925\n",
      "Epoch 2\n",
      "Batch 186/186\t- mae loss: 3.89901\n",
      "Epoch MAE: 3.88558\tVal MAE: 3.89925\n",
      "Epoch 3\n",
      "Batch 186/186\t- mae loss: 3.84362\n",
      "Epoch MAE: 3.87768\tVal MAE: 3.89741\n",
      "Epoch 4\n",
      "Batch 186/186\t- mae loss: 3.85658\n",
      "Epoch MAE: 3.87446\tVal MAE: 3.89622\n",
      "Epoch 5\n",
      "Batch 186/186\t- mae loss: 3.92030\n",
      "Epoch MAE: 3.87154\tVal MAE: 3.89395\n",
      "Epoch 6\n",
      "Batch 186/186\t- mae loss: 3.83593\n",
      "Epoch MAE: 3.86820\tVal MAE: 3.89068\n",
      "Epoch 7\n",
      "Batch 186/186\t- mae loss: 3.87538\n",
      "Epoch MAE: 3.86560\tVal MAE: 3.88949\n",
      "Epoch 8\n",
      "Batch 186/186\t- mae loss: 3.86100\n",
      "Epoch MAE: 3.86290\tVal MAE: 3.88726\n",
      "Epoch 9\n",
      "Batch 186/186\t- mae loss: 3.79003\n",
      "Epoch MAE: 3.85874\tVal MAE: 3.88503\n",
      "Epoch 10\n",
      "Batch 186/186\t- mae loss: 3.87778\n",
      "Epoch MAE: 3.85711\tVal MAE: 3.88047\n",
      "Epoch 11\n",
      "Batch 186/186\t- mae loss: 3.89546\n",
      "Epoch MAE: 3.85318\tVal MAE: 3.88086\n",
      "Epoch 12\n",
      "Batch 186/186\t- mae loss: 3.95224\n",
      "Epoch MAE: 3.85126\tVal MAE: 3.87670\n",
      "Epoch 13\n",
      "Batch 186/186\t- mae loss: 3.85088\n",
      "Epoch MAE: 3.84796\tVal MAE: 3.87478\n",
      "Epoch 14\n",
      "Batch 186/186\t- mae loss: 3.98655\n",
      "Epoch MAE: 3.84528\tVal MAE: 3.87070\n",
      "Epoch 15\n",
      "Batch 186/186\t- mae loss: 3.89386\n",
      "Epoch MAE: 3.84206\tVal MAE: 3.86812\n",
      "Epoch 16\n",
      "Batch 186/186\t- mae loss: 3.93604\n",
      "Epoch MAE: 3.83865\tVal MAE: 3.86370\n",
      "Epoch 17\n",
      "Batch 186/186\t- mae loss: 3.92549\n",
      "Epoch MAE: 3.83545\tVal MAE: 3.85846\n",
      "Epoch 18\n",
      "Batch 186/186\t- mae loss: 3.81033\n",
      "Epoch MAE: 3.83197\tVal MAE: 3.86027\n",
      "Epoch 19\n",
      "Batch 186/186\t- mae loss: 3.77842\n",
      "Epoch MAE: 3.82839\tVal MAE: 3.85222\n",
      "Epoch 20\n",
      "Batch 186/186\t- mae loss: 3.82082\n",
      "Epoch MAE: 3.82527\tVal MAE: 3.85260\n"
     ]
    }
   ],
   "source": [
    "# baseline gets ~ 3.64968 on dms w/ 10 epochs, ~ 4.64478 on 2a3 w/ 10 epochs\n",
    "masked_train(\n",
    "    model, train_dataloader=train_dataloader, val_dataloader=val_dataloader, epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've trained our model, we can save its weights and biases (\"state dict\") so that we can load them for later inferencing or further training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:14:00.616528Z",
     "start_time": "2023-10-05T17:14:00.119617Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"{desired_dataset}_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have both models, it's time to create a submission file. \n",
    "This section creates a zipped csv submission file that can\n",
    "be submitted on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:14:00.624146Z",
     "start_time": "2023-10-05T17:14:00.601389Z"
    }
   },
   "outputs": [],
   "source": [
    "make_submissions = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:14:01.233216Z",
     "start_time": "2023-10-05T17:14:00.608006Z"
    }
   },
   "outputs": [],
   "source": [
    "valid = False\n",
    "\n",
    "if (\n",
    "    os.path.exists(\"2a3_model\")\n",
    "    and os.path.exists(\"dms_model\")\n",
    "    and os.path.exists(\"test_sequences.csv\")\n",
    "    and make_submissions\n",
    "):\n",
    "    model_dms = BaselineModel()\n",
    "    model_2a3 = BaselineModel()\n",
    "    # model_2a3 = AttentionModel(**model_2a3_kwargs)\n",
    "    model_2a3.load_state_dict(torch.load(\"2a3_model\"))\n",
    "    # model_dms = AttentionModel(**model_dms_kwargs)\n",
    "    model_dms.load_state_dict(torch.load(\"dms_model\"))\n",
    "\n",
    "    model_2a3.eval().cuda()\n",
    "    model_dms.eval().cuda()\n",
    "\n",
    "    valid = True\n",
    "else:\n",
    "    print(\"Not going to create submissions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(\n",
    "    model_2a3: torch.nn.Module,\n",
    "    model_dms: torch.nn.Module,\n",
    "    input_ds: str,\n",
    "    out: str,\n",
    "    batch_size: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    Make predictions on the test dataset and write them to a csv file\n",
    "\n",
    "    Parameters:\n",
    "        - model_2a3: torch.nn.Module - the model trained on the 2a3 distribution\n",
    "        - model_dms: torch.nn.Module - the model trained on the dms distribution\n",
    "        - input_ds: str - name of the dataset to load\n",
    "        - out: str - name of the file to write to\n",
    "        - batch_size: int - size of the batches to use to process the data.\n",
    "            In general, larger batch sizes mean faster runtime\n",
    "    \"\"\"\n",
    "    ds = Dataset.load_from_disk(input_ds).with_format(\"torch\")\n",
    "    loader = data.DataLoader(ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    iterable = iter(loader)\n",
    "\n",
    "    with open(out, \"w\") as outfile:\n",
    "        # write the header\n",
    "        outfile.write(\"id,reactivity_DMS_MaP,reactivity_2A3_MaP\\n\")\n",
    "\n",
    "        for _ in tqdm(range(len(loader))):\n",
    "            # get the next group of data\n",
    "            tdata = next(iterable)\n",
    "            inputs = torch.stack([tdata[\"inputs\"], tdata[\"bpp\"]], dim=-1).cuda()\n",
    "            min_ids = tdata[\"id_min\"].numpy()\n",
    "            max_ids = tdata[\"id_max\"].numpy()\n",
    "\n",
    "            # make predictions w/o gradients\n",
    "            with torch.no_grad():\n",
    "                preds_2a3 = model_2a3(inputs).cpu().numpy()\n",
    "                preds_dms = model_dms(inputs).cpu().numpy()\n",
    "\n",
    "            # write preds\n",
    "            for i in range(inputs.shape[0]):\n",
    "                outfile.writelines(\n",
    "                    map(\n",
    "                        lambda seq_idx: f\"{seq_idx},{preds_dms[i, seq_idx-min_ids[i]]:.3f},{preds_2a3[i, seq_idx-min_ids[i]]:.3f}\\n\",\n",
    "                        # +1 since the id_max is inclusive\n",
    "                        range(min_ids[i], max_ids[i] + 1),\n",
    "                    )\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-05T17:14:01.248308Z"
    },
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1313/1313 [05:33<00:00,  3.93it/s]\n"
     ]
    }
   ],
   "source": [
    "if valid:\n",
    "    pipeline(\n",
    "        model_2a3,\n",
    "        model_dms,\n",
    "        \"test_data_preprocessed\",\n",
    "        \"submission.csv\",\n",
    "        batch_size=1024,\n",
    "    )\n",
    "else:\n",
    "    print(\"Not going to create submissions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zipping submissions. This may take a while...\n",
      "updating: submission.csv (deflated 80%)\n",
      "Done zipping submissions!\n"
     ]
    }
   ],
   "source": [
    "if valid:\n",
    "    # zip our submission into an easily-uploadable zip file\n",
    "    print(\"zipping submissions. This may take a while...\")\n",
    "    os.system(\"zip submission.csv.zip submission.csv\")\n",
    "    print(\"Done zipping submissions!\")\n",
    "else:\n",
    "    print(\"Not going to zip submissions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
