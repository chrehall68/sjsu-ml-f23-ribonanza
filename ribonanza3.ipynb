{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ribonanza - Attempt 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A second approach to the [Stanford Ribonanza problem](https://www.kaggle.com/competitions/stanford-ribonanza-rna-folding/) that builds off the first approach.\n",
    "\n",
    "Major differences:\n",
    "- use of attention model architecture\n",
    "- use of only filtered data (data in which SN_filter == 1)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, the attention architecture scores 0.21969\n",
    "\n",
    "![Score2](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- improve model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filesystem Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your project directory should look like this:\n",
    "\n",
    "- `(project directory)`\n",
    "    - `ribonanza2.ipynb`\n",
    "    - `train_data.csv`\n",
    "    - `test_data.csv` (optional)\n",
    "\n",
    "`train_data.csv` is the only file necessary for training, and it can be downloaded from the kaggle competition linked in the description.\n",
    "\n",
    "`test_data.csv` is only necessary if you intend to make and submit predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import tensorflow as tf\n",
    "import keras.layers as layers\n",
    "import keras\n",
    "import pandas\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import seaborn\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "# according to kaggle, this is the maximum # of reactivites to be used\n",
    "NUM_REACTIVITIES = 457\n",
    "\n",
    "# there are 4 different bases (AUCG)\n",
    "NUM_BASES = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(out: str, key: str, value: str, file_name: str, force: bool):\n",
    "    \"\"\"\n",
    "    Filters a file to only take datapoints\n",
    "    whose values of `key` are `value`.\n",
    "\n",
    "    Parameters:\n",
    "        - out: str - the name of the file that will store the filtered datapoints\n",
    "        - key: str - the name of the key to look at\n",
    "        - value: str - the value that the key should have\n",
    "        - file_name: str - the name of the file that contains all the datapoints.\n",
    "        - force: bool - whether or not to force re-processing of the data (if False and `out` already exists, no work will be done)\n",
    "    \"\"\"\n",
    "    if os.path.exists(out) and not force:\n",
    "        print(\"File already exists, not doing any work\")\n",
    "        return\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    # count how many lines we have in total\n",
    "    with open(file_name) as file:\n",
    "        line = file.readline()  # ignore the header\n",
    "        line = (\n",
    "            file.readline()\n",
    "        )  # take the first line since we increment count in the loop\n",
    "        while line != \"\":\n",
    "            count += 1\n",
    "            line = file.readline()\n",
    "\n",
    "    # use that knowledge for a progress bar\n",
    "    with open(file_name, \"r\") as file, open(out, \"w\") as outfile:\n",
    "        # write the header\n",
    "        header = file.readline()\n",
    "        outfile.write(header)\n",
    "\n",
    "        # get what index the SN_filter is\n",
    "        SN_idx = header.split(\",\").index(key)\n",
    "\n",
    "        # only take the approved filtered lines\n",
    "        for _ in tqdm(range(count)):\n",
    "            line = file.readline()\n",
    "            temp = line.split(\",\")\n",
    "            if temp[SN_idx] == value:\n",
    "                outfile.write(line)\n",
    "\n",
    "\n",
    "def filter_train_data(force: bool = False):\n",
    "    \"\"\"\n",
    "    Filters the immense train_data.csv to only take datapoints\n",
    "    whose SN_filter (Signal to Noise filter) is 1. In other words,\n",
    "    we only take good reads. These filtered datapoints are then\n",
    "    written to the file provided\n",
    "\n",
    "    Parameters:\n",
    "        - force: bool - whether or not to force re-processing of the data (if False and `out` already exists, no work will be done)\n",
    "    \"\"\"\n",
    "    filter_data(\"train_data_filtered.csv\", \"SN_filter\", \"1\", \"train_data.csv\", force)\n",
    "\n",
    "\n",
    "def filter_2A3(force: bool = False):\n",
    "    \"\"\"\n",
    "    Only take the 2A3 points\n",
    "\n",
    "    Parameters:\n",
    "        - force: bool - whether or not to force re-processing of the data (if False and `out` already exists, no work will be done)\n",
    "    \"\"\"\n",
    "    filter_data(\n",
    "        \"train_data_2a3.csv\",\n",
    "        \"experiment_type\",\n",
    "        \"2A3_MaP\",\n",
    "        \"train_data_filtered.csv\",\n",
    "        force,\n",
    "    )\n",
    "\n",
    "\n",
    "def filter_DMS(force: bool = False):\n",
    "    \"\"\"\n",
    "    Only take the DMS points\n",
    "\n",
    "    Parameters:\n",
    "        - force: bool - whether or not to force re-processing of the data (if False and `out` already exists, no work will be done)\n",
    "    \"\"\"\n",
    "    filter_data(\n",
    "        \"train_data_dms.csv\",\n",
    "        \"experiment_type\",\n",
    "        \"DMS_MaP\",\n",
    "        \"train_data_filtered.csv\",\n",
    "        force,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists, not doing any work\n"
     ]
    }
   ],
   "source": [
    "# filter our data\n",
    "filter_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists, not doing any work\n"
     ]
    }
   ],
   "source": [
    "# take the 2a3 points\n",
    "filter_2A3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists, not doing any work\n"
     ]
    }
   ],
   "source": [
    "# take the dms points\n",
    "filter_DMS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Data to Inputs and Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode inputs as\n",
    "# A : [1, 0, 0, 0]\n",
    "# U : [0, 1, 0, 0]\n",
    "# C : [0, 0, 1, 0]\n",
    "# G : [0, 0, 0, 1]\n",
    "base_map = {\n",
    "    \"A\": np.array([1, 0, 0, 0]),\n",
    "    \"U\": np.array([0, 1, 0, 0]),\n",
    "    \"C\": np.array([0, 0, 1, 0]),\n",
    "    \"G\": np.array([0, 0, 0, 1]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_csv(out: str, file_name: str, force: bool = False):\n",
    "    \"\"\"\n",
    "    Preprocess the csv and save the preprocessed data as a .npz file\n",
    "\n",
    "    Parameters:\n",
    "        - out: str - the name of the file to save the arrays to\n",
    "        - file_name: str - the name of the input csv file\n",
    "        - force: bool - whether or not to force re-processing of the data (if False and `out` already exists, no work will be done).\n",
    "                Defaults to `False`\n",
    "    \"\"\"\n",
    "    if os.path.exists(out) and not force:\n",
    "        print(\"File already exists, not doing any work\")\n",
    "        return\n",
    "\n",
    "    df = pandas.read_csv(file_name)\n",
    "\n",
    "    inputs = np.zeros((len(df), NUM_REACTIVITIES, NUM_BASES))\n",
    "    outputs = np.zeros((len(df), NUM_REACTIVITIES))\n",
    "    output_masks = np.ones((len(df), NUM_REACTIVITIES), dtype=np.bool_)\n",
    "    errors = np.zeros((len(df), NUM_REACTIVITIES))\n",
    "\n",
    "    for index in tqdm(range(len(df))):\n",
    "        row = df.iloc[index]\n",
    "\n",
    "        # get the sequence\n",
    "        seq_len = len(row[\"sequence\"])\n",
    "\n",
    "        # map the base to its one-hot encoding\n",
    "        inputs[index, :seq_len] = np.array(\n",
    "            list(map(lambda letter: base_map[letter], row[\"sequence\"]))\n",
    "        )\n",
    "\n",
    "        # get all the reactivities and reactivity errors\n",
    "        reactivities = np.array(\n",
    "            list(\n",
    "                map(\n",
    "                    lambda seq_idx: row[\"reactivity_\" + str(seq_idx + 1).rjust(4, \"0\")],\n",
    "                    range(seq_len),\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        reactivity_errors = np.array(\n",
    "            list(\n",
    "                map(\n",
    "                    lambda seq_idx: row[\n",
    "                        \"reactivity_error_\" + str(seq_idx + 1).rjust(4, \"0\")\n",
    "                    ],\n",
    "                    range(seq_len),\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # replace reactivity error nans with 0s (assume no error)\n",
    "        reactivity_errors = np.where(\n",
    "            np.isnan(reactivity_errors), 0.0, reactivity_errors\n",
    "        )\n",
    "\n",
    "        # get where all the reactivities are nan\n",
    "        nan_locats = np.isnan(reactivities)\n",
    "\n",
    "        # where it is nan, store True, else false\n",
    "        output_masks[index, :seq_len] = nan_locats\n",
    "\n",
    "        # where it is not nan, store the reactivity and error, else 0\n",
    "        outputs[index, :seq_len] = np.where(nan_locats == False, reactivities, 0.0)\n",
    "        errors[index, :seq_len] = np.where(nan_locats == False, reactivity_errors, 0.0)\n",
    "\n",
    "    # save the outputs\n",
    "    np.savez_compressed(\n",
    "        out, inputs=inputs, outputs=outputs, output_masks=output_masks, errors=errors\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists, not doing any work\n"
     ]
    }
   ],
   "source": [
    "preprocess_csv(\"train_data_2a3_preprocessed.npz\", \"train_data_2a3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists, not doing any work\n"
     ]
    }
   ],
   "source": [
    "preprocess_csv(\"train_data_dms_preprocessed.npz\", \"train_data_dms.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the desired dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:09:33.551791Z",
     "start_time": "2023-10-05T17:09:33.535197Z"
    }
   },
   "outputs": [],
   "source": [
    "desired_dataset = \"2a3\"  # either \"2a3\" or \"dms\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:09:42.265620Z",
     "start_time": "2023-10-05T17:09:33.728394Z"
    }
   },
   "outputs": [],
   "source": [
    "# load the npz file\n",
    "npz_file = np.load(f\"train_data_{desired_dataset}_preprocessed.npz\")\n",
    "\n",
    "# stored inputs, outputs, and output_masks\n",
    "# note: if visualizing, you may just want to only load outputs and bool_output_masks\n",
    "# since histplot takes a lot of RAM.\n",
    "inputs, outputs, bool_output_masks, errors = (\n",
    "    npz_file[\"inputs\"],\n",
    "    npz_file[\"outputs\"],\n",
    "    npz_file[\"output_masks\"],\n",
    "    npz_file[\"errors\"],\n",
    ")\n",
    "\n",
    "# close the npz file\n",
    "npz_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:09:42.843147Z",
     "start_time": "2023-10-05T17:09:42.265856Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210992, 457)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to usable weights:\n",
    "# if it is meant to be masked, it should be worth 0, else it should be worth 1 - error\n",
    "output_masks = np.where(bool_output_masks, 0.0, 1.0)\n",
    "output_masks -= errors\n",
    "output_masks[output_masks < 0.0] = 0.0\n",
    "output_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = np.clip(outputs, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section of the notebook allows for visualizing the reactivities of the\n",
    "current dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:09:42.844615Z",
     "start_time": "2023-10-05T17:09:42.843236Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:09:42.851158Z",
     "start_time": "2023-10-05T17:09:42.846563Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not visualizing. Set `visualize` to `True` to visualize data\n"
     ]
    }
   ],
   "source": [
    "if visualize:\n",
    "    visualized_items = []\n",
    "    for i in tqdm(range(len(outputs))):\n",
    "        for x in range(NUM_REACTIVITIES):\n",
    "            if not bool_output_masks[i, x]:\n",
    "                visualized_items.append(outputs[i, x])\n",
    "    visualized_items = np.array(visualized_items)\n",
    "    print(f\"took {len(visualized_items)}/{len(outputs)*NUM_REACTIVITIES} reactivities\")\n",
    "else:\n",
    "    print(\"Not visualizing. Set `visualize` to `True` to visualize data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:09:42.851272Z",
     "start_time": "2023-10-05T17:09:42.849526Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not visualizing. Set `visualize` to `True` to visualize data\n"
     ]
    }
   ],
   "source": [
    "if visualize:\n",
    "    seaborn.histplot(visualized_items, binwidth=0.1)\n",
    "else:\n",
    "    print(\"Not visualizing. Set `visualize` to `True` to visualize data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention layers\n",
    "\n",
    "\n",
    "class BaseAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "        self.add = tf.keras.layers.Add()\n",
    "\n",
    "\n",
    "class GlobalSelfAttention(BaseAttention):\n",
    "    def call(self, x):\n",
    "        attn_output = self.mha(query=x, value=x, key=x)\n",
    "        x = self.add([x, attn_output])\n",
    "        x = self.layernorm(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CrossAttention(BaseAttention):\n",
    "    def call(self, x, context):\n",
    "        attn_output = self.mha(\n",
    "            query=x, key=context, value=context, return_attention_scores=False\n",
    "        )\n",
    "\n",
    "        x = self.add([x, attn_output])\n",
    "        x = self.layernorm(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionModel(keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        latent_dim: int,\n",
    "        feedforward_dim: int,\n",
    "        context_window: int,\n",
    "        num_attention_heads: int = 2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # mask\n",
    "        self.mask_layer = layers.Masking(mask_value=0)\n",
    "\n",
    "        # prepatory conv layers\n",
    "        self.conv_f = layers.Conv1D(\n",
    "            filters=latent_dim,\n",
    "            kernel_size=context_window,\n",
    "            strides=1,\n",
    "            padding=\"same\",\n",
    "            activation=\"gelu\",\n",
    "        )\n",
    "        self.conv_b = layers.Conv1D(\n",
    "            filters=latent_dim,\n",
    "            kernel_size=context_window,\n",
    "            strides=1,\n",
    "            padding=\"same\",\n",
    "            activation=\"gelu\",\n",
    "        )\n",
    "        self.add = layers.Add()\n",
    "\n",
    "        # attentions\n",
    "        self.attention = GlobalSelfAttention(\n",
    "            num_heads=num_attention_heads, dropout=0.1, key_dim=latent_dim\n",
    "        )\n",
    "        self.cross_attention = CrossAttention(\n",
    "            num_heads=num_attention_heads, dropout=0.1, key_dim=latent_dim\n",
    "        )\n",
    "\n",
    "        # feedforward\n",
    "        self.ff = layers.Dense(feedforward_dim, activation=\"gelu\")\n",
    "\n",
    "        # output\n",
    "        self.outs = layers.Dense(1)\n",
    "\n",
    "        self.out_shape = layers.Reshape((NUM_REACTIVITIES,))\n",
    "\n",
    "    def call(self, x: tf.Tensor):\n",
    "        x = self.mask_layer(x)\n",
    "\n",
    "        # take inputs\n",
    "        inputs = x\n",
    "        reversed_inputs = tf.reverse(x, axis=[1])  # axis 0 is batch axis\n",
    "\n",
    "        # conv\n",
    "        x_f = self.conv_f(inputs)\n",
    "        x_b = tf.reverse(self.conv_b(reversed_inputs), axis=[1])\n",
    "\n",
    "        # attention\n",
    "        x_g = self.add([x_f, x_b])\n",
    "        x_g = self.attention(x_g)\n",
    "        x_c = self.cross_attention(x_f, x_b)\n",
    "        x = self.add([x_g, x_c])\n",
    "\n",
    "        # feedforward\n",
    "        x = self.ff(x)\n",
    "\n",
    "        # output\n",
    "        x = self.out_shape(self.outs(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:09:42.930488Z",
     "start_time": "2023-10-05T17:09:42.864218Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-06 15:54:37.326831: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-06 15:54:37.365541: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-06 15:54:37.365803: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-06 15:54:37.367286: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-06 15:54:37.367481: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-06 15:54:37.367643: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-06 15:54:37.435433: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-06 15:54:37.435735: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-06 15:54:37.435906: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-06 15:54:37.436028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10185 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:06:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"attention_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking (Masking)           multiple                  0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             multiple                  32896     \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           multiple                  32896     \n",
      "                                                                 \n",
      " add (Add)                   multiple                  0         \n",
      "                                                                 \n",
      " global_self_attention (Glob  multiple                 132224    \n",
      " alSelfAttention)                                                \n",
      "                                                                 \n",
      " cross_attention (CrossAtten  multiple                 132224    \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  132096    \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 463,361\n",
      "Trainable params: 463,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = AttentionModel(context_window=64, latent_dim=128, feedforward_dim=1024)\n",
    "model.build((None, NUM_REACTIVITIES, NUM_BASES))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.AdamW(1e-4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = tf.keras.losses.MeanAbsoluteError(reduction=tf.keras.losses.Reduction.SUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:09:43.992618Z",
     "start_time": "2023-10-05T17:09:43.053099Z"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_batch(m: keras.Model, inps: tf.Tensor, outs: tf.Tensor, masks: tf.Tensor):\n",
    "    \"\"\"\n",
    "    Get the loss on a batch and perform the corresponding weight updates.\n",
    "    Used for training purposes\n",
    "    \"\"\"\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        preds = tf.expand_dims(m(inps, training=True), axis=-1)\n",
    "        outs = tf.expand_dims(outs, axis=-1)\n",
    "\n",
    "        loss = 0.0\n",
    "        for b in range(inps.shape[0]):\n",
    "            loss += mae(outs[b], preds[b], sample_weight=masks[b])\n",
    "\n",
    "        # turn it into mean\n",
    "        loss /= inps.shape[0]\n",
    "\n",
    "        # add the regularization losses\n",
    "        if len(m.losses) > 0:\n",
    "            regularization_loss = tf.add_n(m.losses)\n",
    "            loss += regularization_loss\n",
    "        else:\n",
    "            regularization_loss = 0.0\n",
    "\n",
    "        # calculate gradients\n",
    "        grads = tape.gradient(loss, m.trainable_variables)\n",
    "\n",
    "    # apply grads\n",
    "    m.optimizer.apply_gradients(zip(grads, m.trainable_variables))\n",
    "\n",
    "    # return total loss, mae loss\n",
    "    return loss, loss - regularization_loss\n",
    "\n",
    "@tf.function\n",
    "def noupdate_batch(m: keras.Model, inps: tf.Tensor, outs: tf.Tensor, masks: tf.Tensor):\n",
    "    \"\"\"\n",
    "    Get the loss on a batch without performing any updates.\n",
    "    Used for validation purposes\n",
    "    \"\"\"\n",
    "    preds = tf.expand_dims(m(inps, training=False), axis=-1)\n",
    "    outs = tf.expand_dims(outs, axis=-1)\n",
    "\n",
    "    loss = 0.0\n",
    "    mae = tf.keras.losses.MeanAbsoluteError(reduction=tf.keras.losses.Reduction.SUM)\n",
    "    for b in range(inps.shape[0]):\n",
    "        loss += mae(preds[b], outs[b], sample_weight=masks[b])\n",
    "\n",
    "    # turn it into mean\n",
    "    loss /= inps.shape[0]\n",
    "\n",
    "    # return mae loss\n",
    "    return loss\n",
    "\n",
    "\n",
    "def masked_train(\n",
    "    m: keras.Model,\n",
    "    x: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    masks: np.ndarray,\n",
    "    batch_size: int = 32,\n",
    "    epochs: int = 1,\n",
    "    validation_split: float = 0.1\n",
    "):\n",
    "    \"\"\"\n",
    "    Train the given model.\n",
    "\n",
    "    Arguments:\n",
    "        - m: keras.Model - the model to train.\n",
    "        - x: np.ndarray - the numpy array of inputs.\n",
    "        - y: np.ndarray - the numpy array of outputs.\n",
    "        - masks: np.ndarray - the sample weights (1s and 0s).\n",
    "        - batch_size: int - how large the batches should be. Defaults to `32`.\n",
    "        - epochs: int - how many epochs to train for. Defaults to `1`.\n",
    "        - validation_split: float - how large the validation subset should be, in the range (0, 1]. Defaults to `0.1`.\n",
    "\n",
    "    Note - The choice of np.ndarray is purely arbitrary, and this function can be modified to use tf.Tensors\n",
    "\n",
    "    Note - shuffle code is provided in numpy, but commented out because of memory limitations that less powerful computers\n",
    "    may encounter.\n",
    "    \"\"\"\n",
    "    # shuffle\n",
    "    # shuffled_idxs = np.arange(x.shape[0])\n",
    "    # np.random.shuffle(shuffled_idxs)\n",
    "    # x = x[shuffled_idxs]\n",
    "    # y = y[shuffled_idxs]\n",
    "    # masks = masks[shuffled_idxs]\n",
    "\n",
    "    # generate validation\n",
    "    validation_size = int(x.shape[0] * validation_split)\n",
    "    x_val = x[:validation_size]\n",
    "    y_val = y[:validation_size]\n",
    "    masks_val = masks[:validation_size]\n",
    "    x = x[validation_size:]\n",
    "    y = y[validation_size:]\n",
    "    masks = masks[validation_size:]\n",
    "\n",
    "    # calculate number of batches to do\n",
    "    num_batches = x.shape[0] // batch_size\n",
    "    if x.shape[0] % batch_size != 0:\n",
    "        num_batches += 1\n",
    "\n",
    "    num_validation_batches = x_val.shape[0] // batch_size\n",
    "    if x_val.shape[0] % batch_size != 0:\n",
    "        num_validation_batches += 1\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"Epoch {epoch}\")\n",
    "        epoch_loss = 0.0\n",
    "        epoch_mae = 0.0\n",
    "\n",
    "        for batch in range(num_batches):\n",
    "            num_items = min(batch_size, x.shape[0] - batch * batch_size)\n",
    "\n",
    "            inps = tf.constant(x[batch * batch_size : batch * batch_size + num_items])\n",
    "            outs = tf.constant(y[batch * batch_size : batch * batch_size + num_items])\n",
    "            masks_ = tf.constant(\n",
    "                masks[batch * batch_size : batch * batch_size + num_items]\n",
    "            )\n",
    "\n",
    "            loss, mae_loss = train_batch(m, inps, outs, masks_)\n",
    "\n",
    "            epoch_loss += loss\n",
    "            epoch_mae += mae_loss\n",
    "\n",
    "            # log\n",
    "            print(\n",
    "                f\"Batch {batch+1}/{num_batches}\\t- loss: {loss.numpy():.5f}\\t- mae loss: {mae_loss.numpy():.5f}\",\n",
    "                end=\"\\r\",\n",
    "            )\n",
    "        epoch_loss /= num_batches\n",
    "        epoch_mae /= num_batches\n",
    "\n",
    "        # do validation\n",
    "        val_mae = 0.0\n",
    "        for batch in range(num_validation_batches):\n",
    "            num_items = min(batch_size, x_val.shape[0] - batch * batch_size)\n",
    "\n",
    "            inps = tf.constant(\n",
    "                x_val[batch * batch_size : batch * batch_size + num_items]\n",
    "            )\n",
    "            outs = tf.constant(\n",
    "                y_val[batch * batch_size : batch * batch_size + num_items]\n",
    "            )\n",
    "            masks_ = tf.constant(\n",
    "                masks_val[batch * batch_size : batch * batch_size + num_items]\n",
    "            )\n",
    "\n",
    "            mae_loss = noupdate_batch(m, inps, outs, masks_)\n",
    "\n",
    "            val_mae += mae_loss\n",
    "        val_mae /= num_validation_batches\n",
    "\n",
    "        # shuffle\n",
    "        # shuffled_idxs = np.arange(x.shape[0])\n",
    "        # np.random.shuffle(shuffled_idxs)\n",
    "        # x = x[shuffled_idxs]\n",
    "        # y = y[shuffled_idxs]\n",
    "        # masks = masks[shuffled_idxs]\n",
    "\n",
    "        print()\n",
    "        print(\n",
    "            f\"Epoch loss: {epoch_loss:.5f}\\tEpoch MAE: {epoch_mae:.5f}\\tVal MAE: {val_mae:.5f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:14:00.128074Z",
     "start_time": "2023-10-05T17:09:43.998369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Batch 742/742\t- loss: 14.03800\t- mae loss: 14.03800\n",
      "Epoch loss: 18.18552\tEpoch MAE: 18.18552\tVal MAE: 22.64707\n",
      "Epoch 2\n",
      "Batch 742/742\t- loss: 13.01555\t- mae loss: 13.01555\n",
      "Epoch loss: 18.09517\tEpoch MAE: 18.09517\tVal MAE: 22.14537\n",
      "Epoch 3\n",
      "Batch 742/742\t- loss: 12.72256\t- mae loss: 12.72256\n",
      "Epoch loss: 18.01124\tEpoch MAE: 18.01124\tVal MAE: 21.96640\n",
      "Epoch 4\n",
      "Batch 742/742\t- loss: 12.43657\t- mae loss: 12.43657\n",
      "Epoch loss: 17.94659\tEpoch MAE: 17.94659\tVal MAE: 21.86219\n",
      "Epoch 5\n",
      "Batch 742/742\t- loss: 12.39187\t- mae loss: 12.39187\n",
      "Epoch loss: 17.89081\tEpoch MAE: 17.89081\tVal MAE: 21.83851\n",
      "Epoch 6\n",
      "Batch 742/742\t- loss: 12.25373\t- mae loss: 12.25373\n",
      "Epoch loss: 17.83789\tEpoch MAE: 17.83789\tVal MAE: 21.82283\n",
      "Epoch 7\n",
      "Batch 742/742\t- loss: 12.19668\t- mae loss: 12.19668\n",
      "Epoch loss: 17.78611\tEpoch MAE: 17.78611\tVal MAE: 21.86211\n",
      "Epoch 8\n",
      "Batch 742/742\t- loss: 12.08502\t- mae loss: 12.08502\n",
      "Epoch loss: 17.73326\tEpoch MAE: 17.73326\tVal MAE: 21.80653\n",
      "Epoch 9\n",
      "Batch 742/742\t- loss: 11.98875\t- mae loss: 11.98875\n",
      "Epoch loss: 17.68084\tEpoch MAE: 17.68084\tVal MAE: 21.72117\n",
      "Epoch 10\n",
      "Batch 742/742\t- loss: 11.94009\t- mae loss: 11.94009\n",
      "Epoch loss: 17.62825\tEpoch MAE: 17.62825\tVal MAE: 21.57525\n",
      "Epoch 11\n",
      "Batch 742/742\t- loss: 11.85571\t- mae loss: 11.85571\n",
      "Epoch loss: 17.57489\tEpoch MAE: 17.57489\tVal MAE: 21.41037\n",
      "Epoch 12\n",
      "Batch 742/742\t- loss: 11.74098\t- mae loss: 11.74098\n",
      "Epoch loss: 17.52127\tEpoch MAE: 17.52127\tVal MAE: 21.21163\n",
      "Epoch 13\n",
      "Batch 742/742\t- loss: 11.49333\t- mae loss: 11.49333\n",
      "Epoch loss: 17.46923\tEpoch MAE: 17.46923\tVal MAE: 21.04044\n",
      "Epoch 14\n",
      "Batch 742/742\t- loss: 11.53639\t- mae loss: 11.53639\n",
      "Epoch loss: 17.41956\tEpoch MAE: 17.41956\tVal MAE: 20.91464\n",
      "Epoch 15\n",
      "Batch 742/742\t- loss: 11.26991\t- mae loss: 11.26991\n",
      "Epoch loss: 17.36993\tEpoch MAE: 17.36993\tVal MAE: 20.74771\n",
      "Epoch 16\n",
      "Batch 742/742\t- loss: 11.30224\t- mae loss: 11.30224\n",
      "Epoch loss: 17.32290\tEpoch MAE: 17.32290\tVal MAE: 20.67560\n",
      "Epoch 17\n",
      "Batch 742/742\t- loss: 11.06169\t- mae loss: 11.06169\n",
      "Epoch loss: 17.27894\tEpoch MAE: 17.27894\tVal MAE: 20.51963\n",
      "Epoch 18\n",
      "Batch 742/742\t- loss: 11.06427\t- mae loss: 11.06427\n",
      "Epoch loss: 17.23633\tEpoch MAE: 17.23633\tVal MAE: 20.45824\n",
      "Epoch 19\n",
      "Batch 742/742\t- loss: 10.89245\t- mae loss: 10.89245\n",
      "Epoch loss: 17.19397\tEpoch MAE: 17.19397\tVal MAE: 20.33269\n",
      "Epoch 20\n",
      "Batch 742/742\t- loss: 10.73778\t- mae loss: 10.73778\n",
      "Epoch loss: 17.15329\tEpoch MAE: 17.15329\tVal MAE: 20.25276\n"
     ]
    }
   ],
   "source": [
    "masked_train(model, inputs, outputs, output_masks, epochs=20, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section saves the current model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:14:00.616528Z",
     "start_time": "2023-10-05T17:14:00.119617Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-06 17:50:49.600784: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'x' with dtype float and shape [?,457,128]\n",
      "\t [[{{node x}}]]\n",
      "2023-10-06 17:50:49.609630: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'x' with dtype float and shape [?,457,128]\n",
      "\t [[{{node x}}]]\n",
      "2023-10-06 17:50:49.618654: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'x' with dtype float and shape [?,457,128]\n",
      "\t [[{{node x}}]]\n",
      "2023-10-06 17:50:49.627371: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'x' with dtype float and shape [?,457,128]\n",
      "\t [[{{node x}}]]\n",
      "2023-10-06 17:50:49.633611: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,457,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-10-06 17:50:49.638791: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,457,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-10-06 17:50:50.190425: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'x' with dtype float and shape [?,457,128]\n",
      "\t [[{{node x}}]]\n",
      "2023-10-06 17:50:50.199099: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'x' with dtype float and shape [?,457,128]\n",
      "\t [[{{node x}}]]\n",
      "2023-10-06 17:50:50.290459: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'x' with dtype float and shape [?,457,128]\n",
      "\t [[{{node x}}]]\n",
      "2023-10-06 17:50:50.299177: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'x' with dtype float and shape [?,457,128]\n",
      "\t [[{{node x}}]]\n",
      "2023-10-06 17:50:50.390912: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,457,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-10-06 17:50:50.415849: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,457,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, multi_head_attention_layer_call_fn, multi_head_attention_layer_call_and_return_conditional_losses, layer_normalization_layer_call_fn while saving (showing 5 of 38). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 2a3_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 2a3_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(f\"{desired_dataset}_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section of the noteboook creates a zipped csv submission file that can\n",
    "be submitted on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:14:00.624146Z",
     "start_time": "2023-10-05T17:14:00.601389Z"
    }
   },
   "outputs": [],
   "source": [
    "make_submissions = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:14:01.233216Z",
     "start_time": "2023-10-05T17:14:00.608006Z"
    }
   },
   "outputs": [],
   "source": [
    "valid = False\n",
    "\n",
    "if (\n",
    "    os.path.exists(\"2a3_model\")\n",
    "    and os.path.exists(\"dms_model\")\n",
    "    and os.path.exists(\"test_sequences.csv\")\n",
    "    and make_submissions\n",
    "):\n",
    "    valid = True\n",
    "    model_2a3 = keras.models.load_model(\"2a3_model\")\n",
    "    model_dms = keras.models.load_model(\"dms_model\")\n",
    "else:\n",
    "    print(\"Not going to create submissions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:14:01.247263Z",
     "start_time": "2023-10-05T17:14:01.233464Z"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def call_model(model_2a3, model_dms, inputs):\n",
    "    return model_2a3(inputs, training=False), model_dms(inputs, training=False)\n",
    "\n",
    "\n",
    "def pipeline(\n",
    "    model_2a3: keras.Model,\n",
    "    model_dms: keras.Model,\n",
    "    input_csv: str,\n",
    "    out: str,\n",
    "    batch_size: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    Process test data and write submissions to a csv file\n",
    "\n",
    "    Arguments:\n",
    "        - model_2a3: keras.Model - the model trained on the 2a3 distribution\n",
    "        - model_dms: keras.Model - the model trained on the dms distribution\n",
    "        - input_csv: str - the name of the file that contains the test data\n",
    "        - out: str - the name of the file to write predictions to\n",
    "        - batch_size: int - how many predictions to make at a time\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "\n",
    "    # count how many lines we have in total\n",
    "    with open(input_csv) as file:\n",
    "        line = file.readline()  # ignore the header\n",
    "        # take the first line since we increment count in the loop\n",
    "        line = file.readline()\n",
    "        while line != \"\":\n",
    "            count += 1\n",
    "            line = file.readline()\n",
    "\n",
    "    # use that knowledge for a progress bar\n",
    "    with open(input_csv, \"r\") as file, open(out, \"w\") as outfile:\n",
    "        # write the header\n",
    "        outfile.write(\"id,reactivity_DMS_MaP,reactivity_2A3_MaP\\n\")\n",
    "\n",
    "        # get what index the things we need are\n",
    "        header = file.readline()\n",
    "        split_header = header.split(\",\")\n",
    "        min_idx = split_header.index(\"id_min\")\n",
    "        max_idx = split_header.index(\"id_max\")\n",
    "        sequence_idx = split_header.index(\"sequence\")\n",
    "\n",
    "        # only take the approved filtered lines\n",
    "        num_batches = count // batch_size\n",
    "        if count % batch_size != 0:\n",
    "            num_batches += 1\n",
    "        for batch in tqdm(range(num_batches)):\n",
    "            num_items = min(batch_size, count - batch * batch_size)\n",
    "\n",
    "            # initialize variables\n",
    "            inputs = np.zeros((num_items, NUM_REACTIVITIES, NUM_BASES))\n",
    "            min_seq_idxs = []\n",
    "            sequence_lengths = []\n",
    "\n",
    "            # collect the inputs\n",
    "            for i in range(num_items):\n",
    "                line = file.readline()\n",
    "                temp = line.split(\",\")\n",
    "                sequence = temp[sequence_idx]\n",
    "                max_seq_idx = int(temp[max_idx])\n",
    "                min_seq_idx = int(temp[min_idx])\n",
    "\n",
    "                # verify that everything is correct\n",
    "                assert len(sequence) + min_seq_idx - 1 == max_seq_idx\n",
    "\n",
    "                # store the data\n",
    "                inputs[i, : len(sequence)] = np.array(\n",
    "                    list(map(lambda letter: base_map[letter], sequence))\n",
    "                )\n",
    "                min_seq_idxs.append(min_seq_idx)\n",
    "                sequence_lengths.append(len(sequence))\n",
    "\n",
    "            # run inputs through the associated model\n",
    "            probs_2a3, probs_dms = call_model(model_2a3, model_dms, inputs)\n",
    "            probs_dms = np.squeeze(probs_dms.numpy())\n",
    "            probs_2a3 = np.squeeze(probs_2a3.numpy())\n",
    "\n",
    "            # write predictions\n",
    "            for i in range(num_items):\n",
    "                for seq_idx in range(\n",
    "                    min_seq_idxs[i], min_seq_idxs[i] + sequence_lengths[i]\n",
    "                ):\n",
    "                    outfile.write(\n",
    "                        f\"{seq_idx},{probs_dms[i, seq_idx - min_seq_idxs[i]]:.3f},{probs_2a3[i, seq_idx - min_seq_idxs[i]]:.3f}\\n\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-05T17:14:01.248308Z"
    },
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5250/5250 [26:22<00:00,  3.32it/s]\n"
     ]
    }
   ],
   "source": [
    "if valid:\n",
    "    pipeline(\n",
    "        model_2a3, model_dms, \"test_sequences.csv\", \"submission.csv\", batch_size=256\n",
    "    )\n",
    "else:\n",
    "    print(\"Not going to create submissions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zipping submissions. This may take a while...\n",
      "updating: submission.csv (deflated 71%)\n",
      "Done zipping submissions!\n"
     ]
    }
   ],
   "source": [
    "if valid:\n",
    "    # zip our submission into an easily-uploadable zip file\n",
    "    print(\"zipping submissions. This may take a while...\")\n",
    "    os.system(\"zip submission.csv.zip submission.csv\")\n",
    "    print(\"Done zipping submissions!\")\n",
    "else:\n",
    "    print(\"Not going to zip submissions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
