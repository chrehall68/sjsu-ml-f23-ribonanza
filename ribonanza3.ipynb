{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ribonanza - Attempt 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A second approach to the [Stanford Ribonanza problem](https://www.kaggle.com/competitions/stanford-ribonanza-rna-folding/) that builds off the first approach.\n",
    "\n",
    "Major differences:\n",
    "- use of attention model architecture\n",
    "- use of only filtered data (data in which SN_filter == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, the attention architecture scores 0.20859"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- improve model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filesystem Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your project directory should look like this:\n",
    "\n",
    "- `(project directory)`\n",
    "    - `ribonanza2.ipynb`\n",
    "    - `train_data.csv`\n",
    "    - `test_data.csv` (optional)\n",
    "\n",
    "`train_data.csv` is the only file necessary for training, and it can be downloaded from the kaggle competition linked in the description.\n",
    "\n",
    "`test_data.csv` is only necessary if you intend to make and submit predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-07 22:00:15.370072: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-07 22:00:16.120172: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import tensorflow as tf\n",
    "import keras.layers as layers\n",
    "import keras_nlp\n",
    "import keras\n",
    "import pandas\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import seaborn\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "# according to kaggle, this is the maximum # of reactivites to be used\n",
    "NUM_REACTIVITIES = 457\n",
    "\n",
    "# there are 4 different bases (AUCG)\n",
    "NUM_BASES = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(out: str, key: str, value: str, file_name: str, force: bool):\n",
    "    \"\"\"\n",
    "    Filters a file to only take datapoints\n",
    "    whose values of `key` are `value`.\n",
    "\n",
    "    Parameters:\n",
    "        - out: str - the name of the file that will store the filtered datapoints\n",
    "        - key: str - the name of the key to look at\n",
    "        - value: str - the value that the key should have\n",
    "        - file_name: str - the name of the file that contains all the datapoints.\n",
    "        - force: bool - whether or not to force re-processing of the data (if False and `out` already exists, no work will be done)\n",
    "    \"\"\"\n",
    "    if os.path.exists(out) and not force:\n",
    "        print(\"File already exists, not doing any work\")\n",
    "        return\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    # count how many lines we have in total\n",
    "    with open(file_name) as file:\n",
    "        line = file.readline()  # ignore the header\n",
    "        line = (\n",
    "            file.readline()\n",
    "        )  # take the first line since we increment count in the loop\n",
    "        while line != \"\":\n",
    "            count += 1\n",
    "            line = file.readline()\n",
    "\n",
    "    # use that knowledge for a progress bar\n",
    "    with open(file_name, \"r\") as file, open(out, \"w\") as outfile:\n",
    "        # write the header\n",
    "        header = file.readline()\n",
    "        outfile.write(header)\n",
    "\n",
    "        # get what index the SN_filter is\n",
    "        SN_idx = header.split(\",\").index(key)\n",
    "\n",
    "        # only take the approved filtered lines\n",
    "        for _ in tqdm(range(count)):\n",
    "            line = file.readline()\n",
    "            temp = line.split(\",\")\n",
    "            if temp[SN_idx] == value:\n",
    "                outfile.write(line)\n",
    "\n",
    "\n",
    "def filter_train_data(force: bool = False):\n",
    "    \"\"\"\n",
    "    Filters the immense train_data.csv to only take datapoints\n",
    "    whose SN_filter (Signal to Noise filter) is 1. In other words,\n",
    "    we only take good reads. These filtered datapoints are then\n",
    "    written to the file provided\n",
    "\n",
    "    Parameters:\n",
    "        - force: bool - whether or not to force re-processing of the data (if False and `out` already exists, no work will be done)\n",
    "    \"\"\"\n",
    "    filter_data(\"train_data_filtered.csv\", \"SN_filter\", \"1\", \"train_data.csv\", force)\n",
    "\n",
    "\n",
    "def filter_2A3(force: bool = False):\n",
    "    \"\"\"\n",
    "    Only take the 2A3 points\n",
    "\n",
    "    Parameters:\n",
    "        - force: bool - whether or not to force re-processing of the data (if False and `out` already exists, no work will be done)\n",
    "    \"\"\"\n",
    "    filter_data(\n",
    "        \"train_data_2a3.csv\",\n",
    "        \"experiment_type\",\n",
    "        \"2A3_MaP\",\n",
    "        \"train_data_filtered.csv\",\n",
    "        force,\n",
    "    )\n",
    "\n",
    "\n",
    "def filter_DMS(force: bool = False):\n",
    "    \"\"\"\n",
    "    Only take the DMS points\n",
    "\n",
    "    Parameters:\n",
    "        - force: bool - whether or not to force re-processing of the data (if False and `out` already exists, no work will be done)\n",
    "    \"\"\"\n",
    "    filter_data(\n",
    "        \"train_data_dms.csv\",\n",
    "        \"experiment_type\",\n",
    "        \"DMS_MaP\",\n",
    "        \"train_data_filtered.csv\",\n",
    "        force,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists, not doing any work\n"
     ]
    }
   ],
   "source": [
    "# filter our data\n",
    "filter_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists, not doing any work\n"
     ]
    }
   ],
   "source": [
    "# take the 2a3 points\n",
    "filter_2A3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists, not doing any work\n"
     ]
    }
   ],
   "source": [
    "# take the dms points\n",
    "filter_DMS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Data to Inputs and Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode inputs as\n",
    "# A : 1\n",
    "# U : 2\n",
    "# C : 3\n",
    "# G : 4\n",
    "base_map = {\n",
    "    \"A\": 1,\n",
    "    \"U\": 2,\n",
    "    \"C\": 3,\n",
    "    \"G\": 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_csv(out: str, file_name: str, force: bool = False):\n",
    "    \"\"\"\n",
    "    Preprocess the csv and save the preprocessed data as a .npz file\n",
    "\n",
    "    Parameters:\n",
    "        - out: str - the name of the file to save the arrays to\n",
    "        - file_name: str - the name of the input csv file\n",
    "        - force: bool - whether or not to force re-processing of the data (if False and `out` already exists, no work will be done).\n",
    "                Defaults to `False`\n",
    "    \"\"\"\n",
    "    if os.path.exists(out) and not force:\n",
    "        print(\"File already exists, not doing any work\")\n",
    "        return\n",
    "\n",
    "    df = pandas.read_csv(file_name)\n",
    "\n",
    "    inputs = np.zeros((len(df), NUM_REACTIVITIES))\n",
    "    outputs = np.zeros((len(df), NUM_REACTIVITIES))\n",
    "    output_masks = np.ones((len(df), NUM_REACTIVITIES), dtype=np.bool_)\n",
    "    errors = np.zeros((len(df), NUM_REACTIVITIES))\n",
    "\n",
    "    for index in tqdm(range(len(df))):\n",
    "        row = df.iloc[index]\n",
    "\n",
    "        # get the sequence\n",
    "        seq_len = len(row[\"sequence\"])\n",
    "\n",
    "        # map the base to its one-hot encoding\n",
    "        inputs[index, :seq_len] = np.array(\n",
    "            list(map(lambda letter: base_map[letter], row[\"sequence\"]))\n",
    "        )\n",
    "\n",
    "        # get all the reactivities and reactivity errors\n",
    "        reactivities = np.array(\n",
    "            list(\n",
    "                map(\n",
    "                    lambda seq_idx: row[\"reactivity_\" + str(seq_idx + 1).rjust(4, \"0\")],\n",
    "                    range(seq_len),\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        reactivity_errors = np.array(\n",
    "            list(\n",
    "                map(\n",
    "                    lambda seq_idx: row[\n",
    "                        \"reactivity_error_\" + str(seq_idx + 1).rjust(4, \"0\")\n",
    "                    ],\n",
    "                    range(seq_len),\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # replace reactivity error nans with 0s (assume no error)\n",
    "        reactivity_errors = np.where(\n",
    "            np.isnan(reactivity_errors), 0.0, reactivity_errors\n",
    "        )\n",
    "\n",
    "        # get where all the reactivities are nan\n",
    "        nan_locats = np.isnan(reactivities)\n",
    "\n",
    "        # where it is nan, store True, else false\n",
    "        output_masks[index, :seq_len] = nan_locats\n",
    "\n",
    "        # where it is not nan, store the reactivity and error, else 0\n",
    "        outputs[index, :seq_len] = np.where(nan_locats == False, reactivities, 0.0)\n",
    "        errors[index, :seq_len] = np.where(nan_locats == False, reactivity_errors, 0.0)\n",
    "\n",
    "    # save the outputs\n",
    "    np.savez_compressed(\n",
    "        out, inputs=inputs, outputs=outputs, output_masks=output_masks, errors=errors\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists, not doing any work\n"
     ]
    }
   ],
   "source": [
    "preprocess_csv(\"train_data_2a3_preprocessed.npz\", \"train_data_2a3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists, not doing any work\n"
     ]
    }
   ],
   "source": [
    "preprocess_csv(\"train_data_dms_preprocessed.npz\", \"train_data_dms.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the desired dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:09:33.551791Z",
     "start_time": "2023-10-05T17:09:33.535197Z"
    }
   },
   "outputs": [],
   "source": [
    "desired_dataset = \"dms\"  # either \"2a3\" or \"dms\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:09:42.265620Z",
     "start_time": "2023-10-05T17:09:33.728394Z"
    }
   },
   "outputs": [],
   "source": [
    "# load the npz file\n",
    "npz_file = np.load(f\"train_data_{desired_dataset}_preprocessed.npz\")\n",
    "\n",
    "# stored inputs, outputs, and output_masks\n",
    "# note: if visualizing, you may just want to only load outputs and bool_output_masks\n",
    "# since histplot takes a lot of RAM.\n",
    "inputs, outputs, bool_output_masks, errors = (\n",
    "    npz_file[\"inputs\"],\n",
    "    npz_file[\"outputs\"],\n",
    "    npz_file[\"output_masks\"],\n",
    "    npz_file[\"errors\"],\n",
    ")\n",
    "\n",
    "# close the npz file\n",
    "npz_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:09:42.843147Z",
     "start_time": "2023-10-05T17:09:42.265856Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226925, 457)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to usable weights:\n",
    "# if it is meant to be masked, it should be worth 0, else it should be worth 1 - error\n",
    "output_masks = np.where(bool_output_masks, 0.0, 1.0)\n",
    "output_masks -= errors\n",
    "output_masks[output_masks < 0.0] = 0.0\n",
    "output_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = np.clip(outputs, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section of the notebook allows for visualizing the reactivities of the\n",
    "current dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:09:42.844615Z",
     "start_time": "2023-10-05T17:09:42.843236Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:09:42.851158Z",
     "start_time": "2023-10-05T17:09:42.846563Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not visualizing. Set `visualize` to `True` to visualize data\n"
     ]
    }
   ],
   "source": [
    "if visualize:\n",
    "    visualized_items = []\n",
    "    for i in tqdm(range(len(outputs))):\n",
    "        for x in range(NUM_REACTIVITIES):\n",
    "            if not bool_output_masks[i, x]:\n",
    "                visualized_items.append(outputs[i, x])\n",
    "    visualized_items = np.array(visualized_items)\n",
    "    print(f\"took {len(visualized_items)}/{len(outputs)*NUM_REACTIVITIES} reactivities\")\n",
    "else:\n",
    "    print(\"Not visualizing. Set `visualize` to `True` to visualize data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:09:42.851272Z",
     "start_time": "2023-10-05T17:09:42.849526Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not visualizing. Set `visualize` to `True` to visualize data\n"
     ]
    }
   ],
   "source": [
    "if visualize:\n",
    "    seaborn.histplot(visualized_items, binwidth=0.1)\n",
    "else:\n",
    "    print(\"Not visualizing. Set `visualize` to `True` to visualize data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention layers\n",
    "\n",
    "\n",
    "class BaseAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "        self.add = tf.keras.layers.Add()\n",
    "\n",
    "\n",
    "class GlobalSelfAttention(BaseAttention):\n",
    "    def call(self, x, **kwargs):\n",
    "        attn_output = self.mha(query=x, value=x, key=x, **kwargs)\n",
    "        x = self.add([x, attn_output])\n",
    "        x = self.layernorm(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CrossAttention(BaseAttention):\n",
    "    def call(self, x, context, **kwargs):\n",
    "        attn_output = self.mha(\n",
    "            query=x, key=context, value=context, **kwargs\n",
    "        )\n",
    "\n",
    "        x = self.add([x, attn_output])\n",
    "        x = self.layernorm(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(layers.Layer):\n",
    "    def __init__(self, num_attention_heads: int, latent_dim:int, feedforward_dim:int, dropout_rate:float):\n",
    "        super().__init__()\n",
    "        self.attention = GlobalSelfAttention(num_heads=num_attention_heads, dropout=dropout_rate, key_dim=latent_dim)\n",
    "        self.ff = layers.Dense(feedforward_dim, activation=\"gelu\")\n",
    "        self.ff2 = layers.Dense(latent_dim, activation=\"gelu\")\n",
    "        self.add = layers.Add()\n",
    "        self.norm = layers.LayerNormalization()\n",
    "        \n",
    "    def call(self, x:tf.Tensor, attention_mask: tf.Tensor):\n",
    "        # attention (which has add and norm)\n",
    "        x_pre = self.attention(x,attention_mask=attention_mask)\n",
    "        \n",
    "        # ff\n",
    "        x = self.ff(x_pre)\n",
    "        x = self.ff2(x)\n",
    "        \n",
    "        # add and norm\n",
    "        x = self.add([x, x_pre])\n",
    "        x = self.norm(x)\n",
    "\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionModel(keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        latent_dim: int,\n",
    "        feedforward_dim: int,\n",
    "        context_window: int,\n",
    "        num_attention_heads: int = 2,\n",
    "        num_encoder_layers: int = 2,\n",
    "        dropout_rate:float=0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        self.embedding_layer = layers.Embedding(NUM_BASES, latent_dim, mask_zero=True)\n",
    "        self.sinusoidal_pos_embedding = keras_nlp.layers.SinePositionEncoding()\n",
    "\n",
    "        # prepatory conv layers\n",
    "        self.conv_f = layers.Conv1D(\n",
    "            filters=latent_dim,\n",
    "            kernel_size=context_window,\n",
    "            strides=1,\n",
    "            padding=\"same\",\n",
    "            activation=\"gelu\",\n",
    "        )\n",
    "        self.conv_b = layers.Conv1D(\n",
    "            filters=latent_dim,\n",
    "            kernel_size=context_window,\n",
    "            strides=1,\n",
    "            padding=\"same\",\n",
    "            activation=\"gelu\",\n",
    "        )\n",
    "        self.add = layers.Add()\n",
    "\n",
    "        # attentions\n",
    "        self.attention = GlobalSelfAttention(\n",
    "            num_heads=num_attention_heads, dropout=dropout_rate, key_dim=latent_dim\n",
    "        )\n",
    "        self.cross_attention = CrossAttention(\n",
    "            num_heads=num_attention_heads, dropout=dropout_rate, key_dim=latent_dim\n",
    "        )\n",
    "\n",
    "        # feedforward\n",
    "        self.ff = layers.Dense(feedforward_dim, activation=\"gelu\")\n",
    "        self.ff2 = layers.Dense(latent_dim, activation=\"gelu\")\n",
    "\n",
    "        # encoder layers\n",
    "        self.encoder_layers = []\n",
    "        for _ in range(num_encoder_layers):\n",
    "            self.encoder_layers.append(EncoderLayer(num_attention_heads=num_attention_heads, latent_dim=latent_dim, feedforward_dim=feedforward_dim, dropout_rate=dropout_rate))\n",
    "\n",
    "        # output\n",
    "        self.outs = layers.Dense(1)\n",
    "\n",
    "        self.out_shape = layers.Reshape((NUM_REACTIVITIES,))\n",
    "\n",
    "    def call(self, x: tf.Tensor):\n",
    "        # calculate attention mask\n",
    "        attention_mask = self.embedding_layer.compute_mask(x)\n",
    "        # should be [B, H, T, S] (batch, heads, query size, key size)\n",
    "        # since we are doing self attention, query_size == key_size\n",
    "        attention_mask = attention_mask[:, tf.newaxis, tf.newaxis, :] \n",
    "\n",
    "        x = self.embedding_layer(x)\n",
    "        positional_encoding = self.sinusoidal_pos_embedding(x)\n",
    "\n",
    "        # take inputs\n",
    "        inputs = x\n",
    "        reversed_inputs = tf.reverse(x, axis=[1])  # axis 0 is batch axis\n",
    "\n",
    "        # conv\n",
    "        x_f = self.conv_f(inputs)+ positional_encoding\n",
    "        x_b = tf.reverse(self.conv_b(reversed_inputs), axis=[1]) + positional_encoding\n",
    "\n",
    "        # attention\n",
    "        x_g = self.add([x_f, x_b])\n",
    "        x_g = self.attention(x_g, attention_mask = attention_mask)\n",
    "        x_c = self.cross_attention(x_f, x_b, attention_mask = attention_mask)\n",
    "        x = self.add([x_g, x_c])\n",
    "\n",
    "        # feedforward\n",
    "        x = self.ff(x)\n",
    "        x = self.ff2(x)\n",
    "\n",
    "        # encoder layers\n",
    "        for layer in self.encoder_layers:\n",
    "            x = layer(x, attention_mask = attention_mask)\n",
    "\n",
    "        # output\n",
    "        x = self.out_shape(self.outs(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:09:42.930488Z",
     "start_time": "2023-10-05T17:09:42.864218Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-07 10:45:55.649647: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-07 10:45:55.695556: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-07 10:45:55.695927: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-07 10:45:55.698034: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-07 10:45:55.698382: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-07 10:45:55.698694: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-07 10:45:55.796778: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-07 10:45:55.797034: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-07 10:45:55.797246: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-07 10:45:55.797400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10013 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:06:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"attention_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  1024      \n",
      "                                                                 \n",
      " sine_position_encoding (Sin  multiple                 0         \n",
      " ePositionEncoding)                                              \n",
      "                                                                 \n",
      " conv1d (Conv1D)             multiple                  1048832   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           multiple                  1048832   \n",
      "                                                                 \n",
      " add (Add)                   multiple                  0         \n",
      "                                                                 \n",
      " global_self_attention (Glob  multiple                 2104064   \n",
      " alSelfAttention)                                                \n",
      "                                                                 \n",
      " cross_attention (CrossAtten  multiple                 2104064   \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  263168    \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  262400    \n",
      "                                                                 \n",
      " encoder_layer (EncoderLayer  multiple                 2630144   \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense_4 (Dense)             multiple                  257       \n",
      "                                                                 \n",
      " reshape (Reshape)           multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,462,785\n",
      "Trainable params: 9,462,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = AttentionModel(context_window=16, latent_dim=256, feedforward_dim=1024, num_encoder_layers=1, num_attention_heads=8)\n",
    "model.build((None, NUM_REACTIVITIES))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.AdamW(learning_rate=1e-4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = tf.keras.losses.MeanAbsoluteError(reduction=tf.keras.losses.Reduction.SUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:09:43.992618Z",
     "start_time": "2023-10-05T17:09:43.053099Z"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_batch(m: keras.Model, inps: tf.Tensor, outs: tf.Tensor, masks: tf.Tensor):\n",
    "    \"\"\"\n",
    "    Get the loss on a batch and perform the corresponding weight updates.\n",
    "    Used for training purposes\n",
    "    \"\"\"\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        preds = tf.expand_dims(m(inps, training=True), axis=-1)\n",
    "        outs = tf.expand_dims(outs, axis=-1)\n",
    "\n",
    "        loss = 0.0\n",
    "        for b in range(inps.shape[0]):\n",
    "            loss += mae(outs[b], preds[b], sample_weight=masks[b])\n",
    "\n",
    "        # turn it into mean\n",
    "        loss /= inps.shape[0]\n",
    "\n",
    "        # add the regularization losses\n",
    "        if len(m.losses) > 0:\n",
    "            regularization_loss = tf.add_n(m.losses)\n",
    "            loss += regularization_loss\n",
    "        else:\n",
    "            regularization_loss = 0.0\n",
    "\n",
    "        # calculate gradients\n",
    "        grads = tape.gradient(loss, m.trainable_variables)\n",
    "\n",
    "    # apply grads\n",
    "    m.optimizer.apply_gradients(zip(grads, m.trainable_variables))\n",
    "\n",
    "    # return total loss, mae loss\n",
    "    return loss, loss - regularization_loss\n",
    "\n",
    "@tf.function\n",
    "def noupdate_batch(m: keras.Model, inps: tf.Tensor, outs: tf.Tensor, masks: tf.Tensor):\n",
    "    \"\"\"\n",
    "    Get the loss on a batch without performing any updates.\n",
    "    Used for validation purposes\n",
    "    \"\"\"\n",
    "    preds = tf.expand_dims(m(inps, training=False), axis=-1)\n",
    "    outs = tf.expand_dims(outs, axis=-1)\n",
    "\n",
    "    loss = 0.0\n",
    "    mae = tf.keras.losses.MeanAbsoluteError(reduction=tf.keras.losses.Reduction.SUM)\n",
    "    for b in range(inps.shape[0]):\n",
    "        loss += mae(preds[b], outs[b], sample_weight=masks[b])\n",
    "\n",
    "    # turn it into mean\n",
    "    loss /= inps.shape[0]\n",
    "\n",
    "    # return mae loss\n",
    "    return loss\n",
    "\n",
    "\n",
    "def masked_train(\n",
    "    m: keras.Model,\n",
    "    x: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    masks: np.ndarray,\n",
    "    batch_size: int = 32,\n",
    "    epochs: int = 1,\n",
    "    validation_split: float = 0.1\n",
    "):\n",
    "    \"\"\"\n",
    "    Train the given model.\n",
    "\n",
    "    Arguments:\n",
    "        - m: keras.Model - the model to train.\n",
    "        - x: np.ndarray - the numpy array of inputs.\n",
    "        - y: np.ndarray - the numpy array of outputs.\n",
    "        - masks: np.ndarray - the sample weights (1s and 0s).\n",
    "        - batch_size: int - how large the batches should be. Defaults to `32`.\n",
    "        - epochs: int - how many epochs to train for. Defaults to `1`.\n",
    "        - validation_split: float - how large the validation subset should be, in the range (0, 1]. Defaults to `0.1`.\n",
    "\n",
    "    Note - The choice of np.ndarray is purely arbitrary, and this function can be modified to use tf.Tensors\n",
    "\n",
    "    Note - shuffle code is provided in numpy, but commented out because of memory limitations that less powerful computers\n",
    "    may encounter.\n",
    "    \"\"\"\n",
    "    # shuffle\n",
    "    # shuffled_idxs = np.arange(x.shape[0])\n",
    "    # np.random.shuffle(shuffled_idxs)\n",
    "    # x = x[shuffled_idxs]\n",
    "    # y = y[shuffled_idxs]\n",
    "    # masks = masks[shuffled_idxs]\n",
    "\n",
    "    # generate validation\n",
    "    validation_size = int(x.shape[0] * validation_split)\n",
    "    x_val = x[:validation_size]\n",
    "    y_val = y[:validation_size]\n",
    "    masks_val = masks[:validation_size]\n",
    "    x = x[validation_size:]\n",
    "    y = y[validation_size:]\n",
    "    masks = masks[validation_size:]\n",
    "\n",
    "    # calculate number of batches to do\n",
    "    num_batches = x.shape[0] // batch_size\n",
    "    if x.shape[0] % batch_size != 0:\n",
    "        num_batches += 1\n",
    "\n",
    "    num_validation_batches = x_val.shape[0] // batch_size\n",
    "    if x_val.shape[0] % batch_size != 0:\n",
    "        num_validation_batches += 1\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"Epoch {epoch}\")\n",
    "        epoch_loss = 0.0\n",
    "        epoch_mae = 0.0\n",
    "\n",
    "        for batch in range(num_batches):\n",
    "            num_items = min(batch_size, x.shape[0] - batch * batch_size)\n",
    "\n",
    "            inps = tf.constant(x[batch * batch_size : batch * batch_size + num_items])\n",
    "            outs = tf.constant(y[batch * batch_size : batch * batch_size + num_items])\n",
    "            masks_ = tf.constant(\n",
    "                masks[batch * batch_size : batch * batch_size + num_items]\n",
    "            )\n",
    "\n",
    "            loss, mae_loss = train_batch(m, inps, outs, masks_)\n",
    "\n",
    "            epoch_loss += loss\n",
    "            epoch_mae += mae_loss\n",
    "\n",
    "            # log\n",
    "            print(\n",
    "                f\"Batch {batch+1}/{num_batches}\\t- loss: {loss.numpy():.5f}\\t- mae loss: {mae_loss.numpy():.5f}\",\n",
    "                end=\"\\r\",\n",
    "            )\n",
    "        epoch_loss /= num_batches\n",
    "        epoch_mae /= num_batches\n",
    "\n",
    "        # do validation\n",
    "        val_mae = 0.0\n",
    "        for batch in range(num_validation_batches):\n",
    "            num_items = min(batch_size, x_val.shape[0] - batch * batch_size)\n",
    "\n",
    "            inps = tf.constant(\n",
    "                x_val[batch * batch_size : batch * batch_size + num_items]\n",
    "            )\n",
    "            outs = tf.constant(\n",
    "                y_val[batch * batch_size : batch * batch_size + num_items]\n",
    "            )\n",
    "            masks_ = tf.constant(\n",
    "                masks_val[batch * batch_size : batch * batch_size + num_items]\n",
    "            )\n",
    "\n",
    "            mae_loss = noupdate_batch(m, inps, outs, masks_)\n",
    "\n",
    "            val_mae += mae_loss\n",
    "        val_mae /= num_validation_batches\n",
    "\n",
    "        # shuffle\n",
    "        # shuffled_idxs = np.arange(x.shape[0])\n",
    "        # np.random.shuffle(shuffled_idxs)\n",
    "        # x = x[shuffled_idxs]\n",
    "        # y = y[shuffled_idxs]\n",
    "        # masks = masks[shuffled_idxs]\n",
    "\n",
    "        print()\n",
    "        print(\n",
    "            f\"Epoch loss: {epoch_loss:.5f}\\tEpoch MAE: {epoch_mae:.5f}\\tVal MAE: {val_mae:.5f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:14:00.128074Z",
     "start_time": "2023-10-05T17:09:43.998369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-07 10:46:04.229385: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-10-07 10:46:04.730024: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-10-07 10:46:04.981784: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fc220010990 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-10-07 10:46:04.981828: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2023-10-07 10:46:04.987996: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-10-07 10:46:05.139130: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3192/3192\t- loss: 17.67981\t- mae loss: 17.67981\n",
      "Epoch loss: 14.15007\tEpoch MAE: 14.15007\tVal MAE: 22.38618\n",
      "Epoch 2\n",
      "Batch 3192/3192\t- loss: 14.70246\t- mae loss: 14.70246\n",
      "Epoch loss: 12.94919\tEpoch MAE: 12.94919\tVal MAE: 23.34550\n",
      "Epoch 3\n",
      "Batch 3192/3192\t- loss: 12.44912\t- mae loss: 12.44912\n",
      "Epoch loss: 12.56580\tEpoch MAE: 12.56580\tVal MAE: 23.70991\n",
      "Epoch 4\n",
      "Batch 3192/3192\t- loss: 11.44859\t- mae loss: 11.44859\n",
      "Epoch loss: 12.30172\tEpoch MAE: 12.30172\tVal MAE: 22.87072\n",
      "Epoch 5\n",
      "Batch 3192/3192\t- loss: 11.39549\t- mae loss: 11.39549\n",
      "Epoch loss: 12.07011\tEpoch MAE: 12.07011\tVal MAE: 22.77704\n",
      "Epoch 6\n",
      "Batch 3192/3192\t- loss: 10.73919\t- mae loss: 10.73919\n",
      "Epoch loss: 11.87783\tEpoch MAE: 11.87783\tVal MAE: 21.89330\n",
      "Epoch 7\n",
      "Batch 3192/3192\t- loss: 10.64915\t- mae loss: 10.64915\n",
      "Epoch loss: 11.71720\tEpoch MAE: 11.71720\tVal MAE: 21.20430\n",
      "Epoch 8\n",
      "Batch 3192/3192\t- loss: 10.49534\t- mae loss: 10.49534\n",
      "Epoch loss: 11.57877\tEpoch MAE: 11.57877\tVal MAE: 21.08699\n",
      "Epoch 9\n",
      "Batch 3192/3192\t- loss: 10.42767\t- mae loss: 10.42767\n",
      "Epoch loss: 11.45956\tEpoch MAE: 11.45956\tVal MAE: 20.87154\n",
      "Epoch 10\n",
      "Batch 3192/3192\t- loss: 10.55130\t- mae loss: 10.55130\n",
      "Epoch loss: 11.35027\tEpoch MAE: 11.35027\tVal MAE: 20.17728\n",
      "Epoch 11\n",
      "Batch 3192/3192\t- loss: 10.24722\t- mae loss: 10.24722\n",
      "Epoch loss: 11.24304\tEpoch MAE: 11.24304\tVal MAE: 20.26415\n",
      "Epoch 12\n",
      "Batch 3192/3192\t- loss: 10.33754\t- mae loss: 10.33754\n",
      "Epoch loss: 11.14611\tEpoch MAE: 11.14611\tVal MAE: 20.46096\n",
      "Epoch 13\n",
      "Batch 3192/3192\t- loss: 10.00504\t- mae loss: 10.00504\n",
      "Epoch loss: 11.06287\tEpoch MAE: 11.06287\tVal MAE: 20.06654\n",
      "Epoch 14\n",
      "Batch 3192/3192\t- loss: 10.02834\t- mae loss: 10.02834\n",
      "Epoch loss: 10.97353\tEpoch MAE: 10.97353\tVal MAE: 19.76429\n",
      "Epoch 15\n",
      "Batch 3192/3192\t- loss: 9.74200\t- mae loss: 9.7420090\n",
      "Epoch loss: 10.88664\tEpoch MAE: 10.88664\tVal MAE: 19.90711\n",
      "Epoch 16\n",
      "Batch 3192/3192\t- loss: 9.84996\t- mae loss: 9.8499657\n",
      "Epoch loss: 10.77174\tEpoch MAE: 10.77174\tVal MAE: 19.58956\n",
      "Epoch 17\n",
      "Batch 3192/3192\t- loss: 9.98510\t- mae loss: 9.9851089\n",
      "Epoch loss: 10.62983\tEpoch MAE: 10.62983\tVal MAE: 19.35465\n",
      "Epoch 18\n",
      "Batch 3192/3192\t- loss: 10.01390\t- mae loss: 10.01390\n",
      "Epoch loss: 10.50532\tEpoch MAE: 10.50532\tVal MAE: 19.20664\n",
      "Epoch 19\n",
      "Batch 3192/3192\t- loss: 9.75317\t- mae loss: 9.7531758\n",
      "Epoch loss: 10.41757\tEpoch MAE: 10.41757\tVal MAE: 18.90891\n",
      "Epoch 20\n",
      "Batch 3192/3192\t- loss: 9.95236\t- mae loss: 9.9523667\n",
      "Epoch loss: 10.33738\tEpoch MAE: 10.33738\tVal MAE: 19.06694\n"
     ]
    }
   ],
   "source": [
    "masked_train(model, inputs, outputs, output_masks, epochs=20, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section saves the current model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:14:00.616528Z",
     "start_time": "2023-10-05T17:14:00.119617Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-07 21:58:56.029039: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,457,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-10-07 21:58:56.051029: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'x' with dtype float and shape [?,457,256]\n",
      "\t [[{{node x}}]]\n",
      "2023-10-07 21:58:56.060166: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'x' with dtype float and shape [?,457,256]\n",
      "\t [[{{node x}}]]\n",
      "2023-10-07 21:58:56.070528: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'x' with dtype float and shape [?,457,256]\n",
      "\t [[{{node x}}]]\n",
      "2023-10-07 21:58:56.080230: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'x' with dtype float and shape [?,457,256]\n",
      "\t [[{{node x}}]]\n",
      "2023-10-07 21:58:56.086627: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,457,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-10-07 21:58:56.092102: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,457,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-10-07 21:58:56.105129: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'x' with dtype float and shape [?,457,256]\n",
      "\t [[{{node x}}]]\n",
      "2023-10-07 21:58:56.118885: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'x' with dtype float and shape [?,457,256]\n",
      "\t [[{{node x}}]]\n",
      "2023-10-07 21:58:56.125626: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,457,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-10-07 21:58:56.129740: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,457,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-10-07 21:58:57.084142: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,457,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-10-07 21:58:57.152730: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'x' with dtype float and shape [?,457,256]\n",
      "\t [[{{node x}}]]\n",
      "2023-10-07 21:58:57.161238: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'x' with dtype float and shape [?,457,256]\n",
      "\t [[{{node x}}]]\n",
      "2023-10-07 21:58:57.256076: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'x' with dtype float and shape [?,457,256]\n",
      "\t [[{{node x}}]]\n",
      "2023-10-07 21:58:57.264900: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'x' with dtype float and shape [?,457,256]\n",
      "\t [[{{node x}}]]\n",
      "2023-10-07 21:58:57.358152: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,457,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-10-07 21:58:57.382197: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,457,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-10-07 21:58:57.409562: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,457,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-10-07 21:58:57.428415: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,457,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-10-07 21:58:57.501450: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'x' with dtype float and shape [?,457,256]\n",
      "\t [[{{node x}}]]\n",
      "2023-10-07 21:58:57.514886: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'x' with dtype float and shape [?,457,256]\n",
      "\t [[{{node x}}]]\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, multi_head_attention_layer_call_fn, multi_head_attention_layer_call_and_return_conditional_losses, layer_normalization_layer_call_fn while saving (showing 5 of 66). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: dms_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: dms_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(f\"{desired_dataset}_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section of the noteboook creates a zipped csv submission file that can\n",
    "be submitted on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:14:00.624146Z",
     "start_time": "2023-10-05T17:14:00.601389Z"
    }
   },
   "outputs": [],
   "source": [
    "make_submissions = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:14:01.233216Z",
     "start_time": "2023-10-05T17:14:00.608006Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-07 22:00:29.387783: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-07 22:00:29.425810: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-07 22:00:29.426099: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-07 22:00:29.427898: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-07 22:00:29.428134: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-07 22:00:29.428348: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-07 22:00:29.520208: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-07 22:00:29.520478: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-07 22:00:29.520704: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-07 22:00:29.520868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10010 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:06:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "valid = False\n",
    "\n",
    "if (\n",
    "    os.path.exists(\"2a3_model\")\n",
    "    and os.path.exists(\"dms_model\")\n",
    "    and os.path.exists(\"test_sequences.csv\")\n",
    "    and make_submissions\n",
    "):\n",
    "    valid = True\n",
    "    model_2a3 = keras.models.load_model(\"2a3_model\")\n",
    "    model_dms = keras.models.load_model(\"dms_model\")\n",
    "else:\n",
    "    print(\"Not going to create submissions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:14:01.247263Z",
     "start_time": "2023-10-05T17:14:01.233464Z"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def call_model(model_2a3, model_dms, inputs):\n",
    "    return model_2a3(inputs, training=False), model_dms(inputs, training=False)\n",
    "\n",
    "\n",
    "def pipeline(\n",
    "    model_2a3: keras.Model,\n",
    "    model_dms: keras.Model,\n",
    "    input_csv: str,\n",
    "    out: str,\n",
    "    batch_size: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    Process test data and write submissions to a csv file\n",
    "\n",
    "    Arguments:\n",
    "        - model_2a3: keras.Model - the model trained on the 2a3 distribution\n",
    "        - model_dms: keras.Model - the model trained on the dms distribution\n",
    "        - input_csv: str - the name of the file that contains the test data\n",
    "        - out: str - the name of the file to write predictions to\n",
    "        - batch_size: int - how many predictions to make at a time\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "\n",
    "    # count how many lines we have in total\n",
    "    with open(input_csv) as file:\n",
    "        line = file.readline()  # ignore the header\n",
    "        # take the first line since we increment count in the loop\n",
    "        line = file.readline()\n",
    "        while line != \"\":\n",
    "            count += 1\n",
    "            line = file.readline()\n",
    "\n",
    "    # use that knowledge for a progress bar\n",
    "    with open(input_csv, \"r\") as file, open(out, \"w\") as outfile:\n",
    "        # write the header\n",
    "        outfile.write(\"id,reactivity_DMS_MaP,reactivity_2A3_MaP\\n\")\n",
    "\n",
    "        # get what index the things we need are\n",
    "        header = file.readline()\n",
    "        split_header = header.split(\",\")\n",
    "        min_idx = split_header.index(\"id_min\")\n",
    "        max_idx = split_header.index(\"id_max\")\n",
    "        sequence_idx = split_header.index(\"sequence\")\n",
    "\n",
    "        # only take the approved filtered lines\n",
    "        num_batches = count // batch_size\n",
    "        if count % batch_size != 0:\n",
    "            num_batches += 1\n",
    "        for batch in tqdm(range(num_batches)):\n",
    "            num_items = min(batch_size, count - batch * batch_size)\n",
    "\n",
    "            # initialize variables\n",
    "            inputs = np.zeros((num_items, NUM_REACTIVITIES))\n",
    "            min_seq_idxs = []\n",
    "            sequence_lengths = []\n",
    "\n",
    "            # collect the inputs\n",
    "            for i in range(num_items):\n",
    "                line = file.readline()\n",
    "                temp = line.split(\",\")\n",
    "                sequence = temp[sequence_idx]\n",
    "                max_seq_idx = int(temp[max_idx])\n",
    "                min_seq_idx = int(temp[min_idx])\n",
    "\n",
    "                # verify that everything is correct\n",
    "                assert len(sequence) + min_seq_idx - 1 == max_seq_idx\n",
    "\n",
    "                # store the data\n",
    "                inputs[i, : len(sequence)] = np.array(\n",
    "                    list(map(lambda letter: base_map[letter], sequence))\n",
    "                )\n",
    "                min_seq_idxs.append(min_seq_idx)\n",
    "                sequence_lengths.append(len(sequence))\n",
    "\n",
    "            # run inputs through the associated model\n",
    "            probs_2a3, probs_dms = call_model(model_2a3, model_dms, inputs)\n",
    "            probs_dms = np.squeeze(probs_dms.numpy())\n",
    "            probs_2a3 = np.squeeze(probs_2a3.numpy())\n",
    "\n",
    "            # write predictions\n",
    "            for i in range(num_items):\n",
    "                for seq_idx in range(\n",
    "                    min_seq_idxs[i], min_seq_idxs[i] + sequence_lengths[i]\n",
    "                ):\n",
    "                    outfile.write(\n",
    "                        f\"{seq_idx},{probs_dms[i, seq_idx - min_seq_idxs[i]]:.3f},{probs_2a3[i, seq_idx - min_seq_idxs[i]]:.3f}\\n\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-05T17:14:01.248308Z"
    },
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20998 [00:00<?, ?it/s]2023-10-07 22:00:33.968676: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-10-07 22:00:34.430620: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "100%|██████████| 20998/20998 [2:37:38<00:00,  2.22it/s]  \n"
     ]
    }
   ],
   "source": [
    "if valid:\n",
    "    pipeline(\n",
    "        model_2a3, model_dms, \"test_sequences.csv\", \"submission.csv\", batch_size=64\n",
    "    )\n",
    "else:\n",
    "    print(\"Not going to create submissions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zipping submissions. This may take a while...\n",
      "updating: submission.csv (deflated 72%)\n",
      "Done zipping submissions!\n"
     ]
    }
   ],
   "source": [
    "if valid:\n",
    "    # zip our submission into an easily-uploadable zip file\n",
    "    print(\"zipping submissions. This may take a while...\")\n",
    "    os.system(\"zip submission.csv.zip submission.csv\")\n",
    "    print(\"Done zipping submissions!\")\n",
    "else:\n",
    "    print(\"Not going to zip submissions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
