{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ribonanza - Attempt 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A second approach to the [Stanford Ribonanza problem](https://www.kaggle.com/competitions/stanford-ribonanza-rna-folding/) that builds off the first and second approaches.\n",
    "\n",
    "Major differences:\n",
    "- use of pytorch instead of tensorflow\n",
    "- use of attention model architecture\n",
    "- use bpp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, the attention architecture scores 0.182"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- experiment with other types of attention\n",
    "- try using LinearFold instead of EternaFold\n",
    "- try using ThreshKnot instead of EternaFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filesystem Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your project directory should look like this:\n",
    "\n",
    "- `(project directory)`\n",
    "    - `ribonanza2.ipynb`\n",
    "    - `train_data.csv`\n",
    "    - `test_data.csv` (optional)\n",
    "\n",
    "`train_data.csv` is the only file necessary for training, and it can be downloaded from the kaggle competition linked in the description.\n",
    "\n",
    "`test_data.csv` is only necessary if you intend to make and submit predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependency Seetup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to install pip packages:\n",
    "```sh\n",
    "pip install torch numpy seaborn xformers arnie datasets tensorboard\n",
    "```\n",
    "Need to install conda packages for eternafold:\n",
    "```sh\n",
    "conda install -c conda-forge \"libgcc-ng>=12\" \"libstdcxx-ng>=12\"\n",
    "conda install -c bioconda eternafold\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset\n",
    "import os\n",
    "\n",
    "# for visualization\n",
    "import seaborn\n",
    "\n",
    "# typing hints\n",
    "from typing import List\n",
    "from collections.abc import Callable\n",
    "\n",
    "# used for better attention mechanisms\n",
    "import xformers.components.positional_embedding as embeddings\n",
    "import xformers.ops as xops\n",
    "import xformers.components.attention as attentions\n",
    "import xformers.components.attention.utils as att_utils\n",
    "import xformers.components as components\n",
    "\n",
    "# used for bpps\n",
    "from arnie.bpps import bpps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "# according to kaggle, this is the maximum # of reactivites to be used\n",
    "NUM_REACTIVITIES = 457\n",
    "\n",
    "# there are 4 different bases (AUCG)\n",
    "NUM_BASES = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\"  # if no gpu available, use cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(out: str, key: str, value: str, file_name: str, force: bool):\n",
    "    \"\"\"\n",
    "    Filters a file to only take datapoints\n",
    "    whose values of `key` are `value`.\n",
    "\n",
    "    Parameters:\n",
    "        - out: str - the name of the file that will store the filtered datapoints\n",
    "        - key: str - the name of the key to look at\n",
    "        - value: str - the value that the key should have\n",
    "        - file_name: str - the name of the file that contains all the datapoints.\n",
    "        - force: bool - whether or not to force re-processing of the data (if False and `out` already exists, no work will be done)\n",
    "    \"\"\"\n",
    "    if os.path.exists(out) and not force:\n",
    "        print(\"File already exists, not doing any work\")\n",
    "        return\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    # count how many lines we have in total\n",
    "    with open(file_name) as file:\n",
    "        line = file.readline()  # ignore the header\n",
    "        line = (\n",
    "            file.readline()\n",
    "        )  # take the first line since we increment count in the loop\n",
    "        while line != \"\":\n",
    "            count += 1\n",
    "            line = file.readline()\n",
    "\n",
    "    # use that knowledge for a progress bar\n",
    "    with open(file_name, \"r\") as file, open(out, \"w\") as outfile:\n",
    "        # write the header\n",
    "        header = file.readline()\n",
    "        outfile.write(header)\n",
    "\n",
    "        # get what index the SN_filter is\n",
    "        SN_idx = header.split(\",\").index(key)\n",
    "\n",
    "        # only take the approved filtered lines\n",
    "        for _ in tqdm(range(count)):\n",
    "            line = file.readline()\n",
    "            temp = line.split(\",\")\n",
    "            if temp[SN_idx] == value:\n",
    "                outfile.write(line)\n",
    "\n",
    "\n",
    "def filter_train_data(force: bool = False):\n",
    "    \"\"\"\n",
    "    Filters the immense train_data.csv to only take datapoints\n",
    "    whose SN_filter (Signal to Noise filter) is 1. In other words,\n",
    "    we only take good reads. These filtered datapoints are then\n",
    "    written to the file provided\n",
    "\n",
    "    Parameters:\n",
    "        - force: bool - whether or not to force re-processing of the data (if False and `out` already exists, no work will be done)\n",
    "    \"\"\"\n",
    "    filter_data(\"train_data_filtered.csv\", \"SN_filter\", \"1\", \"train_data.csv\", force)\n",
    "\n",
    "\n",
    "def filter_2A3(force: bool = False):\n",
    "    \"\"\"\n",
    "    Only take the 2A3 points\n",
    "\n",
    "    Parameters:\n",
    "        - force: bool - whether or not to force re-processing of the data (if False and `out` already exists, no work will be done)\n",
    "    \"\"\"\n",
    "    filter_data(\n",
    "        \"train_data_2a3.csv\",\n",
    "        \"experiment_type\",\n",
    "        \"2A3_MaP\",\n",
    "        \"train_data_filtered.csv\",\n",
    "        force,\n",
    "    )\n",
    "\n",
    "\n",
    "def filter_DMS(force: bool = False):\n",
    "    \"\"\"\n",
    "    Only take the DMS points\n",
    "\n",
    "    Parameters:\n",
    "        - force: bool - whether or not to force re-processing of the data (if False and `out` already exists, no work will be done)\n",
    "    \"\"\"\n",
    "    filter_data(\n",
    "        \"train_data_dms.csv\",\n",
    "        \"experiment_type\",\n",
    "        \"DMS_MaP\",\n",
    "        \"train_data_filtered.csv\",\n",
    "        force,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1643680/1643680 [00:18<00:00, 88557.06it/s] \n"
     ]
    }
   ],
   "source": [
    "# filter our data\n",
    "filter_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 437917/437917 [00:05<00:00, 76366.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# take the 2a3 points\n",
    "filter_2A3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 437917/437917 [00:05<00:00, 78839.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# take the dms points\n",
    "filter_DMS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Data to Inputs and Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode inputs as\n",
    "# A : 1\n",
    "# U : 2\n",
    "# C : 3\n",
    "# G : 4\n",
    "base_map = {\n",
    "    \"A\": 1,\n",
    "    \"U\": 2,\n",
    "    \"C\": 3,\n",
    "    \"G\": 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(row):\n",
    "    \"\"\"\n",
    "    Convert a row containing all csv columns in the original dataset\n",
    "    to a row containing only the columns:\n",
    "    - inputs\n",
    "    - outputs\n",
    "    - bpp\n",
    "    - output_masks\n",
    "    - reactivity_error\n",
    "    - bool_output_masks\n",
    "    \"\"\"\n",
    "    # initialize arrays\n",
    "    # note that we assume everything is masked until told otherwise\n",
    "    inputs = np.zeros((NUM_REACTIVITIES,), dtype=np.float32)\n",
    "    bpp = np.zeros((NUM_REACTIVITIES,), dtype=np.float32)\n",
    "    output_masks = np.ones((NUM_REACTIVITIES,), dtype=np.bool_)\n",
    "    reactivity_errors = np.zeros((NUM_REACTIVITIES,), dtype=np.float32)\n",
    "    reactivities = np.zeros((NUM_REACTIVITIES,), dtype=np.float32)\n",
    "\n",
    "    seq_len = len(row[\"sequence\"])\n",
    "\n",
    "    # encode the bases\n",
    "    inputs[:seq_len] = np.array(\n",
    "        list(map(lambda letter: base_map[letter], row[\"sequence\"]))\n",
    "    )\n",
    "\n",
    "    # get the probability that any of those bases are paired\n",
    "    bpp[:seq_len] = np.max(bpps(row[\"sequence\"], package=\"eternafold\"), axis=-1)\n",
    "\n",
    "    # get the reactivities and their errors\n",
    "    reactivities[:seq_len] = np.array(\n",
    "        list(\n",
    "            map(\n",
    "                lambda seq_idx: np.float32(\n",
    "                    row[\"reactivity_\" + str(seq_idx + 1).rjust(4, \"0\")]\n",
    "                ),\n",
    "                range(seq_len),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    reactivity_errors[:seq_len] = np.array(\n",
    "        list(\n",
    "            map(\n",
    "                lambda seq_idx: np.float32(\n",
    "                    row[\"reactivity_error_\" + str(seq_idx + 1).rjust(4, \"0\")]\n",
    "                ),\n",
    "                range(seq_len),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # replace reactivity error nans with 0s (assume no error)\n",
    "    reactivity_errors = np.where(np.isnan(reactivity_errors), 0.0, reactivity_errors)\n",
    "\n",
    "    # get where all the reactivities are nan\n",
    "    nan_locats = np.isnan(reactivities)\n",
    "\n",
    "    # where it is nan, store True, else False\n",
    "    output_masks[:seq_len] = nan_locats[:seq_len]\n",
    "\n",
    "    # where it is not nan, store the reactivity and error, else 0\n",
    "    reactivities[:seq_len] = np.where(\n",
    "        nan_locats[:seq_len] == False, reactivities[:seq_len], 0.0\n",
    "    )\n",
    "    reactivity_errors[:seq_len] = np.where(\n",
    "        nan_locats[:seq_len] == False, reactivity_errors[:seq_len], 0.0\n",
    "    )\n",
    "\n",
    "    # store the values\n",
    "    row = {}\n",
    "    row[\"inputs\"] = inputs\n",
    "    row[\"bpp\"] = bpp\n",
    "    row[\"outputs\"] = np.clip(reactivities, 0, 1)\n",
    "    row[\"output_masks\"] = np.clip(\n",
    "        np.where(output_masks, 0.0, 1.0) - np.abs(reactivity_errors), 0, 1\n",
    "    )\n",
    "    row[\"bool_output_masks\"] = output_masks\n",
    "    row[\"reactivity_errors\"] = np.abs(reactivity_errors)\n",
    "\n",
    "    return row\n",
    "\n",
    "\n",
    "def process_data_test(row):\n",
    "    \"\"\"\n",
    "    Almost the same as process_data, except it only takes inputs and bpp\n",
    "    \"\"\"\n",
    "    # initialize arrays\n",
    "    # note that we assume everything is masked until told otherwise\n",
    "    inputs = np.zeros((NUM_REACTIVITIES,), dtype=np.float32)\n",
    "    bpp = np.zeros((NUM_REACTIVITIES,), dtype=np.float32)\n",
    "\n",
    "    seq_len = len(row[\"sequence\"])\n",
    "\n",
    "    # encode the bases\n",
    "    inputs[:seq_len] = np.array(\n",
    "        list(map(lambda letter: base_map[letter], row[\"sequence\"]))\n",
    "    )\n",
    "\n",
    "    # get the probability that any of those bases are paired\n",
    "    bpp[:seq_len] = np.max(bpps(row[\"sequence\"], package=\"eternafold\"), axis=-1)\n",
    "\n",
    "    row[\"inputs\"] = inputs\n",
    "    row[\"bpp\"] = bpp\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_csv(\n",
    "    out: str,\n",
    "    file_name: str,\n",
    "    n_proc: int = 12,\n",
    "    map_fn: Callable = process_data,\n",
    "    extra_cols_to_keep: List[str] = [],\n",
    "):\n",
    "    \"\"\"\n",
    "    Preprocess the csv and save the preprocessed data as a dataset\n",
    "    that can be loaded via datasets.Dataset.load_from_file\n",
    "\n",
    "    The dataset contains the following items:\n",
    "        - bool_output_masks: Tensor(dtype=torch.bool) - the output masks.\n",
    "            If True, then that item should NOT be used to calculate loss.\n",
    "            If False, then that item should be used to calculate loss\n",
    "        - reactivity_errors: Tensor(dtype=torch.float32) - the reactivity errors\n",
    "        - output_masks: Tensor(dtype=torch.float32) - the elementwise weights to multiply the loss by to properly\n",
    "            account for masked items and reactivity errors\n",
    "        - inputs: tensor(dtype=torch.float32) - the input sequence, specifically of shape (None, NUM_REACTIVITIES)\n",
    "        - bpp: tensor(dtype=torch.float32)\n",
    "        - outputs: tensor(dtype=torch.float32) - the expected reactivities. Note that a simple MAE or MSE loss will not\n",
    "            suffice for training models on this dataset. Please use the output_masks tensor as well.\n",
    "\n",
    "    Parameters:\n",
    "        - out: str - the name of the file to save the arrays to\n",
    "        - file_name: str - the name of the input csv file\n",
    "        - n_proc: int - the number of processes to use while processing data\n",
    "        - map_fn: Callable - the function to apply to all dataset rows\n",
    "        - extra_cols_to_keep: List[str] - the names of any extra columns to keep in the dataset\n",
    "    \"\"\"\n",
    "    if os.path.exists(out):\n",
    "        print(\n",
    "            \"File already exists, not doing any work.\\n\"\n",
    "            + \"To force re-preprocessing, delete the dataset directory and restart the kernel.\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    names_to_keep = [\n",
    "        \"reactivity_errors\",\n",
    "        \"bool_output_masks\",\n",
    "        \"output_masks\",\n",
    "        \"inputs\",\n",
    "        \"outputs\",\n",
    "        \"bpp\",\n",
    "    ] + extra_cols_to_keep\n",
    "\n",
    "    # load dataset and map it to our preprocess function\n",
    "    ds = Dataset.from_csv(file_name).map(map_fn, num_proc=n_proc)\n",
    "\n",
    "    # drop excess columns and save to disk\n",
    "    ds.remove_columns(\n",
    "        list(filter(lambda c: c not in names_to_keep, ds.column_names))\n",
    "    ).save_to_disk(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86d152960b614d5ca339697fbf265972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25cbb1e0a1b84e1e8a9ec7cf990c5f3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e28f2d649e540f79089a3cc0ef3f531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c21c1c966f745e6b7bf379d30789fe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=12):   0%|          | 0/210992 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preprocess_csv(\"train_data_2a3_preprocessed\", \"train_data_2a3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists, not doing any work.\n",
      "To force re-preprocessing, delete the dataset directory and restart the kernel.\n"
     ]
    }
   ],
   "source": [
    "preprocess_csv(\"train_data_dms_preprocessed\", \"train_data_dms.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists, not doing any work.\n",
      "To force re-preprocessing, delete the dataset directory and restart the kernel.\n"
     ]
    }
   ],
   "source": [
    "preprocess_csv(\n",
    "    \"test_data_preprocessed\",\n",
    "    \"test_sequences.csv\",\n",
    "    map_fn=process_data_test,\n",
    "    extra_cols_to_keep=[\"id_min\", \"id_max\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the desired dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:09:33.551791Z",
     "start_time": "2023-10-05T17:09:33.535197Z"
    }
   },
   "outputs": [],
   "source": [
    "desired_dataset = \"2a3\"  # either \"2a3\" or \"dms\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['inputs', 'bpp', 'outputs', 'output_masks', 'bool_output_masks', 'reactivity_errors'],\n",
       "    num_rows: 210992\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.load_from_disk(\n",
    "    f\"train_data_{desired_dataset}_preprocessed\"\n",
    ").with_format(\"torch\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set is len 189892 and val dataset is len 21100\n"
     ]
    }
   ],
   "source": [
    "columns = [\"inputs\", \"outputs\", \"output_masks\", \"bpp\"]\n",
    "split = dataset.train_test_split(test_size=0.1).select_columns(columns)\n",
    "train_dataset = split[\"train\"]\n",
    "val_dataset = split[\"test\"]\n",
    "\n",
    "print(\n",
    "    \"train set is len\", len(train_dataset), \"and val dataset is len\", len(val_dataset)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the dataset preprocessed, we can visualize what the distribution looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:09:42.844615Z",
     "start_time": "2023-10-05T17:09:42.843236Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(*args):\n",
    "    \"\"\"\n",
    "    Gets the product of all arguments passed to it\n",
    "    \"\"\"\n",
    "    prod = 1\n",
    "    for item in args:\n",
    "        prod *= item\n",
    "    return prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if visualize:\n",
    "    # select all the reactivities that are valid (that shouldn't be masked)\n",
    "    visualized_items = torch.masked_select(\n",
    "        dataset[\"outputs\"], dataset[\"bool_output_masks\"] == False\n",
    "    ).numpy()\n",
    "\n",
    "    # sanity check that we didn't take all the items\n",
    "    print(\n",
    "        f\"took {visualized_items.shape[0] / multiply(*dataset['outputs'].shape):.5f}% of the data\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:09:42.851272Z",
     "start_time": "2023-10-05T17:09:42.849526Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not visualizing. Set `visualize` to `True` to visualize data\n"
     ]
    }
   ],
   "source": [
    "if visualize:\n",
    "    seaborn.histplot(visualized_items, binwidth=0.1)\n",
    "else:\n",
    "    print(\"Not visualizing. Set `visualize` to `True` to visualize data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To model our distribution, we have two models:\n",
    "- an AttentionModel that uses attention layers\n",
    "- a BaselineModel that we compare against that uses only a couple convolution layers and a Linear layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we establish a baseline model comprised of Linear and Convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineModel(torch.nn.Module):\n",
    "    def __init__(self, context_window: int = 31, device: str = DEVICE):\n",
    "        super(BaselineModel, self).__init__()\n",
    "        self.preLayer = torch.nn.Linear(2, 2).to(device)\n",
    "        self.conv_layer = torch.nn.Conv1d(2, 2, context_window, padding=\"same\").to(\n",
    "            device\n",
    "        )\n",
    "        self.conv_layer_b = torch.nn.Conv1d(2, 2, context_window, padding=\"same\").to(\n",
    "            device\n",
    "        )\n",
    "        self.ff = torch.nn.Linear(NUM_REACTIVITIES * 2, NUM_REACTIVITIES).to(device)\n",
    "        self.gelu = torch.nn.GELU()\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.gelu(self.preLayer(x))\n",
    "        x = x.reshape(x.shape[0], -1, x.shape[1])\n",
    "\n",
    "        x = self.gelu(\n",
    "            self.conv_layer(x)\n",
    "            + torch.flip(self.conv_layer_b(torch.flip(x, dims=[2])), dims=[2])\n",
    "        )\n",
    "\n",
    "        return self.relu(self.ff(x.flatten(start_dim=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can write our attention model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTransformerEncoderLayer(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        attention: components.Attention,\n",
    "        latent_dim: int,\n",
    "        ff_dim: int,\n",
    "        n_heads: int,\n",
    "        device: str = DEVICE,\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        super(CustomTransformerEncoderLayer, self).__init__()\n",
    "        self.attention = components.MultiHeadDispatch(\n",
    "            dim_model=latent_dim, num_heads=n_heads, attention=attention, **kwargs\n",
    "        ).to(device)\n",
    "        self.layer_norm = torch.nn.LayerNorm(latent_dim).to(device)\n",
    "\n",
    "        self.ff1 = torch.nn.Linear(latent_dim, ff_dim).to(device)\n",
    "        self.ff2 = torch.nn.Linear(ff_dim, latent_dim).to(device)\n",
    "        self.gelu = torch.nn.GELU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor, attention_mask: torch.Tensor):\n",
    "        # MHA self attention, add, norm\n",
    "        x = self.layer_norm(self.attention(x, att_mask=attention_mask) + x)\n",
    "\n",
    "        # ff, add, norm\n",
    "        x = self.layer_norm(self.gelu(self.ff2(self.gelu(self.ff1(x)))) + x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class CustomTransformerDecoderLayer(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        attention: components.Attention,\n",
    "        latent_dim: int,\n",
    "        ff_dim: int,\n",
    "        n_heads: int,\n",
    "        device: str = DEVICE,\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        super(CustomTransformerDecoderLayer, self).__init__()\n",
    "        self.crossattention = components.MultiHeadDispatch(\n",
    "            dim_model=latent_dim, num_heads=n_heads, attention=attention, **kwargs\n",
    "        ).to(device)\n",
    "\n",
    "        self.selfattention = components.MultiHeadDispatch(\n",
    "            dim_model=latent_dim, num_heads=n_heads, attention=attention, **kwargs\n",
    "        ).to(device)\n",
    "        self.layer_norm = torch.nn.LayerNorm(latent_dim).to(device)\n",
    "\n",
    "        self.ff1 = torch.nn.Linear(latent_dim, ff_dim).to(device)\n",
    "        self.ff2 = torch.nn.Linear(ff_dim, latent_dim).to(device)\n",
    "        self.gelu = torch.nn.GELU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor, ctx: torch.Tensor, attention_mask: torch.Tensor):\n",
    "        # MHA self attention, add norm\n",
    "        x = self.layer_norm(self.selfattention(x) + x)\n",
    "\n",
    "        # MHA cross attention, add, norm\n",
    "        x = self.layer_norm(\n",
    "            self.crossattention(key=ctx, query=ctx, value=x, att_mask=attention_mask)\n",
    "            + x\n",
    "        )\n",
    "\n",
    "        # ff, add, norm\n",
    "        x = self.layer_norm(self.gelu(self.ff2(self.gelu(self.ff1(x)))) + x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class CustomTransformerEncoder(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        attention_type: components.Attention,\n",
    "        n_layers: int,\n",
    "        latent_dim: int,\n",
    "        ff_dim: int,\n",
    "        n_heads: int,\n",
    "        device: str = DEVICE,\n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        super(CustomTransformerEncoder, self).__init__()\n",
    "        for i in range(n_layers):\n",
    "            self.add_module(\n",
    "                str(i),\n",
    "                CustomTransformerEncoderLayer(\n",
    "                    attention=attention_type,\n",
    "                    latent_dim=latent_dim,\n",
    "                    ff_dim=ff_dim,\n",
    "                    n_heads=n_heads,\n",
    "                    device=device,\n",
    "                    **kwargs\n",
    "                ),\n",
    "            )\n",
    "\n",
    "    def forward(self, x: torch.Tensor, attention_mask: torch.Tensor):\n",
    "        for module in self._modules.values():\n",
    "            x = module(x, attention_mask=attention_mask)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CustomTransformerDecoder(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        attention_type: components.Attention,\n",
    "        n_layers: int,\n",
    "        latent_dim: int,\n",
    "        ff_dim: int,\n",
    "        n_heads: int,\n",
    "        device: str = DEVICE,\n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        super(CustomTransformerDecoder, self).__init__()\n",
    "        for i in range(n_layers):\n",
    "            self.add_module(\n",
    "                str(i),\n",
    "                CustomTransformerDecoderLayer(\n",
    "                    attention=attention_type,\n",
    "                    latent_dim=latent_dim,\n",
    "                    ff_dim=ff_dim,\n",
    "                    n_heads=n_heads,\n",
    "                    device=device,\n",
    "                    **kwargs\n",
    "                ),\n",
    "            )\n",
    "\n",
    "    def forward(self, x: torch.Tensor, ctx: torch.Tensor, attention_mask: torch.Tensor):\n",
    "        for module in self._modules.values():\n",
    "            x = module(x, ctx, attention_mask=attention_mask)\n",
    "        return x\n",
    "\n",
    "\n",
    "class AttentionModel(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        attention_type: attentions.Attention = attentions.ScaledDotProduct(dropout=0.1),\n",
    "        latent_dim: int = 128,\n",
    "        ff_dim: int = 1024,\n",
    "        n_heads: int = 2,\n",
    "        enc_layers: int = 1,\n",
    "        dec_layers: int = 1,\n",
    "        device: str = DEVICE,\n",
    "    ) -> None:\n",
    "        super(AttentionModel, self).__init__()\n",
    "\n",
    "        # data\n",
    "        self.n_heads = n_heads\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        # projection layer\n",
    "        self.proj = torch.nn.Linear(2, latent_dim).to(device)\n",
    "\n",
    "        # positional embedding encoder/decoder layers\n",
    "        self.pos_embedding = embeddings.SinePositionalEmbedding(latent_dim).to(device)\n",
    "        self.has_encoder = enc_layers >= 1\n",
    "        self.has_decoder = dec_layers >= 1\n",
    "        if self.has_encoder:\n",
    "            self.encoder_layers = CustomTransformerEncoder(\n",
    "                latent_dim=latent_dim,\n",
    "                ff_dim=ff_dim,\n",
    "                n_heads=n_heads,\n",
    "                device=device,\n",
    "                attention_type=attention_type,\n",
    "                n_layers=enc_layers,\n",
    "            )\n",
    "        if self.has_decoder:\n",
    "            self.decoder_layers = CustomTransformerDecoder(\n",
    "                latent_dim=latent_dim,\n",
    "                ff_dim=ff_dim,\n",
    "                n_heads=n_heads,\n",
    "                attention_type=attention_type,\n",
    "                n_layers=dec_layers,\n",
    "            )\n",
    "\n",
    "        # output head\n",
    "        self.head = torch.nn.Linear(latent_dim, 1).to(device)\n",
    "        self.final_result = torch.nn.Linear(NUM_REACTIVITIES, NUM_REACTIVITIES).to(\n",
    "            device\n",
    "        )\n",
    "\n",
    "        # activations\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.gelu = torch.nn.GELU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        mask = att_utils.maybe_merge_masks(\n",
    "            att_mask=None,\n",
    "            key_padding_mask=(x != 0).any(dim=-1),\n",
    "            batch_size=x.shape[0],\n",
    "            num_heads=self.n_heads,\n",
    "            src_len=x.shape[1],\n",
    "        )\n",
    "\n",
    "        # project to latent dimension\n",
    "        x = self.proj(x)\n",
    "\n",
    "        # embed and then perform attention\n",
    "        x = self.pos_embedding(x)\n",
    "        if self.has_decoder and self.has_encoder:\n",
    "            x = self.decoder_layers(\n",
    "                x, ctx=self.encoder_layers(x, attention_mask=mask), attention_mask=mask\n",
    "            )\n",
    "        elif self.has_encoder:\n",
    "            x = self.encoder_layers(x, attention_mask=mask)\n",
    "        elif self.has_decoder:\n",
    "            x = self.decoder_layers(x, ctx=x, attention_mask=mask)\n",
    "\n",
    "        # final result\n",
    "        x = self.relu(self.final_result(self.gelu(self.head(x).flatten(start_dim=1))))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_baseline = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dms_kwargs = dict(\n",
    "    latent_dim=32,\n",
    "    n_heads=1,\n",
    "    enc_layers=4,\n",
    "    dec_layers=4,\n",
    "    ff_dim=2048,\n",
    ")\n",
    "model_2a3_kwargs = dict(\n",
    "    latent_dim=32,\n",
    "    n_heads=1,\n",
    "    enc_layers=4,\n",
    "    dec_layers=4,\n",
    "    ff_dim=2048,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the model\n",
    "if use_baseline:\n",
    "    model = BaselineModel()\n",
    "elif desired_dataset == \"dms\":\n",
    "    model = AttentionModel(**model_dms_kwargs)\n",
    "elif desired_dataset == \"2a3\":\n",
    "    model = AttentionModel(**model_2a3_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load old weights if possible\n",
    "if os.path.exists(f\"{desired_dataset}_model\"):\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(f\"{desired_dataset}_model\"))\n",
    "        print(\"loaded previous weights\")\n",
    "    except Exception as e:\n",
    "        print(\"not loading previous weights because\", e)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1661, 0.1917, 0.0000, 0.0226, 0.0216, 0.0000, 0.0000, 0.1297, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0534, 0.0514, 0.0353, 0.0000, 0.0000, 0.0241,\n",
       "         0.0000, 0.0168, 0.0082, 0.0000, 0.0000, 0.2082, 0.0000, 0.0000, 0.3466,\n",
       "         0.0320, 0.1227, 0.0000, 0.1147, 0.2009, 0.0000, 0.0000, 0.0000, 0.0418,\n",
       "         0.0000, 0.0000, 0.2318, 0.0232, 0.2241, 0.1276, 0.0000, 0.0000, 0.0000,\n",
       "         0.0518, 0.0713, 0.0022, 0.0000, 0.2042, 0.2147, 0.0000, 0.2107, 0.0000,\n",
       "         0.0857, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0283, 0.0000, 0.0257,\n",
       "         0.0155, 0.0000, 0.2107, 0.0000, 0.0069, 0.1242, 0.0000, 0.1265, 0.0000,\n",
       "         0.0000, 0.2558, 0.2531, 0.0923, 0.0710, 0.1986, 0.0000, 0.3856, 0.0000,\n",
       "         0.0000, 0.0000, 0.1005, 0.0000, 0.0096, 0.0000, 0.1856, 0.0034, 0.1289,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.1380, 0.0000, 0.0000, 0.0839, 0.0947,\n",
       "         0.0754, 0.0000, 0.0000, 0.1567, 0.0740, 0.0086, 0.1283, 0.0140, 0.1151,\n",
       "         0.0000, 0.0353, 0.0000, 0.0135, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0178, 0.0000, 0.0000, 0.1356, 0.0408, 0.1272, 0.0000, 0.0000, 0.2361,\n",
       "         0.0636, 0.0000, 0.0000, 0.2541, 0.2523, 0.0000, 0.0000, 0.0000, 0.1890,\n",
       "         0.1448, 0.0968, 0.0000, 0.0988, 0.0000, 0.0000, 0.0185, 0.1755, 0.0000,\n",
       "         0.0000, 0.1137, 0.0000, 0.0000, 0.0000, 0.0098, 0.1260, 0.2937, 0.0000,\n",
       "         0.0000, 0.0000, 0.1703, 0.0118, 0.0000, 0.1222, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.1204, 0.1045, 0.2153, 0.2957, 0.0153, 0.0686, 0.0000,\n",
       "         0.0000, 0.0449, 0.0000, 0.0389, 0.2060, 0.0000, 0.0000, 0.1597, 0.0961,\n",
       "         0.0601, 0.0000, 0.1443, 0.0000, 0.0249, 0.0000, 0.0000, 0.1394, 0.0000,\n",
       "         0.0000, 0.2619, 0.4811, 0.0000, 0.0000, 0.2607, 0.2320, 0.1815, 0.1317,\n",
       "         0.0219, 0.0000, 0.0000, 0.1560, 0.0495, 0.0323, 0.0000, 0.0000, 0.2098,\n",
       "         0.0000, 0.0000, 0.0000, 0.0484, 0.1686, 0.0209, 0.0745, 0.1428, 0.0210,\n",
       "         0.2972, 0.0517, 0.0255, 0.0000, 0.0285, 0.0000, 0.0489, 0.0000, 0.3096,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.2733, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0208, 0.0000, 0.0000, 0.0000, 0.0000, 0.0689, 0.3045, 0.0000,\n",
       "         0.0000, 0.1453, 0.0000, 0.0000, 0.0000, 0.1426, 0.1746, 0.0000, 0.0601,\n",
       "         0.0000, 0.0000, 0.0566, 0.0161, 0.0764, 0.1878, 0.0000, 0.1690, 0.1233,\n",
       "         0.0212, 0.0000, 0.0000, 0.0000, 0.0000, 0.0121, 0.0000, 0.0000, 0.0000,\n",
       "         0.0166, 0.0000, 0.2940, 0.1335, 0.0000, 0.0007, 0.0000, 0.0000, 0.0000,\n",
       "         0.0550, 0.1206, 0.0000, 0.0000, 0.2288, 0.0000, 0.0000, 0.0000, 0.1206,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.3287, 0.0000, 0.0000, 0.0446, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.2649, 0.0000, 0.0983, 0.0000, 0.0000,\n",
       "         0.1272, 0.0152, 0.1872, 0.2253, 0.2953, 0.1422, 0.0162, 0.0000, 0.1113,\n",
       "         0.0000, 0.0000, 0.0000, 0.0682, 0.0215, 0.0000, 0.0000, 0.0000, 0.0475,\n",
       "         0.0864, 0.0000, 0.1579, 0.0000, 0.0000, 0.1224, 0.0000, 0.1575, 0.2785,\n",
       "         0.2704, 0.1000, 0.0914, 0.0917, 0.0000, 0.0110, 0.0000, 0.1155, 0.1069,\n",
       "         0.0000, 0.1158, 0.0268, 0.1929, 0.1254, 0.0000, 0.0000, 0.2159, 0.1119,\n",
       "         0.0081, 0.0235, 0.0260, 0.0000, 0.0165, 0.1497, 0.0000, 0.0000, 0.0584,\n",
       "         0.1748, 0.2310, 0.2556, 0.0373, 0.0712, 0.0489, 0.0519, 0.0409, 0.1169,\n",
       "         0.0071, 0.0000, 0.1238, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0466, 0.0000, 0.0765, 0.0000, 0.0000, 0.0724, 0.3551, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0060, 0.0000, 0.0000, 0.0933, 0.0000, 0.1697, 0.0000,\n",
       "         0.2046, 0.0000, 0.0000, 0.0000, 0.0332, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.1130, 0.1460, 0.0000, 0.0000, 0.0310, 0.0083, 0.0438, 0.0000,\n",
       "         0.0000, 0.1389, 0.0000, 0.0000, 0.0000, 0.0000, 0.0098, 0.0000, 0.2028,\n",
       "         0.0578, 0.0622, 0.0000, 0.1155, 0.0000, 0.0000, 0.0149, 0.1709, 0.1731,\n",
       "         0.1463, 0.0378, 0.1273, 0.0282, 0.0000, 0.1515, 0.0000, 0.0995, 0.0000,\n",
       "         0.0000, 0.0669, 0.0000, 0.0000, 0.0000, 0.0000, 0.2532, 0.0000, 0.0000,\n",
       "         0.0000, 0.0190, 0.2961, 0.1225, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1694, 0.1229, 0.0000, 0.0000, 0.0297, 0.0203, 0.0000, 0.1839, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0901, 0.0409, 0.0573, 0.0000, 0.0000, 0.0214,\n",
       "         0.0000, 0.0000, 0.0511, 0.0000, 0.0361, 0.1950, 0.0000, 0.0000, 0.4377,\n",
       "         0.0000, 0.1481, 0.0000, 0.0939, 0.1981, 0.0000, 0.0693, 0.0000, 0.0365,\n",
       "         0.0000, 0.0000, 0.2060, 0.1395, 0.2458, 0.1558, 0.0000, 0.0000, 0.0000,\n",
       "         0.0959, 0.0306, 0.0000, 0.0000, 0.2255, 0.2432, 0.0000, 0.2074, 0.0000,\n",
       "         0.1315, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0188, 0.0308, 0.0499,\n",
       "         0.0000, 0.0000, 0.2127, 0.0114, 0.0649, 0.1338, 0.0000, 0.1672, 0.0000,\n",
       "         0.0000, 0.2288, 0.2184, 0.0158, 0.0496, 0.1961, 0.0000, 0.4290, 0.0000,\n",
       "         0.0000, 0.0000, 0.0795, 0.0181, 0.0379, 0.0000, 0.1717, 0.0453, 0.1521,\n",
       "         0.0000, 0.0000, 0.0378, 0.0121, 0.1536, 0.0000, 0.0560, 0.0326, 0.0163,\n",
       "         0.0000, 0.0000, 0.0000, 0.0931, 0.0978, 0.0000, 0.1459, 0.0183, 0.0416,\n",
       "         0.0000, 0.0903, 0.0000, 0.0422, 0.0000, 0.0000, 0.0000, 0.0037, 0.0437,\n",
       "         0.0000, 0.0000, 0.0000, 0.1897, 0.0473, 0.1161, 0.0000, 0.0000, 0.2764,\n",
       "         0.1257, 0.0000, 0.0000, 0.2057, 0.2546, 0.0000, 0.0000, 0.0000, 0.0841,\n",
       "         0.1855, 0.0787, 0.0000, 0.0767, 0.0000, 0.0000, 0.0000, 0.1003, 0.0000,\n",
       "         0.0000, 0.1190, 0.0000, 0.0069, 0.0000, 0.0740, 0.1106, 0.2631, 0.0000,\n",
       "         0.0000, 0.0000, 0.1241, 0.0000, 0.0000, 0.1238, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.1168, 0.0751, 0.1406, 0.2412, 0.0364, 0.1098, 0.0000,\n",
       "         0.0000, 0.1188, 0.0000, 0.0022, 0.1706, 0.0000, 0.0112, 0.0976, 0.0518,\n",
       "         0.0616, 0.0000, 0.1246, 0.0000, 0.0972, 0.0638, 0.0000, 0.2161, 0.0000,\n",
       "         0.0000, 0.2969, 0.5110, 0.0056, 0.0000, 0.2733, 0.2569, 0.2632, 0.1244,\n",
       "         0.0449, 0.0000, 0.0000, 0.1544, 0.0000, 0.0771, 0.0000, 0.0000, 0.2061,\n",
       "         0.0000, 0.0000, 0.0000, 0.0551, 0.2456, 0.1187, 0.0902, 0.1339, 0.0000,\n",
       "         0.2818, 0.0800, 0.0000, 0.0000, 0.0023, 0.0000, 0.0000, 0.0000, 0.2933,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.2866, 0.0000, 0.0000, 0.0000, 0.0635,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0102, 0.0214, 0.3867, 0.0000,\n",
       "         0.0000, 0.1398, 0.0000, 0.0000, 0.0000, 0.1664, 0.1488, 0.0000, 0.0302,\n",
       "         0.0482, 0.0000, 0.0470, 0.0398, 0.0555, 0.2454, 0.0000, 0.1794, 0.0723,\n",
       "         0.0452, 0.0000, 0.0000, 0.0000, 0.0000, 0.0798, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.2407, 0.1632, 0.0000, 0.0292, 0.0000, 0.0172, 0.0000,\n",
       "         0.0421, 0.1440, 0.0000, 0.0000, 0.1637, 0.0000, 0.0000, 0.0000, 0.0444,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.3204, 0.0000, 0.0000, 0.0774, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.2010, 0.0000, 0.1387, 0.0000, 0.0000,\n",
       "         0.0806, 0.0000, 0.1623, 0.3215, 0.2706, 0.1413, 0.0000, 0.0000, 0.0568,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0669, 0.0333, 0.0000, 0.0000, 0.0000,\n",
       "         0.1119, 0.0000, 0.1637, 0.0000, 0.0000, 0.1333, 0.0000, 0.2087, 0.3113,\n",
       "         0.2052, 0.0930, 0.1408, 0.1847, 0.0000, 0.0087, 0.0000, 0.1711, 0.1075,\n",
       "         0.0000, 0.0788, 0.0793, 0.1846, 0.1071, 0.0000, 0.0495, 0.3012, 0.1234,\n",
       "         0.0844, 0.0000, 0.0363, 0.0000, 0.0000, 0.0922, 0.0000, 0.0000, 0.0551,\n",
       "         0.1440, 0.1573, 0.2675, 0.0627, 0.1237, 0.0000, 0.0843, 0.0000, 0.1508,\n",
       "         0.0000, 0.0000, 0.1412, 0.0000, 0.0000, 0.0000, 0.0013, 0.0000, 0.0000,\n",
       "         0.0185, 0.0153, 0.0952, 0.0418, 0.0016, 0.0522, 0.4028, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1106, 0.0000, 0.1952, 0.0000,\n",
       "         0.2004, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0587, 0.1394, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.2159, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1738,\n",
       "         0.0000, 0.0040, 0.0000, 0.1610, 0.0000, 0.0000, 0.0000, 0.1743, 0.1824,\n",
       "         0.1091, 0.0879, 0.0952, 0.0265, 0.0000, 0.1739, 0.0000, 0.1095, 0.0000,\n",
       "         0.0000, 0.1200, 0.0000, 0.0000, 0.0000, 0.0000, 0.2368, 0.0000, 0.0178,\n",
       "         0.0000, 0.0452, 0.2286, 0.1237, 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure that calling the model works as expected\n",
    "inp = torch.zeros((2, NUM_REACTIVITIES, 2))\n",
    "inp[:, 0, :] = 1\n",
    "\n",
    "model(inp.to(DEVICE)).cpu().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttentionModel(\n",
      "  (proj): Linear(in_features=2, out_features=32, bias=True)\n",
      "  (pos_embedding): SinePositionalEmbedding()\n",
      "  (encoder_layers): CustomTransformerEncoder(\n",
      "    (0): CustomTransformerEncoderLayer(\n",
      "      (attention): MultiHeadDispatch(\n",
      "        (attention): ScaledDotProduct(\n",
      "          (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (in_proj_container): InputProjection(\n",
      "          (q_proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (k_proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (v_proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "        )\n",
      "        (resid_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "      (ff1): Linear(in_features=32, out_features=2048, bias=True)\n",
      "      (ff2): Linear(in_features=2048, out_features=32, bias=True)\n",
      "      (gelu): GELU(approximate='none')\n",
      "    )\n",
      "    (1): CustomTransformerEncoderLayer(\n",
      "      (attention): MultiHeadDispatch(\n",
      "        (attention): ScaledDotProduct(\n",
      "          (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (in_proj_container): InputProjection(\n",
      "          (q_proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (k_proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (v_proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "        )\n",
      "        (resid_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "      (ff1): Linear(in_features=32, out_features=2048, bias=True)\n",
      "      (ff2): Linear(in_features=2048, out_features=32, bias=True)\n",
      "      (gelu): GELU(approximate='none')\n",
      "    )\n",
      "    (2): CustomTransformerEncoderLayer(\n",
      "      (attention): MultiHeadDispatch(\n",
      "        (attention): ScaledDotProduct(\n",
      "          (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (in_proj_container): InputProjection(\n",
      "          (q_proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (k_proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (v_proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "        )\n",
      "        (resid_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "      (ff1): Linear(in_features=32, out_features=2048, bias=True)\n",
      "      (ff2): Linear(in_features=2048, out_features=32, bias=True)\n",
      "      (gelu): GELU(approximate='none')\n",
      "    )\n",
      "    (3): CustomTransformerEncoderLayer(\n",
      "      (attention): MultiHeadDispatch(\n",
      "        (attention): ScaledDotProduct(\n",
      "          (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (in_proj_container): InputProjection(\n",
      "          (q_proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (k_proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (v_proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "        )\n",
      "        (resid_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "      (ff1): Linear(in_features=32, out_features=2048, bias=True)\n",
      "      (ff2): Linear(in_features=2048, out_features=32, bias=True)\n",
      "      (gelu): GELU(approximate='none')\n",
      "    )\n",
      "  )\n",
      "  (decoder_layers): CustomTransformerDecoder(\n",
      "    (0): CustomTransformerDecoderLayer(\n",
      "      (crossattention): MultiHeadDispatch(\n",
      "        (attention): ScaledDotProduct(\n",
      "          (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (in_proj_container): InputProjection(\n",
      "          (q_proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (k_proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (v_proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "        )\n",
      "        (resid_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (selfattention): MultiHeadDispatch(\n",
      "        (attention): ScaledDotProduct(\n",
      "          (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (in_proj_container): InputProjection(\n",
      "          (q_proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (k_proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (v_proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "        )\n",
      "        (resid_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "      (ff1): Linear(in_features=32, out_features=2048, bias=True)\n",
      "      (ff2): Linear(in_features=2048, out_features=32, bias=True)\n",
      "      (gelu): GELU(approximate='none')\n",
      "    )\n",
      "    (1): CustomTransformerDecoderLayer(\n",
      "      (crossattention): MultiHeadDispatch(\n",
      "        (attention): ScaledDotProduct(\n",
      "          (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (in_proj_container): InputProjection(\n",
      "          (q_proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (k_proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (v_proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "        )\n",
      "        (resid_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (selfattention): MultiHeadDispatch(\n",
      "        (attention): ScaledDotProduct(\n",
      "          (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (in_proj_container): InputProjection(\n",
      "          (q_proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (k_proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (v_proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "        )\n",
      "        (resid_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "      (ff1): Linear(in_features=32, out_features=2048, bias=True)\n",
      "      (ff2): Linear(in_features=2048, out_features=32, bias=True)\n",
      "      (gelu): GELU(approximate='none')\n",
      "    )\n",
      "    (2): CustomTransformerDecoderLayer(\n",
      "      (crossattention): MultiHeadDispatch(\n",
      "        (attention): ScaledDotProduct(\n",
      "          (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (in_proj_container): InputProjection(\n",
      "          (q_proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (k_proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (v_proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "        )\n",
      "        (resid_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (selfattention): MultiHeadDispatch(\n",
      "        (attention): ScaledDotProduct(\n",
      "          (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (in_proj_container): InputProjection(\n",
      "          (q_proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (k_proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (v_proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "        )\n",
      "        (resid_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "      (ff1): Linear(in_features=32, out_features=2048, bias=True)\n",
      "      (ff2): Linear(in_features=2048, out_features=32, bias=True)\n",
      "      (gelu): GELU(approximate='none')\n",
      "    )\n",
      "    (3): CustomTransformerDecoderLayer(\n",
      "      (crossattention): MultiHeadDispatch(\n",
      "        (attention): ScaledDotProduct(\n",
      "          (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (in_proj_container): InputProjection(\n",
      "          (q_proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (k_proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (v_proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "        )\n",
      "        (resid_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (selfattention): MultiHeadDispatch(\n",
      "        (attention): ScaledDotProduct(\n",
      "          (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (in_proj_container): InputProjection(\n",
      "          (q_proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (k_proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (v_proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "        )\n",
      "        (resid_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "      (ff1): Linear(in_features=32, out_features=2048, bias=True)\n",
      "      (ff2): Linear(in_features=2048, out_features=32, bias=True)\n",
      "      (gelu): GELU(approximate='none')\n",
      "    )\n",
      "  )\n",
      "  (head): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (final_result): Linear(in_features=457, out_features=457, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (gelu): GELU(approximate='none')\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 1325851\n"
     ]
    }
   ],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(\"Total params:\", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), 3e-4, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Training Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"2a3_4enc_4dec_2048ff_32lat_1hd\"\n",
    "writer = SummaryWriter(f\"runs/{run_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "SHUFFLE = True\n",
    "\n",
    "# create dataloaders\n",
    "train_dataloader = data.DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=SHUFFLE\n",
    ")\n",
    "# no point in shuffling validation set\n",
    "val_dataloader = data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unweightedL1(\n",
    "    y_pred: torch.Tensor,\n",
    "    y_true: torch.Tensor,\n",
    "    weights: torch.Tensor,\n",
    "    l1=torch.nn.L1Loss(reduction=\"none\"),\n",
    "):\n",
    "    \"\"\"\n",
    "    MAE Loss function where sample weights are only used to determine masks.\n",
    "    \"\"\"\n",
    "    return (l1(y_pred, y_true))[weights != 0].mean()\n",
    "\n",
    "\n",
    "def weightedL1(\n",
    "    y_pred: torch.Tensor,\n",
    "    y_true: torch.Tensor,\n",
    "    weights: torch.Tensor,\n",
    "    l1=torch.nn.L1Loss(reduction=\"none\"),\n",
    "):\n",
    "    \"\"\"\n",
    "    MAE loss function that takes into account sample weights\n",
    "    \"\"\"\n",
    "    return (l1(y_pred, y_true) * weights)[weights != 0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:09:43.992618Z",
     "start_time": "2023-10-05T17:09:43.053099Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_batch(\n",
    "    m: torch.nn.Module, inps: torch.Tensor, outs: torch.Tensor, masks: torch.Tensor\n",
    "):\n",
    "    \"\"\"\n",
    "    Get the loss on a batch and perform the corresponding weight updates.\n",
    "    Used for training purposes\n",
    "    \"\"\"\n",
    "    optimizer.zero_grad()\n",
    "    preds = m(inps)\n",
    "\n",
    "    # get the weighted mae\n",
    "    weighted_loss = weightedL1(preds, outs, masks)\n",
    "    weighted_loss.backward()\n",
    "\n",
    "    # calculate gradients\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        unweighted_loss = unweightedL1(preds, outs, masks)\n",
    "\n",
    "    # return weighted and unweighted mae loss\n",
    "    return weighted_loss.detach().cpu(), unweighted_loss.detach().cpu()\n",
    "\n",
    "\n",
    "def noupdate_batch(\n",
    "    m: torch.nn.Module, inps: torch.Tensor, outs: torch.Tensor, masks: torch.Tensor\n",
    "):\n",
    "    \"\"\"\n",
    "    Get the loss on a batch without performing any updates.\n",
    "    Used for validation purposes\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        preds = m(inps)\n",
    "        weighted_loss = weightedL1(preds, outs, masks)\n",
    "        unweighted_loss = unweightedL1(preds, outs, masks)\n",
    "\n",
    "    # return weighted and unweighted mae loss\n",
    "    return weighted_loss.cpu(), unweighted_loss.cpu()\n",
    "\n",
    "\n",
    "\n",
    "def masked_train(\n",
    "    m: torch.nn.Module,\n",
    "    train_dataloader: data.DataLoader,\n",
    "    val_dataloader: data.DataLoader,\n",
    "    epochs: int = 1,\n",
    "    device: str = DEVICE,\n",
    "):\n",
    "    \"\"\"\n",
    "    Train the given model.\n",
    "\n",
    "    Arguments:\n",
    "        - m: torch.nn.Module - the model to train.\n",
    "        - train_dataloader: data.Dataloader - the dataloader that provides the batched training data\n",
    "        - val_dataloader: data.Dataloader - the dataloader that provides the batched validation data\n",
    "        - epochs: int - how many epochs to train for. Defaults to `1`.\n",
    "        - device: str - the device to train on, defaults to `DEVICE`\n",
    "    \"\"\"\n",
    "    m = m.to(device)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"Epoch {epoch}\")\n",
    "        epoch_mae = 0.0\n",
    "        epoch_weighted_mae = 0.0\n",
    "\n",
    "        m = m.train()\n",
    "        for tdata in (prog := tqdm(train_dataloader, desc=\"batch\")):\n",
    "            inps = torch.stack([tdata[\"inputs\"], tdata[\"bpp\"]], dim=-1)\n",
    "            outs = tdata[\"outputs\"]\n",
    "            masks = tdata[\"output_masks\"]\n",
    "\n",
    "            inps = inps.to(device)\n",
    "            outs = outs.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            weighted_mae, mae = train_batch(m, inps, outs, masks)\n",
    "\n",
    "            epoch_weighted_mae += weighted_mae\n",
    "            epoch_mae += mae\n",
    "\n",
    "            # log\n",
    "            prog.set_postfix_str(\n",
    "                f\"mae_loss: {mae:.5f}, weighted_mae_loss: {weighted_mae:.5f}\"\n",
    "            )\n",
    "\n",
    "            # break  # used for sanity check\n",
    "        epoch_weighted_mae /= len(train_dataloader)\n",
    "        epoch_mae /= len(train_dataloader)\n",
    "\n",
    "        # do validation\n",
    "        val_mae = 0.0\n",
    "        val_weighted_mae = 0.0\n",
    "        m = m.eval()\n",
    "        for vdata in val_dataloader:\n",
    "            inps = torch.stack([vdata[\"inputs\"], vdata[\"bpp\"]], dim=-1)\n",
    "            outs = vdata[\"outputs\"]\n",
    "            masks = vdata[\"output_masks\"]\n",
    "\n",
    "            inps = inps.to(device)\n",
    "            outs = outs.to(device)\n",
    "            masks = masks.to(device)\n",
    "            weighted_mae, mae = noupdate_batch(m, inps, outs, masks)\n",
    "\n",
    "            val_weighted_mae += weighted_mae\n",
    "            val_mae += mae\n",
    "        val_weighted_mae /= len(val_dataloader)\n",
    "        val_mae /= len(val_dataloader)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch MAE: {epoch_mae:.5f}\\tEpoch Weighted MAE: {epoch_weighted_mae:.5f}\\t\"\n",
    "            + f\"Val MAE: {val_mae:.5f}\\tVal Weighted MAE: {val_weighted_mae:.5f}\"\n",
    "        )\n",
    "\n",
    "        writer.add_scalar(\"epoch_mae\", epoch_mae, global_step=epoch)\n",
    "        writer.add_scalar(\"val_mae\", val_mae, global_step=epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actually Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:14:00.128074Z",
     "start_time": "2023-10-05T17:09:43.998369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 5935/5935 [08:48<00:00, 11.23it/s, mae_loss: 4.44841]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch MAE: 4.47702\tVal MAE: 4.16918\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 5935/5935 [08:46<00:00, 11.27it/s, mae_loss: 3.53083]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch MAE: 4.02770\tVal MAE: 3.95749\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 5935/5935 [08:46<00:00, 11.26it/s, mae_loss: 4.13797]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch MAE: 3.90536\tVal MAE: 3.87650\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 5935/5935 [08:46<00:00, 11.27it/s, mae_loss: 4.37849]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch MAE: 3.84980\tVal MAE: 3.84144\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 5935/5935 [08:46<00:00, 11.27it/s, mae_loss: 3.90057]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch MAE: 3.81516\tVal MAE: 3.81270\n",
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 5935/5935 [08:46<00:00, 11.27it/s, mae_loss: 3.44230]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch MAE: 3.78689\tVal MAE: 3.78277\n",
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 5935/5935 [08:46<00:00, 11.27it/s, mae_loss: 3.48380]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch MAE: 3.76225\tVal MAE: 3.75762\n",
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 5935/5935 [08:46<00:00, 11.27it/s, mae_loss: 3.62215]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch MAE: 3.74261\tVal MAE: 3.74168\n",
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 5935/5935 [08:46<00:00, 11.26it/s, mae_loss: 3.61237]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch MAE: 3.72531\tVal MAE: 3.72991\n",
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 5935/5935 [08:47<00:00, 11.26it/s, mae_loss: 3.12289]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch MAE: 3.70957\tVal MAE: 3.70936\n",
      "Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 5935/5935 [08:47<00:00, 11.26it/s, mae_loss: 3.38920]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch MAE: 3.69511\tVal MAE: 3.70276\n",
      "Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 5935/5935 [08:47<00:00, 11.26it/s, mae_loss: 4.28023]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch MAE: 3.68126\tVal MAE: 3.68388\n",
      "Epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 5935/5935 [08:47<00:00, 11.26it/s, mae_loss: 4.08066]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch MAE: 3.66762\tVal MAE: 3.66970\n",
      "Epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 5935/5935 [08:47<00:00, 11.26it/s, mae_loss: 3.02614]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch MAE: 3.65575\tVal MAE: 3.66305\n",
      "Epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 5935/5935 [08:47<00:00, 11.26it/s, mae_loss: 3.80542]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch MAE: 3.64424\tVal MAE: 3.64721\n",
      "Epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 5935/5935 [08:47<00:00, 11.26it/s, mae_loss: 3.37479]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch MAE: 3.63390\tVal MAE: 3.63535\n",
      "Epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 5935/5935 [08:47<00:00, 11.26it/s, mae_loss: 3.22153]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch MAE: 3.62388\tVal MAE: 3.63098\n",
      "Epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 5935/5935 [08:47<00:00, 11.25it/s, mae_loss: 3.75673]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch MAE: 3.61453\tVal MAE: 3.62176\n",
      "Epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 5935/5935 [08:47<00:00, 11.26it/s, mae_loss: 3.38778]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch MAE: 3.60493\tVal MAE: 3.61179\n",
      "Epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 5935/5935 [08:47<00:00, 11.25it/s, mae_loss: 3.39821]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch MAE: 3.59683\tVal MAE: 3.60006\n",
      "Epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 5935/5935 [08:47<00:00, 11.25it/s, mae_loss: 3.24906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch MAE: 3.58812\tVal MAE: 3.60502\n",
      "Epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 5935/5935 [08:47<00:00, 11.25it/s, mae_loss: 3.21587]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch MAE: 3.57291\tVal MAE: 3.57219\n",
      "Epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 5935/5935 [08:47<00:00, 11.25it/s, mae_loss: 3.58285]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch MAE: 3.55620\tVal MAE: 3.56388\n",
      "Epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 5935/5935 [08:47<00:00, 11.25it/s, mae_loss: 2.97358]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch MAE: 3.54758\tVal MAE: 3.56231\n",
      "Epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 5935/5935 [08:47<00:00, 11.26it/s, mae_loss: 3.28555]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch MAE: 3.53928\tVal MAE: 3.55091\n",
      "Epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 5935/5935 [08:47<00:00, 11.25it/s, mae_loss: 3.11013]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch MAE: 3.53188\tVal MAE: 3.54549\n",
      "Epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 5935/5935 [08:47<00:00, 11.25it/s, mae_loss: 3.64237]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch MAE: 3.52473\tVal MAE: 3.53989\n",
      "Epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 5935/5935 [08:47<00:00, 11.25it/s, mae_loss: 3.14513]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch MAE: 3.51731\tVal MAE: 3.53033\n",
      "Epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 5935/5935 [08:47<00:00, 11.25it/s, mae_loss: 3.48912]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch MAE: 3.51022\tVal MAE: 3.52403\n",
      "Epoch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 5935/5935 [08:47<00:00, 11.26it/s, mae_loss: 3.12371]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch MAE: 3.50327\tVal MAE: 3.52571\n",
      "Epoch 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 5935/5935 [08:47<00:00, 11.25it/s, mae_loss: 4.09936]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch MAE: 3.49658\tVal MAE: 3.51007\n",
      "Epoch 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 5935/5935 [08:47<00:00, 11.25it/s, mae_loss: 3.70177]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch MAE: 3.48996\tVal MAE: 3.50311\n",
      "Epoch 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 5935/5935 [08:47<00:00, 11.26it/s, mae_loss: 2.79417]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch MAE: 3.48262\tVal MAE: 3.49953\n",
      "Epoch 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 5935/5935 [08:47<00:00, 11.26it/s, mae_loss: 3.42455]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch MAE: 3.47677\tVal MAE: 3.49149\n",
      "Epoch 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 5935/5935 [08:47<00:00, 11.26it/s, mae_loss: 2.49733]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch MAE: 3.47006\tVal MAE: 3.48975\n",
      "Epoch 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 5935/5935 [08:47<00:00, 11.26it/s, mae_loss: 4.14771]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch MAE: 3.46446\tVal MAE: 3.48189\n",
      "Epoch 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 5935/5935 [08:47<00:00, 11.26it/s, mae_loss: 3.27662]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch MAE: 3.45867\tVal MAE: 3.48002\n",
      "Epoch 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 5935/5935 [08:47<00:00, 11.25it/s, mae_loss: 3.35660]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch MAE: 3.45274\tVal MAE: 3.47069\n",
      "Epoch 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 5935/5935 [08:47<00:00, 11.26it/s, mae_loss: 3.97856]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch MAE: 3.44727\tVal MAE: 3.46915\n",
      "Epoch 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 5935/5935 [08:47<00:00, 11.25it/s, mae_loss: 3.81477]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch MAE: 3.44136\tVal MAE: 3.46431\n"
     ]
    }
   ],
   "source": [
    "# baseline gets ~ 3.02 on dms w/ 10 epochs, ~ 3.87 on 2a3 w/ 20 epochs\n",
    "masked_train(\n",
    "    model, train_dataloader=train_dataloader, val_dataloader=val_dataloader, epochs=40\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've trained our model, we can save its weights and biases (\"state dict\") so that we can load them for later inferencing or further training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:14:00.616528Z",
     "start_time": "2023-10-05T17:14:00.119617Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"{desired_dataset}_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have both models, it's time to create a submission file. \n",
    "This section creates a zipped csv submission file that can\n",
    "be submitted on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:14:00.624146Z",
     "start_time": "2023-10-05T17:14:00.601389Z"
    }
   },
   "outputs": [],
   "source": [
    "make_submissions = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T17:14:01.233216Z",
     "start_time": "2023-10-05T17:14:00.608006Z"
    }
   },
   "outputs": [],
   "source": [
    "valid = False\n",
    "\n",
    "if (\n",
    "    os.path.exists(\"2a3_model\")\n",
    "    and os.path.exists(\"dms_model\")\n",
    "    and os.path.exists(\"test_sequences.csv\")\n",
    "    and make_submissions\n",
    "):\n",
    "    if use_baseline:\n",
    "        model_dms = BaselineModel()\n",
    "        model_2a3 = BaselineModel()\n",
    "    else:\n",
    "        model_2a3 = AttentionModel(**model_2a3_kwargs)\n",
    "        model_dms = AttentionModel(**model_dms_kwargs)\n",
    "\n",
    "    model_2a3.load_state_dict(torch.load(\"2a3_model\"))\n",
    "    model_dms.load_state_dict(torch.load(\"dms_model\"))\n",
    "\n",
    "    model_2a3.eval().to(DEVICE)\n",
    "    model_dms.eval().to(DEVICE)\n",
    "\n",
    "    valid = True\n",
    "else:\n",
    "    print(\"Not going to create submissions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(\n",
    "    model_2a3: torch.nn.Module,\n",
    "    model_dms: torch.nn.Module,\n",
    "    input_ds: str,\n",
    "    out: str,\n",
    "    batch_size: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    Make predictions on the test dataset and write them to a csv file\n",
    "\n",
    "    Parameters:\n",
    "        - model_2a3: torch.nn.Module - the model trained on the 2a3 distribution\n",
    "        - model_dms: torch.nn.Module - the model trained on the dms distribution\n",
    "        - input_ds: str - name of the dataset to load\n",
    "        - out: str - name of the file to write to\n",
    "        - batch_size: int - size of the batches to use to process the data.\n",
    "            In general, larger batch sizes mean faster runtime\n",
    "    \"\"\"\n",
    "    ds = Dataset.load_from_disk(input_ds).with_format(\"torch\")\n",
    "    loader = data.DataLoader(ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    iterable = iter(loader)\n",
    "\n",
    "    with open(out, \"w\") as outfile:\n",
    "        # write the header\n",
    "        outfile.write(\"id,reactivity_DMS_MaP,reactivity_2A3_MaP\\n\")\n",
    "\n",
    "        for _ in tqdm(range(len(loader))):\n",
    "            # get the next group of data\n",
    "            tdata = next(iterable)\n",
    "            inputs = torch.stack([tdata[\"inputs\"], tdata[\"bpp\"]], dim=-1).to(DEVICE)\n",
    "            min_ids = tdata[\"id_min\"].numpy()\n",
    "            max_ids = tdata[\"id_max\"].numpy()\n",
    "\n",
    "            # make predictions w/o gradients\n",
    "            with torch.no_grad():\n",
    "                preds_2a3 = model_2a3(inputs).cpu().numpy()\n",
    "                preds_dms = model_dms(inputs).cpu().numpy()\n",
    "\n",
    "            # write preds\n",
    "            for i in range(inputs.shape[0]):\n",
    "                outfile.writelines(\n",
    "                    map(\n",
    "                        lambda seq_idx: f\"{seq_idx},{preds_dms[i, seq_idx-min_ids[i]]:.3f},{preds_2a3[i, seq_idx-min_ids[i]]:.3f}\\n\",\n",
    "                        # +1 since the id_max is inclusive\n",
    "                        range(min_ids[i], max_ids[i] + 1),\n",
    "                    )\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-05T17:14:01.248308Z"
    },
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41995/41995 [49:45<00:00, 14.07it/s]\n"
     ]
    }
   ],
   "source": [
    "if valid:\n",
    "    pipeline(\n",
    "        model_2a3,\n",
    "        model_dms,\n",
    "        \"test_data_preprocessed\",\n",
    "        \"submission.csv\",\n",
    "        batch_size=BATCH_SIZE,\n",
    "    )\n",
    "else:\n",
    "    print(\"Not going to create submissions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zipping submissions. This may take a while...\n",
      "updating: submission.csv (deflated 80%)\n",
      "Done zipping submissions!\n"
     ]
    }
   ],
   "source": [
    "if valid:\n",
    "    # zip our submission into an easily-uploadable zip file\n",
    "    print(\"zipping submissions. This may take a while...\")\n",
    "    os.system(\"zip submission.csv.zip submission.csv\")\n",
    "    print(\"Done zipping submissions!\")\n",
    "else:\n",
    "    print(\"Not going to zip submissions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
